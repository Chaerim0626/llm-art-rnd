{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc5c67d-0b33-4bfc-824a-1c23656acfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import markdown\n",
    "from docx import Document\n",
    "from bs4 import BeautifulSoup\n",
    "from docx.shared import Pt\n",
    "from docx.oxml.ns import qn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2440f2f5-8cba-464f-afd4-d03641b17f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading JSON files: 100%|██████████████████| 111/111 [00:00<00:00, 699.25file/s]\n",
      "Writing to Word:   0%|                             | 0/11029 [00:00<?, ?entry/s]/home/chae/ch/lib/python3.12/site-packages/docx/styles/styles.py:130: UserWarning: style lookup by style_id is deprecated. Use style name as key instead.\n",
      "  return self._get_style_id_from_style(self[style_name], style_type)\n",
      "Writing to Word: 100%|█████████████████| 11029/11029 [04:13<00:00, 43.58entry/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 JSON 데이터가 './dataset2.docx'에 작품 번호 순서대로 저장되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.oxml.ns import qn\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1. Word 문서 생성\n",
    "doc = Document()\n",
    "\n",
    "# 2. 폰트 설정 함수 정의 (한글 지원)\n",
    "def set_font(run, font_name=\"맑은 고딕\", size=11, bold=False):\n",
    "    run.font.size = Pt(size)\n",
    "    run.bold = bold\n",
    "    run.font.name = font_name\n",
    "    r = run._element\n",
    "    r.rPr.rFonts.set(qn('w:eastAsia'), font_name)\n",
    "\n",
    "# 3. JSON 파일들이 저장된 폴더 경로 설정\n",
    "folder_path = \"./artworks\"  # JSON 파일 경로 수정\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith(\".json\")]\n",
    "\n",
    "# 4. Markdown 형식의 콘텐츠를 Word 문서로 변환하는 함수\n",
    "def markdown_to_docx(md_content, doc):\n",
    "    html = markdown.markdown(md_content)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    for element in soup.descendants:\n",
    "        if element.name == \"p\":\n",
    "            para = doc.add_paragraph(element.get_text())\n",
    "            set_font(para.runs[0])\n",
    "        elif element.name in [\"h1\", \"h2\", \"h3\"]:\n",
    "            heading_level = int(element.name[1])\n",
    "            para = doc.add_heading(element.get_text(), level=heading_level)\n",
    "            set_font(para.runs[0], bold=True)\n",
    "        elif element.name == \"li\":\n",
    "            para = doc.add_paragraph(element.get_text(), style='ListBullet')\n",
    "            set_font(para.runs[0])\n",
    "\n",
    "# 5. JSON 파일 반복 처리 및 데이터 모으기\n",
    "all_data = []\n",
    "\n",
    "for filename in tqdm(json_files, desc=\"Reading JSON files\", unit=\"file\", ncols=80):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data_list = json.load(f)\n",
    "        all_data.extend(data_list)\n",
    "\n",
    "# 6. 작품 번호(wrkMngNo) 기준 정렬\n",
    "all_data = sorted(all_data, key=lambda x: int(x.get('rnum', 0)))\n",
    "\n",
    "# 7. 정렬된 데이터를 Word 문서에 기록 (진행 퍼센트 표시)\n",
    "for idx, data in enumerate(tqdm(all_data, desc=\"Writing to Word\", unit=\"entry\", ncols=80)):\n",
    "    md_content = f\"\"\"\n",
    "- 작품명: {data.get('wrkNm', 'N/A')} / {data.get('wrkNmCh', 'N/A')} / {data.get('wrkNmEng', 'N/A')}\n",
    "- 작가: {data.get('artistnm', 'N/A')} / {data.get('artistnmEng', 'N/A')}\n",
    "- 작품 번호: {data.get('rnum', 'N/A')}\n",
    "- 제작 연도: {data.get('wrkProdTermEnd', 'N/A')}\n",
    "- 크기: {data.get('detail_dimensions', 'N/A')}\n",
    "- 재료: {data.get('detail_material', 'N/A')}\n",
    "- 카테고리: {data.get('detail_category', 'N/A')}\n",
    "- 작품 설명: {data.get('detail_desc', 'N/A')}\n",
    "\"\"\"\n",
    "\n",
    "    # Markdown을 Word 문서로 변환\n",
    "    markdown_to_docx(md_content, doc)\n",
    "\n",
    "    # 구분선 추가\n",
    "    doc.add_paragraph()\n",
    "    doc.add_paragraph()  # 빈 줄 추가\n",
    "\n",
    "# 8. Word 문서 저장\n",
    "output_path = \"./dataset2.docx\"\n",
    "doc.save(output_path)\n",
    "\n",
    "print(f\"모든 JSON 데이터가 '{output_path}'에 작품 번호 순서대로 저장되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc91425c-01ed-4f77-8c42-3d6946f0275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating split Word files: 100%|████████████████| 5/5 [00:16<00:00,  3.26s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.docx 파일이 5개로 나누어 저장되었습니다!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 원본 Word 문서 열기\n",
    "input_path = \"./dataset.docx\"\n",
    "doc = Document(input_path)\n",
    "\n",
    "# 2. 문서의 모든 단락(paragraphs) 가져오기\n",
    "paragraphs = doc.paragraphs\n",
    "total_paragraphs = len(paragraphs)\n",
    "\n",
    "# 3. 각 문서에 포함될 단락 수 계산\n",
    "chunk_size = total_paragraphs // 5  # 나눌 단위 크기\n",
    "remainder = total_paragraphs % 5  # 남은 단락 수\n",
    "\n",
    "# 4. 5개의 문서를 생성하고 저장\n",
    "start_idx = 0\n",
    "\n",
    "for i in tqdm(range(5), desc=\"Creating split Word files\", unit=\"file\", ncols=80):\n",
    "    # 남은 단락을 분배하기 위해 일부 문서에 +1 단락 추가\n",
    "    end_idx = start_idx + chunk_size + (1 if i < remainder else 0)\n",
    "\n",
    "    # 새로운 Word 문서 생성\n",
    "    new_doc = Document()\n",
    "    for para in paragraphs[start_idx:end_idx]:\n",
    "        new_doc.add_paragraph(para.text)\n",
    "\n",
    "    # 새로운 문서 저장 (파일명에 인덱스 번호 추가)\n",
    "    output_path = f\"./dataset_part_{i + 1}.docx\"\n",
    "    new_doc.save(output_path)\n",
    "\n",
    "    # 다음 문서의 시작 인덱스 설정\n",
    "    start_idx = end_idx\n",
    "\n",
    "print(\"dataset.docx 파일이 5개로 나누어 저장되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724f8a8-c609-4675-ab40-dc14260cb2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "ch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
