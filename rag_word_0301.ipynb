{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e06783-f083-424c-9ace-51f3c3bf5e00",
   "metadata": {},
   "source": [
    "### 1. 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacafc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==1.0.1 (from -r requirements.txt (line 1))\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting aiohappyeyeballs==2.4.3 (from -r requirements.txt (line 2))\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiohttp==3.10.10 (from -r requirements.txt (line 3))\n",
      "  Downloading aiohttp-3.10.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiosignal==1.3.1 (from -r requirements.txt (line 4))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting altair==5.4.1 (from -r requirements.txt (line 5))\n",
      "  Downloading altair-5.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting annotated-types==0.7.0 (from -r requirements.txt (line 6))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting anyio==4.6.2.post1 (from -r requirements.txt (line 7))\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting argon2-cffi==23.1.0 (from -r requirements.txt (line 8))\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting argon2-cffi-bindings==21.2.0 (from -r requirements.txt (line 9))\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting arrow==1.3.0 (from -r requirements.txt (line 10))\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting asgiref==3.8.1 (from -r requirements.txt (line 11))\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting asttokens==2.4.1 (from -r requirements.txt (line 12))\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting async-lru==2.0.4 (from -r requirements.txt (line 13))\n",
      "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting attrs==24.2.0 (from -r requirements.txt (line 14))\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting babel==2.16.0 (from -r requirements.txt (line 15))\n",
      "  Downloading babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff==2.2.1 (from -r requirements.txt (line 16))\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting bcrypt==4.2.0 (from -r requirements.txt (line 17))\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting beautifulsoup4==4.12.3 (from -r requirements.txt (line 18))\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bitsandbytes==0.44.1 (from -r requirements.txt (line 19))\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting bleach==6.1.0 (from -r requirements.txt (line 20))\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting blinker==1.8.2 (from -r requirements.txt (line 21))\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting build==1.2.2.post1 (from -r requirements.txt (line 22))\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting cachetools==5.5.0 (from -r requirements.txt (line 23))\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting certifi==2024.8.30 (from -r requirements.txt (line 24))\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cffi==1.17.1 (from -r requirements.txt (line 25))\n",
      "  Downloading cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting charset-normalizer==3.4.0 (from -r requirements.txt (line 26))\n",
      "  Downloading charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from -r requirements.txt (line 27))\n",
      "  Downloading chroma_hnswlib-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting chromadb==0.5.15 (from -r requirements.txt (line 28))\n",
      "  Downloading chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting click==8.1.7 (from -r requirements.txt (line 29))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting colorama==0.4.6 (from -r requirements.txt (line 30))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting coloredlogs==15.0.1 (from -r requirements.txt (line 31))\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (0.2.2)\n",
      "Collecting dataclasses-json==0.6.7 (from -r requirements.txt (line 33))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting debugpy==1.8.7 (from -r requirements.txt (line 34))\n",
      "  Downloading debugpy-1.8.7-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting decorator==5.1.1 (from -r requirements.txt (line 35))\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting defusedxml==0.7.1 (from -r requirements.txt (line 36))\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting Deprecated==1.2.14 (from -r requirements.txt (line 37))\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting docx2txt==0.8 (from -r requirements.txt (line 38))\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting durationpy==0.9 (from -r requirements.txt (line 39))\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting einops==0.8.0 (from -r requirements.txt (line 40))\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting executing==2.1.0 (from -r requirements.txt (line 41))\n",
      "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting faiss-cpu==1.9.0 (from -r requirements.txt (line 42))\n",
      "  Downloading faiss_cpu-1.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting fastapi==0.115.2 (from -r requirements.txt (line 43))\n",
      "  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting fastjsonschema==2.20.0 (from -r requirements.txt (line 44))\n",
      "  Downloading fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting filelock==3.16.1 (from -r requirements.txt (line 45))\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting flatbuffers==24.3.25 (from -r requirements.txt (line 46))\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting fonttools==4.55.0 (from -r requirements.txt (line 47))\n",
      "  Downloading fonttools-4.55.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
      "Collecting fpdf2==2.8.1 (from -r requirements.txt (line 48))\n",
      "  Downloading fpdf2-2.8.1-py2.py3-none-any.whl.metadata (63 kB)\n",
      "Collecting fqdn==1.5.1 (from -r requirements.txt (line 49))\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting frozenlist==1.4.1 (from -r requirements.txt (line 50))\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting fsspec==2024.9.0 (from -r requirements.txt (line 51))\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting git-filter-repo==2.47.0 (from -r requirements.txt (line 52))\n",
      "  Downloading git_filter_repo-2.47.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting gitdb==4.0.11 (from -r requirements.txt (line 53))\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting GitPython==3.1.43 (from -r requirements.txt (line 54))\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting google-auth==2.35.0 (from -r requirements.txt (line 55))\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos==1.65.0 (from -r requirements.txt (line 56))\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting greenlet==3.1.1 (from -r requirements.txt (line 57))\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting gritql==0.1.5 (from -r requirements.txt (line 58))\n",
      "  Downloading gritql-0.1.5-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting grpcio==1.67.0 (from -r requirements.txt (line 59))\n",
      "  Downloading grpcio-1.67.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting h11==0.14.0 (from -r requirements.txt (line 60))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httpcore==1.0.6 (from -r requirements.txt (line 61))\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting httptools==0.6.4 (from -r requirements.txt (line 62))\n",
      "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting httpx==0.27.2 (from -r requirements.txt (line 63))\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx-sse==0.4.0 (from -r requirements.txt (line 64))\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting huggingface-hub==0.25.2 (from -r requirements.txt (line 65))\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting humanfriendly==10.0 (from -r requirements.txt (line 66))\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting idna==3.10 (from -r requirements.txt (line 67))\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting importlib_metadata==8.4.0 (from -r requirements.txt (line 68))\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting importlib_resources==6.4.5 (from -r requirements.txt (line 69))\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting iniconfig==2.0.0 (from -r requirements.txt (line 70))\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (6.29.5)\n",
      "Collecting ipython==8.28.0 (from -r requirements.txt (line 72))\n",
      "  Downloading ipython-8.28.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting isoduration==20.11.0 (from -r requirements.txt (line 73))\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jedi==0.19.1 (from -r requirements.txt (line 74))\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting Jinja2==3.1.4 (from -r requirements.txt (line 75))\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib==1.4.2 (from -r requirements.txt (line 76))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting json5==0.9.25 (from -r requirements.txt (line 77))\n",
      "  Downloading json5-0.9.25-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jsonpatch==1.33 (from -r requirements.txt (line 78))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer==3.0.0 (from -r requirements.txt (line 79))\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonschema==4.23.0 (from -r requirements.txt (line 80))\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonschema-specifications==2024.10.1 (from -r requirements.txt (line 81))\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jupyter-events==0.10.0 (from -r requirements.txt (line 82))\n",
      "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyter-lsp==2.2.5 (from -r requirements.txt (line 83))\n",
      "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 84)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 85)) (5.7.2)\n",
      "Collecting jupyter_server==2.14.2 (from -r requirements.txt (line 86))\n",
      "  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyter_server_terminals==0.5.3 (from -r requirements.txt (line 87))\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting jupyterlab==4.2.5 (from -r requirements.txt (line 88))\n",
      "  Downloading jupyterlab-4.2.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting jupyterlab_pygments==0.3.0 (from -r requirements.txt (line 89))\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting jupyterlab_server==2.27.3 (from -r requirements.txt (line 90))\n",
      "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting keybert==0.8.5 (from -r requirements.txt (line 91))\n",
      "  Downloading keybert-0.8.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes==31.0.0 (from -r requirements.txt (line 92))\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain==0.3.12 (from -r requirements.txt (line 93))\n",
      "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-chroma==0.1.4 (from -r requirements.txt (line 94))\n",
      "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langchain-cli==0.0.35 (from -r requirements.txt (line 95))\n",
      "  Downloading langchain_cli-0.0.35-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting langchain-community==0.3.12 (from -r requirements.txt (line 96))\n",
      "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core==0.3.25 (from -r requirements.txt (line 97))\n",
      "  Downloading langchain_core-0.3.25-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-huggingface==0.1.0 (from -r requirements.txt (line 98))\n",
      "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain-text-splitters==0.3.3 (from -r requirements.txt (line 99))\n",
      "  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langserve==0.3.0 (from -r requirements.txt (line 100))\n",
      "  Downloading langserve-0.3.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting langsmith==0.1.135 (from -r requirements.txt (line 101))\n",
      "  Downloading langsmith-0.1.135-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lxml==5.3.0 (from -r requirements.txt (line 102))\n",
      "  Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting Markdown==3.7 (from -r requirements.txt (line 103))\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting markdown-it-py==3.0.0 (from -r requirements.txt (line 104))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting MarkupSafe==3.0.1 (from -r requirements.txt (line 105))\n",
      "  Downloading MarkupSafe-3.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting marshmallow==3.22.0 (from -r requirements.txt (line 106))\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 107)) (0.1.7)\n",
      "Collecting mdurl==0.1.2 (from -r requirements.txt (line 108))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting mistune==3.0.2 (from -r requirements.txt (line 109))\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3==5.0.1 (from -r requirements.txt (line 110))\n",
      "  Downloading mmh3-5.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting monotonic==1.6 (from -r requirements.txt (line 111))\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mpmath==1.3.0 (from -r requirements.txt (line 112))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting multidict==6.1.0 (from -r requirements.txt (line 113))\n",
      "  Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting mypy-extensions==1.0.0 (from -r requirements.txt (line 114))\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting narwhals==1.9.4 (from -r requirements.txt (line 115))\n",
      "  Downloading narwhals-1.9.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting nbclient==0.10.0 (from -r requirements.txt (line 116))\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbconvert==7.16.4 (from -r requirements.txt (line 117))\n",
      "  Downloading nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting nbformat==5.10.4 (from -r requirements.txt (line 118))\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 119)) (1.6.0)\n",
      "Collecting networkx==3.4.1 (from -r requirements.txt (line 120))\n",
      "  Downloading networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting notebook_shim==0.2.4 (from -r requirements.txt (line 121))\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 122))\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from -r requirements.txt (line 123))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from -r requirements.txt (line 124))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from -r requirements.txt (line 125))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from -r requirements.txt (line 126))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from -r requirements.txt (line 127))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from -r requirements.txt (line 128))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from -r requirements.txt (line 129))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from -r requirements.txt (line 130))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from -r requirements.txt (line 131))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from -r requirements.txt (line 132))\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.77 (from -r requirements.txt (line 133))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from -r requirements.txt (line 134))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting oauthlib==3.2.2 (from -r requirements.txt (line 135))\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting onnxruntime==1.19.2 (from -r requirements.txt (line 136))\n",
      "  Downloading onnxruntime-1.19.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-api==1.27.0 (from -r requirements.txt (line 137))\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from -r requirements.txt (line 138))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.27.0 (from -r requirements.txt (line 139))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from -r requirements.txt (line 140))\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from -r requirements.txt (line 141))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi==0.48b0 (from -r requirements.txt (line 142))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from -r requirements.txt (line 143))\n",
      "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk==1.27.0 (from -r requirements.txt (line 144))\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from -r requirements.txt (line 145))\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from -r requirements.txt (line 146))\n",
      "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting orjson==3.10.7 (from -r requirements.txt (line 147))\n",
      "  Downloading orjson-3.10.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Collecting overrides==7.7.0 (from -r requirements.txt (line 148))\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting packaging==24.1 (from -r requirements.txt (line 149))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas==2.2.3 (from -r requirements.txt (line 150))\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pandocfilters==1.5.1 (from -r requirements.txt (line 151))\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 152)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 153)) (4.9.0)\n",
      "Collecting pillow==10.4.0 (from -r requirements.txt (line 154))\n",
      "  Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 155)) (4.3.6)\n",
      "Collecting pluggy==1.5.0 (from -r requirements.txt (line 156))\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting posthog==3.7.0 (from -r requirements.txt (line 157))\n",
      "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting prometheus_client==0.21.0 (from -r requirements.txt (line 158))\n",
      "  Downloading prometheus_client-0.21.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting prompt_toolkit==3.0.48 (from -r requirements.txt (line 159))\n",
      "  Downloading prompt_toolkit-3.0.48-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting propcache==0.2.0 (from -r requirements.txt (line 160))\n",
      "  Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting protobuf==4.25.5 (from -r requirements.txt (line 161))\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting psutil==6.0.0 (from -r requirements.txt (line 162))\n",
      "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 163)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 164)) (0.2.3)\n",
      "Collecting pyarrow==17.0.0 (from -r requirements.txt (line 165))\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pyasn1==0.6.1 (from -r requirements.txt (line 166))\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pyasn1_modules==0.4.1 (from -r requirements.txt (line 167))\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pycparser==2.22 (from -r requirements.txt (line 168))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting pydantic==2.9.2 (from -r requirements.txt (line 169))\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pydantic-settings==2.5.2 (from -r requirements.txt (line 170))\n",
      "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pydantic_core==2.23.4 (from -r requirements.txt (line 171))\n",
      "  Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting pydeck==0.9.1 (from -r requirements.txt (line 172))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting Pygments==2.18.0 (from -r requirements.txt (line 173))\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting PyMuPDF==1.24.11 (from -r requirements.txt (line 174))\n",
      "  Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting PyPika==0.48.9 (from -r requirements.txt (line 175))\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyproject_hooks==1.2.0 (from -r requirements.txt (line 176))\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pytest==8.3.3 (from -r requirements.txt (line 177))\n",
      "  Downloading pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 178)) (2.9.0.post0)\n",
      "Collecting python-docx==1.1.2 (from -r requirements.txt (line 179))\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 180))\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting python-json-logger==2.0.7 (from -r requirements.txt (line 181))\n",
      "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pytz==2024.2 (from -r requirements.txt (line 182))\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML==6.0.2 (from -r requirements.txt (line 183))\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pyzmq==26.2.0 (from -r requirements.txt (line 184))\n",
      "  Downloading pyzmq-26.2.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting referencing==0.35.1 (from -r requirements.txt (line 185))\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting regex==2024.9.11 (from -r requirements.txt (line 186))\n",
      "  Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests==2.32.3 (from -r requirements.txt (line 187))\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting requests-oauthlib==2.0.0 (from -r requirements.txt (line 188))\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests-toolbelt==1.0.0 (from -r requirements.txt (line 189))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting rfc3339-validator==0.1.4 (from -r requirements.txt (line 190))\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator==0.1.1 (from -r requirements.txt (line 191))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting rich==13.9.2 (from -r requirements.txt (line 192))\n",
      "  Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rpds-py==0.20.0 (from -r requirements.txt (line 193))\n",
      "  Downloading rpds_py-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting rsa==4.9 (from -r requirements.txt (line 194))\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting safetensors==0.4.5 (from -r requirements.txt (line 195))\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting scikit-learn==1.5.2 (from -r requirements.txt (line 196))\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting scipy==1.14.1 (from -r requirements.txt (line 197))\n",
      "  Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting Send2Trash==1.8.3 (from -r requirements.txt (line 198))\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting sentence-transformers==3.2.0 (from -r requirements.txt (line 199))\n",
      "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setuptools==75.2.0 (from -r requirements.txt (line 200))\n",
      "  Downloading setuptools-75.2.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting shellingham==1.5.4 (from -r requirements.txt (line 201))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting six==1.16.0 (from -r requirements.txt (line 202))\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting smmap==5.0.1 (from -r requirements.txt (line 203))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting sniffio==1.3.1 (from -r requirements.txt (line 204))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting soupsieve==2.6 (from -r requirements.txt (line 205))\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting SQLAlchemy==2.0.36 (from -r requirements.txt (line 206))\n",
      "  Downloading SQLAlchemy-2.0.36-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting sse-starlette==1.8.2 (from -r requirements.txt (line 207))\n",
      "  Downloading sse_starlette-1.8.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 208)) (0.6.3)\n",
      "Collecting starlette==0.40.0 (from -r requirements.txt (line 209))\n",
      "  Downloading starlette-0.40.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting streamlit==1.39.0 (from -r requirements.txt (line 210))\n",
      "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting streamlit-chat==0.1.1 (from -r requirements.txt (line 211))\n",
      "  Downloading streamlit_chat-0.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting sympy==1.13.3 (from -r requirements.txt (line 212))\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tenacity==8.5.0 (from -r requirements.txt (line 213))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting terminado==0.18.1 (from -r requirements.txt (line 214))\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting threadpoolctl==3.5.0 (from -r requirements.txt (line 215))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken==0.8.0 (from -r requirements.txt (line 216))\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tinycss2==1.3.0 (from -r requirements.txt (line 217))\n",
      "  Downloading tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tokenizers==0.20.1 (from -r requirements.txt (line 218))\n",
      "  Downloading tokenizers-0.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting toml==0.10.2 (from -r requirements.txt (line 219))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tomlkit==0.13.2 (from -r requirements.txt (line 220))\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting torch==2.4.1 (from -r requirements.txt (line 221))\n",
      "  Downloading torch-2.4.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting tornado==6.4.1 (from -r requirements.txt (line 222))\n",
      "  Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting tqdm==4.66.5 (from -r requirements.txt (line 223))\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 224)) (5.14.3)\n",
      "Collecting transformers==4.45.2 (from -r requirements.txt (line 225))\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting triton==3.0.0 (from -r requirements.txt (line 226))\n",
      "  Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting typer==0.9.4 (from -r requirements.txt (line 227))\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting types-python-dateutil==2.9.0.20241003 (from -r requirements.txt (line 228))\n",
      "  Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting typing-inspect==0.9.0 (from -r requirements.txt (line 229))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting typing_extensions==4.12.2 (from -r requirements.txt (line 230))\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tzdata==2024.2 (from -r requirements.txt (line 231))\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting uri-template==1.3.0 (from -r requirements.txt (line 232))\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting urllib3==2.2.3 (from -r requirements.txt (line 233))\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting uvicorn==0.32.0 (from -r requirements.txt (line 234))\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting uvloop==0.21.0 (from -r requirements.txt (line 235))\n",
      "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchdog==5.0.3 (from -r requirements.txt (line 236))\n",
      "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting watchfiles==0.24.0 (from -r requirements.txt (line 237))\n",
      "  Downloading watchfiles-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/chae/faiss_env/lib/python3.12/site-packages (from -r requirements.txt (line 238)) (0.2.13)\n",
      "Collecting webcolors==24.8.0 (from -r requirements.txt (line 239))\n",
      "  Downloading webcolors-24.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting webencodings==0.5.1 (from -r requirements.txt (line 240))\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting websocket-client==1.8.0 (from -r requirements.txt (line 241))\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting websockets==13.1 (from -r requirements.txt (line 242))\n",
      "  Downloading websockets-13.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting wrapt==1.16.0 (from -r requirements.txt (line 243))\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting yarl==1.15.4 (from -r requirements.txt (line 244))\n",
      "  Downloading yarl-1.15.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting zipp==3.20.2 (from -r requirements.txt (line 245))\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'langsmith' candidate (version 0.1.135 at https://files.pythonhosted.org/packages/f7/d8/529992f20c16271c5864be1d6a89b060e483f098c7d02138564e7b13ffe7/langsmith-0.1.135-py3-none-any.whl (from https://pypi.org/simple/langsmith/) (requires-python:<4.0,>=3.8.1))\n",
      "Reason for being yanked: <none given>\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiohttp-3.10.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.1/658.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Downloading chroma_hnswlib-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-0.5.15-py3-none-any.whl (607 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.0/607.0 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading debugpy-1.8.7-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading faiss_cpu-1.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n",
      "Downloading fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading fonttools-4.55.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fpdf2-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading git_filter_repo-2.47.0-py3-none-any.whl (76 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.1/613.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gritql-0.1.5-py2.py3-none-any.whl (5.2 kB)\n",
      "Downloading grpcio-1.67.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading ipython-8.28.0-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.5/819.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading json5-0.9.25-py3-none-any.whl (30 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Downloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading jupyterlab-4.2.5-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Downloading keybert-0.8.5-py3-none-any.whl (37 kB)\n",
      "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.12-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
      "Downloading langchain_cli-0.0.35-py3-none-any.whl (117 kB)\n",
      "Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.25-py3-none-any.whl (411 kB)\n",
      "Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_text_splitters-0.3.3-py3-none-any.whl (27 kB)\n",
      "Downloading langserve-0.3.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.135-py3-none-any.whl (295 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Downloading mmh3-5.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading narwhals-1.9.4-py3-none-any.whl (188 kB)\n",
      "Downloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading onnxruntime-1.19.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading orjson-3.10.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading prometheus_client-0.21.0-py3-none-any.whl (54 kB)\n",
      "Downloading prompt_toolkit-3.0.48-py3-none-any.whl (386 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
      "Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
      "Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading pytest-8.3.3-py3-none-any.whl (342 kB)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyzmq-26.2.0-cp312-cp312-manylinux_2_28_x86_64.whl (860 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m860.6/860.6 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (797 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.0/797.0 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rich-13.9.2-py3-none-any.whl (242 kB)\n",
      "Downloading rpds_py-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (357 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (434 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Downloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n",
      "Downloading setuptools-75.2.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sse_starlette-1.8.2-py3-none-any.whl (8.9 kB)\n",
      "Downloading starlette-0.40.0-py3-none-any.whl (73 kB)\n",
      "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading streamlit_chat-0.1.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading tokenizers-0.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading torch-2.4.1-cp312-cp312-manylinux1_x86_64.whl (797.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.0/797.0 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading watchfiles-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
      "Downloading webcolors-24.8.0-py3-none-any.whl (15 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-13.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n",
      "Downloading yarl-1.15.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (331 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Building wheels for collected packages: docx2txt, PyPika\n",
      "  Building wheel for docx2txt (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3992 sha256=d380bb947c676b35b6488da0c6a5c8d80d9c714f5d0467311cafddf87c09b87a\n",
      "  Stored in directory: /home/chae/.cache/pip/wheels/6f/81/48/001bbc0109c15e18c009eee300022f42d1e070e54f1d00b218\n",
      "  Building wheel for PyPika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyPika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53770 sha256=e115d00c574c707dd2a83529c679b9e1fb0e8ea0bf1affd2c577aafe6a1b2da4\n",
      "  Stored in directory: /home/chae/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built docx2txt PyPika\n",
      "Installing collected packages: webencodings, pytz, PyPika, mpmath, monotonic, gritql, flatbuffers, fastjsonschema, durationpy, docx2txt, zipp, wrapt, websockets, websocket-client, webcolors, watchdog, uvloop, urllib3, uri-template, tzdata, typing_extensions, types-python-dateutil, tqdm, tornado, tomlkit, toml, tinycss2, threadpoolctl, tenacity, sympy, soupsieve, sniffio, smmap, six, shellingham, setuptools, Send2Trash, safetensors, rpds-py, rfc3986-validator, regex, pyzmq, PyYAML, python-json-logger, python-dotenv, pyproject_hooks, PyMuPDF, Pygments, pycparser, pyasn1, psutil, protobuf, propcache, prompt_toolkit, prometheus_client, pluggy, pillow, pandocfilters, packaging, overrides, orjson, opentelemetry-util-http, oauthlib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, narwhals, mypy-extensions, multidict, mmh3, mistune, mdurl, MarkupSafe, Markdown, lxml, jupyterlab_pygments, jsonpointer, json5, joblib, jedi, iniconfig, importlib_resources, idna, humanfriendly, httpx-sse, httptools, h11, grpcio, greenlet, git-filter-repo, fsspec, frozenlist, fqdn, fonttools, filelock, executing, einops, defusedxml, decorator, debugpy, colorama, click, charset-normalizer, certifi, cachetools, blinker, bcrypt, backoff, babel, attrs, async-lru, asgiref, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspect, typer, triton, terminado, SQLAlchemy, scipy, rsa, rfc3339-validator, requests, referencing, python-docx, pytest, pydantic_core, pyasn1_modules, pyarrow, opentelemetry-proto, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, markdown-it-py, jsonpatch, Jinja2, importlib_metadata, httpcore, googleapis-common-protos, gitdb, fpdf2, faiss-cpu, Deprecated, coloredlogs, chroma-hnswlib, cffi, build, bleach, beautifulsoup4, asttokens, anyio, aiosignal, watchfiles, tiktoken, starlette, scikit-learn, rich, requests-toolbelt, requests-oauthlib, pydeck, pydantic, posthog, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, nvidia-cusolver-cu12, jupyter_server_terminals, jsonschema-specifications, huggingface-hub, httpx, google-auth, GitPython, dataclasses-json, arrow, argon2-cffi-bindings, aiohttp, torch, tokenizers, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-instrumentation, langsmith, kubernetes, jsonschema, isoduration, ipython, fastapi, argon2-cffi, transformers, sse-starlette, opentelemetry-sdk, opentelemetry-instrumentation-asgi, nbformat, langchain-core, bitsandbytes, altair, accelerate, streamlit, sentence-transformers, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, nbclient, langserve, langchain-text-splitters, jupyter-events, streamlit-chat, nbconvert, langchain-huggingface, langchain, keybert, chromadb, langchain-community, langchain-cli, langchain-chroma, jupyter_server, notebook_shim, jupyterlab_server, jupyter-lsp, jupyterlab\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.4.2\n",
      "    Uninstalling tornado-6.4.2:\n",
      "      Successfully uninstalled tornado-6.4.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 26.2.1\n",
      "    Uninstalling pyzmq-26.2.1:\n",
      "      Successfully uninstalled pyzmq-26.2.1\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.19.1\n",
      "    Uninstalling Pygments-2.19.1:\n",
      "      Successfully uninstalled Pygments-2.19.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 7.0.0\n",
      "    Uninstalling psutil-7.0.0:\n",
      "      Successfully uninstalled psutil-7.0.0\n",
      "  Attempting uninstall: prompt_toolkit\n",
      "    Found existing installation: prompt_toolkit 3.0.50\n",
      "    Uninstalling prompt_toolkit-3.0.50:\n",
      "      Successfully uninstalled prompt_toolkit-3.0.50\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.19.2\n",
      "    Uninstalling jedi-0.19.2:\n",
      "      Successfully uninstalled jedi-0.19.2\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 2.2.0\n",
      "    Uninstalling executing-2.2.0:\n",
      "      Successfully uninstalled executing-2.2.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.2.1\n",
      "    Uninstalling decorator-5.2.1:\n",
      "      Successfully uninstalled decorator-5.2.1\n",
      "  Attempting uninstall: debugpy\n",
      "    Found existing installation: debugpy 1.8.12\n",
      "    Uninstalling debugpy-1.8.12:\n",
      "      Successfully uninstalled debugpy-1.8.12\n",
      "  Attempting uninstall: asttokens\n",
      "    Found existing installation: asttokens 3.0.0\n",
      "    Uninstalling asttokens-3.0.0:\n",
      "      Successfully uninstalled asttokens-3.0.0\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 9.0.0\n",
      "    Uninstalling ipython-9.0.0:\n",
      "      Successfully uninstalled ipython-9.0.0\n",
      "Successfully installed Deprecated-1.2.14 GitPython-3.1.43 Jinja2-3.1.4 Markdown-3.7 MarkupSafe-3.0.1 PyMuPDF-1.24.11 PyPika-0.48.9 PyYAML-6.0.2 Pygments-2.18.0 SQLAlchemy-2.0.36 Send2Trash-1.8.3 accelerate-1.0.1 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 altair-5.4.1 annotated-types-0.7.0 anyio-4.6.2.post1 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 asgiref-3.8.1 asttokens-2.4.1 async-lru-2.0.4 attrs-24.2.0 babel-2.16.0 backoff-2.2.1 bcrypt-4.2.0 beautifulsoup4-4.12.3 bitsandbytes-0.44.1 bleach-6.1.0 blinker-1.8.2 build-1.2.2.post1 cachetools-5.5.0 certifi-2024.8.30 cffi-1.17.1 charset-normalizer-3.4.0 chroma-hnswlib-0.7.6 chromadb-0.5.15 click-8.1.7 colorama-0.4.6 coloredlogs-15.0.1 dataclasses-json-0.6.7 debugpy-1.8.7 decorator-5.1.1 defusedxml-0.7.1 docx2txt-0.8 durationpy-0.9 einops-0.8.0 executing-2.1.0 faiss-cpu-1.9.0 fastapi-0.115.2 fastjsonschema-2.20.0 filelock-3.16.1 flatbuffers-24.3.25 fonttools-4.55.0 fpdf2-2.8.1 fqdn-1.5.1 frozenlist-1.4.1 fsspec-2024.9.0 git-filter-repo-2.47.0 gitdb-4.0.11 google-auth-2.35.0 googleapis-common-protos-1.65.0 greenlet-3.1.1 gritql-0.1.5 grpcio-1.67.0 h11-0.14.0 httpcore-1.0.6 httptools-0.6.4 httpx-0.27.2 httpx-sse-0.4.0 huggingface-hub-0.25.2 humanfriendly-10.0 idna-3.10 importlib_metadata-8.4.0 importlib_resources-6.4.5 iniconfig-2.0.0 ipython-8.28.0 isoduration-20.11.0 jedi-0.19.1 joblib-1.4.2 json5-0.9.25 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter_server-2.14.2 jupyter_server_terminals-0.5.3 jupyterlab-4.2.5 jupyterlab_pygments-0.3.0 jupyterlab_server-2.27.3 keybert-0.8.5 kubernetes-31.0.0 langchain-0.3.12 langchain-chroma-0.1.4 langchain-cli-0.0.35 langchain-community-0.3.12 langchain-core-0.3.25 langchain-huggingface-0.1.0 langchain-text-splitters-0.3.3 langserve-0.3.0 langsmith-0.1.135 lxml-5.3.0 markdown-it-py-3.0.0 marshmallow-3.22.0 mdurl-0.1.2 mistune-3.0.2 mmh3-5.0.1 monotonic-1.6 mpmath-1.3.0 multidict-6.1.0 mypy-extensions-1.0.0 narwhals-1.9.4 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 networkx-3.4.1 notebook_shim-0.2.4 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 oauthlib-3.2.2 onnxruntime-1.19.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.10.7 overrides-7.7.0 packaging-24.1 pandas-2.2.3 pandocfilters-1.5.1 pillow-10.4.0 pluggy-1.5.0 posthog-3.7.0 prometheus_client-0.21.0 prompt_toolkit-3.0.48 propcache-0.2.0 protobuf-4.25.5 psutil-6.0.0 pyarrow-17.0.0 pyasn1-0.6.1 pyasn1_modules-0.4.1 pycparser-2.22 pydantic-2.9.2 pydantic-settings-2.5.2 pydantic_core-2.23.4 pydeck-0.9.1 pyproject_hooks-1.2.0 pytest-8.3.3 python-docx-1.1.2 python-dotenv-1.0.1 python-json-logger-2.0.7 pytz-2024.2 pyzmq-26.2.0 referencing-0.35.1 regex-2024.9.11 requests-2.32.3 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rich-13.9.2 rpds-py-0.20.0 rsa-4.9 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.2.0 setuptools-75.2.0 shellingham-1.5.4 six-1.16.0 smmap-5.0.1 sniffio-1.3.1 soupsieve-2.6 sse-starlette-1.8.2 starlette-0.40.0 streamlit-1.39.0 streamlit-chat-0.1.1 sympy-1.13.3 tenacity-8.5.0 terminado-0.18.1 threadpoolctl-3.5.0 tiktoken-0.8.0 tinycss2-1.3.0 tokenizers-0.20.1 toml-0.10.2 tomlkit-0.13.2 torch-2.4.1 tornado-6.4.1 tqdm-4.66.5 transformers-4.45.2 triton-3.0.0 typer-0.9.4 types-python-dateutil-2.9.0.20241003 typing-inspect-0.9.0 typing_extensions-4.12.2 tzdata-2024.2 uri-template-1.3.0 urllib3-2.2.3 uvicorn-0.32.0 uvloop-0.21.0 watchdog-5.0.3 watchfiles-0.24.0 webcolors-24.8.0 webencodings-0.5.1 websocket-client-1.8.0 websockets-13.1 wrapt-1.16.0 yarl-1.15.4 zipp-3.20.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt  # 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f425499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # PyTorch 버전\n",
    "print(torch.version.cuda)  # PyTorch가 사용하는 CUDA 버전\n",
    "print(torch.cuda.is_available())  # GPU 사용 가능 여부\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d49d96-9721-43a6-8482-9158d25c93fe",
   "metadata": {},
   "source": [
    "### 2. 문서 split 및 Chroma를 활용한 vector store 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60d82f23-0f73-4879-8a69-46d5237a47b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로그인 상태입니다. 사용자: chaeeee\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(f\"로그인 상태입니다. 사용자: {user_info['name']}\")\n",
    "except Exception as e:\n",
    "    print(\"로그인되지 않았거나 토큰이 유효하지 않습니다.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98ea6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import os, json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. JSON 파일 경로 설정\n",
    "json_path = \"./json_data.json\"  # 단일 JSON 파일 경로\n",
    "\n",
    "# 2. JSON 데이터 불러오기\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "# 3. {}를 기준으로 JSON 데이터 분할 및 Document 객체 생성\n",
    "documents = []\n",
    "\n",
    "for data in tqdm(all_data, desc=\"Generating Documents\", unit=\"entry\", ncols=80):\n",
    "    metadata = {\n",
    "        \"title\": data.get('title', 'N/A'),\n",
    "        \"artist\": data.get('artist', 'N/A'),\n",
    "        \"year\": data.get('year', 'N/A'),\n",
    "        \"read_count\": data.get('read_count', 0)\n",
    "    }\n",
    "\n",
    "    # JSON 데이터의 각 항목을 Document 객체로 변환\n",
    "    doc_content = json.dumps(data, ensure_ascii=False, indent=4)\n",
    "    documents.append(Document(\n",
    "        page_content=doc_content.strip(),\n",
    "        metadata=metadata\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c477cb-437e-4c75-b35d-f42641901204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 텍스트 분할 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=128  # 오버랩 설정\n",
    ")\n",
    "\n",
    "# 단일 DOCX 파일 로드\n",
    "file_path = \"./dataset2.docx\"  # 파일 경로를 이곳에 입력하세요\n",
    "loader = Docx2txtLoader(file_path)\n",
    "raw_text = loader.load()[0].page_content  # DOCX 파일의 전체 텍스트 가져오기\n",
    "print(\"raw_text 개수: \", len(raw_text))\n",
    "      \n",
    "# 작품명을 기준으로 텍스트 분리\n",
    "def split_artwork_documents(doc_text):\n",
    "    artworks = doc_text.split(\"\\n\\n작품명:\")  # 작품을 구분\n",
    "    documents = []\n",
    "\n",
    "    for artwork in artworks:\n",
    "        if artwork.strip():  # 빈 텍스트 제외\n",
    "            # \"작품명:\" 추가로 일관성 유지\n",
    "            doc_content = \"작품명:\" + artwork if not artwork.startswith(\"작품명:\") else artwork\n",
    "\n",
    "            # 메타데이터 초기화\n",
    "            metadata = {}\n",
    "            lines = doc_content.split(\"\\n\")  # 텍스트 줄 단위로 나누기\n",
    "\n",
    "            # 메타데이터 추출\n",
    "            for line in lines:\n",
    "                if line.startswith(\"작품명:\"):\n",
    "                    metadata[\"작품명\"] = line.replace(\"작품명:\", \"\").strip()\n",
    "                elif line.startswith(\"작가:\"):\n",
    "                    metadata[\"작가\"] = line.replace(\"작가:\", \"\").strip()\n",
    "                elif line.startswith(\"제작 연도:\"):\n",
    "                    metadata[\"제작 연도\"] = line.replace(\"제작 연도:\", \"\").strip()\n",
    "                elif line.startswith(\"카테고리:\"):\n",
    "                    metadata[\"카테고리\"] = line.replace(\"카테고리:\", \"\").strip()\n",
    "\n",
    "            # Document 객체 생성\n",
    "            documents.append(Document(\n",
    "                page_content=doc_content.strip(),\n",
    "                metadata=metadata\n",
    "            ))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "# 작품별 Document 생성\n",
    "documents = split_artwork_documents(raw_text)\n",
    "\n",
    "# 생성된 작품별 Document에 대해 추가 청크 분할\n",
    "chunked_documents = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    for chunk in chunks:\n",
    "        # 청크에 원래 Document의 메타데이터 유지\n",
    "        chunked_documents.append(Document(\n",
    "            page_content=chunk,\n",
    "            metadata=doc.metadata  # 원본 메타데이터 복사\n",
    "        ))\n",
    "\n",
    "print(f\"총 문서 수: {len(chunked_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ddbe99-f6c8-4580-92b6-503253277965",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[11001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102d292-48e8-4eeb-9280-79dc003ed796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 Document 객체의 텍스트 길이 확인\n",
    "len(documents[11001].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec14a4-2333-4381-8152-dc30d011ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800자를 초과하는 Document 개수 세기\n",
    "over_800_count = sum(1 for doc in documents if len(doc.page_content) > 800)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"800자를 초과하는 Document 개수: {over_800_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ef186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss  # FAISS 라이브러리 필요\n",
    "\n",
    "# 1. 임베딩 초기화\n",
    "embedding_model = SentenceTransformer(\"nlpai-lab/KURE-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce036d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문서 데이터와 메타데이터 분리\n",
    "texts = [doc.page_content for doc in documents]  # 문서 텍스트\n",
    "metadatas = [doc.metadata for doc in documents]  # 문서 메타데이터\n",
    "\n",
    "# 3. 문서 임베딩 생성\n",
    "embeddings = embedding_model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23144ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. FAISS 인덱스 생성\n",
    "embedding_dim = embeddings.shape[1]  # 벡터 차원 확인\n",
    "faiss_index = faiss.IndexFlatL2(embedding_dim)  # L2 거리 기반 인덱스\n",
    "faiss_index.add(embeddings)  # 벡터 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba322337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# 5. Docstore 생성\n",
    "# 각 문서에 고유 ID를 부여해 InMemoryDocstore 생성\n",
    "docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(documents)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd078ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. FAISS 벡터스토어 생성\n",
    "def embed_query(text):\n",
    "    return embedding_model.encode([text])[0]  # 단일 쿼리 텍스트를 임베딩\n",
    "\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(documents))}\n",
    "\n",
    "faiss_db = FAISS(\n",
    "    embedding_function=embed_query,\n",
    "    index=faiss_index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "# 7. FAISS 데이터베이스 저장\n",
    "faiss_db.save_local(\"./faiss_artworks_0114_docx\")\n",
    "print(\"FAISS 데이터베이스가 성공적으로 저장되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 검색 테스트\n",
    "query = \"박승무의 설경\"\n",
    "results = faiss_db.similarity_search(query, k=5)\n",
    "\n",
    "# 10. 검색 결과 출력\n",
    "for result in results:\n",
    "    print(\"문서 텍스트:\", result.page_content)\n",
    "    print(\"문서 메타데이터:\", result.metadata)\n",
    "    print('=------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591c49d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chae/faiss_env/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "You try to use a model that was created with version 3.3.1, however, your version is 3.2.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"nlpai-lab/KURE-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b6a00995-3f64-49d2-8b0f-033e8b640085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 데이터베이스가 성공적으로 로드되었습니다!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# 기존 DB 로드 \n",
    "persist_directory = \"./faiss_artworks_0114\"\n",
    "\n",
    "try:\n",
    "    faiss_db = FAISS.load_local(\n",
    "        folder_path=persist_directory,\n",
    "        embeddings=embedding_model,\n",
    "        allow_dangerous_deserialization=True  # 신뢰할 수 있는 소스에서만 사용\n",
    "    )\n",
    "    \n",
    "    # embedding_function 수정\n",
    "    faiss_db.embedding_function = lambda text: (\n",
    "        embedding_model.encode(text) if isinstance(text, str) else embedding_model.encode(str(text))\n",
    "    )\n",
    "    \n",
    "    print(\"FAISS 데이터베이스가 성공적으로 로드되었습니다!\")\n",
    "except Exception as e:\n",
    "    print(f\"FAISS 데이터베이스 로드 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4607b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4bit 양자화 활성화\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # 계산 타입 설정 (float16이 일반적)\n",
    "    bnb_4bit_use_double_quant=True,  # 더블 양자화 사용 (메모리 절약)\n",
    "    bnb_4bit_quant_type=\"nf4\",  # NormalFloat4 (NF4) 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0bffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4-bit 양자화 활성화\n",
    "    bnb_4bit_compute_dtype=\"float16\",  # 계산 정밀도 설정\n",
    "    bnb_4bit_quant_type=\"nf4\",  # NF4 양자화 방식 사용 (효율적)\n",
    "    bnb_4bit_use_double_quant=True,  # 이중 양자화 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40645602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:27<00:00,  6.98s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "\n",
    "# 모델과 토크나이저 로드 (CUDA 사용)\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,  # ✅ 올바른 양자화 설정 적용\n",
    "    device_map=\"auto\",  # ✅ 자동 GPU 배치\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6446fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_301791/1315975019.py:15: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 파이프라인 생성\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,  # 생성할 최대 토큰 수 증가\n",
    "    do_sample=True,        # 샘플링 활성화\n",
    "    temperature=0.1,      \n",
    "    top_k=50,             \n",
    "    repetition_penalty=1.05\n",
    ")\n",
    "# LangChain의 HuggingFacePipeline 사용\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5890507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "deepseek_template = \"\"\"\n",
    "<|system|>\n",
    "You are a friendly chatbot specializing in artworks and general conversations.\n",
    "Your primary role is to answer questions **accurately based on the provided document (context)**. \n",
    "If the requested information is not found in the document, respond with:\n",
    "\"문서에 해당 정보가 없습니다.\" \n",
    "\n",
    "However, if the question is a general conversation or does not relate to the document, you should respond naturally as a conversational chatbot. \n",
    "You can talk about art history, artists, exhibitions, and general topics such as daily life, technology, and culture. \n",
    "Maintain a friendly and engaging tone, ensuring all responses are written in Korean.\n",
    "Use **beautiful Markdown formatting** (headings, bullet points, **bold** or *italic* text) to enhance readability.\n",
    "You must include the artwork number in your response.\n",
    "\n",
    "<|context|>\n",
    "{context}\n",
    "\n",
    "<|user|>\n",
    "Question: {question}\n",
    "\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exaone_template = '''\n",
    "<|system|>\n",
    "You are an AI assistant tasked with refining and polishing the provided logical reasoning into a final answer in Korean.  \n",
    "Your role is to produce a clear, concise, and well-structured response that maintains the original meaning and key details.  \n",
    "Ensure that your final answer is written in Korean and uses **beautiful Markdown formatting** (e.g., headings, bullet points, **bold** or *italic* text) to enhance readability.  \n",
    "Focus solely on refining the content without adding any new information.\n",
    "\n",
    "<|reasoning|>\n",
    "{reasoning}\n",
    "\n",
    "<|user|>\n",
    "Based on the above reasoning, please generate a refined and final answer in Korean.\n",
    "\n",
    "<|assistant|>\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# DeepSeek 템플릿 생성\n",
    "deepseek_prompt = ChatPromptTemplate.from_template(deepseek_template)\n",
    "\n",
    "# EXAONE 템플릿 생성\n",
    "exaone_prompt = ChatPromptTemplate.from_template(exaone_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "747bc299-6dde-4a89-beeb-0f330ac28baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = '''\n",
    "<|system|>\n",
    "You are a friendly chatbot specializing in artworks and general conversations.\n",
    "Your primary role is to answer questions strictly based on the information provided in the document (context). \n",
    "If the requested information is not found in the document, respond with:\n",
    "\"The document does not contain this information.\" \n",
    "\n",
    "However, if the question is a general conversation or does not relate to the document, you should respond naturally as a conversational chatbot. \n",
    "You can talk about art history, artists, exhibitions, and general topics such as daily life, technology, and culture. \n",
    "Maintain a friendly and engaging tone, ensuring all responses are written in Korean.\n",
    "Use **beautiful Markdown formatting** (headings, bullet points, bold or italic text) to enhance readability.\n",
    "You must include artwork number.\n",
    "\n",
    "<|context|>\n",
    "{context}\n",
    "\n",
    "<|user|>\n",
    "Question: {question}\n",
    "\n",
    "<|assistant|>\n",
    "'''\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "137611cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_db.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                # 검색 결과 개수\n",
    "        \"fetch_k\": 15,         # 더 많은 결과 가져오기\n",
    "        \"mmr\": True,           # MMR 활성화\n",
    "        \"mmr_beta\": 0.3      # 다양성과 관련성 간 균형\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4e8023be-86e0-487d-b773-df209eac7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MarkdownOutputParser:\n",
    "    \"\"\"Enhanced Markdown parser with additional formatting options.\"\"\"\n",
    "\n",
    "    def __call__(self, llm_output):\n",
    "        \"\"\"Extracts the assistant's response from after the </think> tag and formats it in Markdown.\"\"\"\n",
    "        if not llm_output or llm_output.strip() == \"\":\n",
    "            return \"❌ 모델에서 응답을 생성하지 못했습니다.\"\n",
    "\n",
    "        # \"</think>\" 이후 텍스트 추출\n",
    "        match = re.search(r\"</think>\\s*(.*)\", llm_output, re.DOTALL)\n",
    "        extracted_text = match.group(1).strip() if match else llm_output.strip()\n",
    "\n",
    "        # Markdown 형식 적용\n",
    "        formatted_output = f\"\"\"\n",
    "### **🔹 모델 응답 결과**\n",
    "\n",
    "{extracted_text}\n",
    "\"\"\"\n",
    "        return formatted_output.strip()  # 양 끝 공백 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "84f0b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MarkdownOutputParser2:\n",
    "    \"\"\"Enhanced Markdown parser with additional formatting options.\"\"\"\n",
    "\n",
    "    def __call__(self, llm_output):\n",
    "        \"\"\"Extracts the assistant's response from after the </think> tag and formats it in Markdown.\"\"\"\n",
    "        if not llm_output or llm_output.strip() == \"\":\n",
    "            return \"❌ 모델에서 응답을 생성하지 못했습니다.\"\n",
    "\n",
    "        # \"</think>\" 이후 텍스트 추출\n",
    "        match = re.search(r\"<\\|assistant\\|>\\s*(.*)\", llm_output, re.DOTALL)\n",
    "        extracted_text = match.group(1).strip() if match else llm_output.strip()\n",
    "\n",
    "        # Markdown 형식 적용\n",
    "        formatted_output = f\"\"\"\n",
    "### **🔹 모델 응답 결과**\n",
    "\n",
    "{extracted_text}\n",
    "\"\"\"\n",
    "        return formatted_output.strip()  # 양 끝 공백 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4072d98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:25<00:00,  3.63s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# 🔹 EXAONE 모델 로드\n",
    "exaone_model_id = \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\"\n",
    "exaone_tokenizer = AutoTokenizer.from_pretrained(exaone_model_id)\n",
    "exaone_model = AutoModelForCausalLM.from_pretrained(\n",
    "    exaone_model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"cuda\",  # CUDA에서 자동 배치\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "57b1bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 파이프라인 생성\n",
    "exaone_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=exaone_model,\n",
    "    tokenizer=exaone_tokenizer,\n",
    "    max_new_tokens=1024,  # 생성할 최대 토큰 수 증가\n",
    "    do_sample=True,        # 샘플링 활성화\n",
    "    temperature=0.1,      \n",
    "    top_k=50,             \n",
    "    repetition_penalty=1.05\n",
    ")\n",
    "# LangChain의 HuggingFacePipeline 사용\n",
    "exaone_llm = HuggingFacePipeline(pipeline=exaone_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0e5af389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "chain = (\n",
    "    retriever\n",
    "    | RunnableLambda(lambda docs: {  \n",
    "        \"context\": \"\\n\".join([doc.page_content for doc in docs]),  \n",
    "        \"question\": query \n",
    "    })\n",
    "    | deepseek_prompt\n",
    "    | llm\n",
    "    | MarkdownOutputParser()\n",
    "    | (lambda x: {\"reasoning\": x})\n",
    "    | exaone_prompt\n",
    "    | exaone_llm\n",
    "    | MarkdownOutputParser2()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fb2b4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"2000년대 유화작품 2개 추천해줘?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1ef549de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### **🔹 모델 응답 결과**\n",
      "\n",
      "## 🖼️ 2000년대 유화 작품 추천\n",
      "\n",
      "2000년대의 주목할 만한 유화 작품 두 점을 소개합니다:\n",
      "\n",
      "* **《아이리스》 (6609)**\n",
      "    * **작가**: 김점선\n",
      "    * **연도**: 2001\n",
      "    * **크기**: 199.5 x 139.3 cm\n",
      "    * **재료**: 캔버스에 유화 물감\n",
      "    * **특징**: 김점선 작가는 독창적인 시각으로 작품 세계를 구축했습니다. 《아이리스》는 화려한 색감과 역동적인 붓터치가 생명력 넘치는 분위기를 자아냅니다.\n",
      "\n",
      "* **《정물화 2》 (4483)**\n",
      "    * **작가**: 김지원\n",
      "    * **연도**: 2000\n",
      "    * **크기**: 194 x 130 cm\n",
      "    * **재료**: 캔버스에 유화 물감\n",
      "    * **특징**: 김지원 작가는 일상적인 사물들을 통해 새로운 해석을 제시합니다. 《정물화 2》는 사실적인 표현 속에 경쾌한 붓터치가 더해져 사물의 독창성과 생동감을 잘 드러냅니다.\n",
      "\n",
      "두 작품 모두 2000년대 유화 예술의 특징을 잘 보여주는 대표작입니다.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"question\": query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "501b6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Content: {\n",
      "    \"title\": \"이호섭 인물\",\n",
      "    \"title_ch\": \"李湖燮 人物\",\n",
      "    \"title_eng\": \"Portrait of Lee, Ho-Sup\",\n",
      "    \"artist\": \"임응식\",\n",
      "    \"artist_eng\": \"LIMB Eungsik\",\n",
      "    \"artwork_number\": 663,\n",
      "    \"year\": \"1982\",\n",
      "    \"size\": \"33×25.7\",\n",
      "    \"materials\": \"종이에 젤라틴실버프린트\",\n",
      "    \"category\": \"사진\",\n",
      "    \"description\": \"한국 사진계의 선구자인 임응식(1912-2001)은 사진의 기록성, 현실성 등 사진매체의 본질에 주목하여 인간 생활사를 표현하였던 작가이다. 그는 1950년대 이후 ‘생활주의 사진운동’을 일으켜 리얼리즘(Realism)에 입각한 사진을 제작하였으며, 자신의 사진관에 대해 \\\"사진이란 인간생활의 기록이고 진실이다\\\"라고 하였다.임응식은 노년기에 들어서면서부터 친분이 있는 주위의 예술가들을 주제로 인물 사진을 찍었다. 사실주의에 입각하여 우리의 생활과 역사를 기록해오던 그가 유명 예술인의 모습을 촬영한 이유는, 늦기 전에 그들의 가치를 기록해 두어야 한다는 사명감 때문이었다. 그는 자신의 마지막 작업으로써 동료 예술인들을 필름에 담는 것은 자신의 ‘임무’라고 사진집『풍모』(1982)의 서문에서 밝힌 바 있다.이러한 작업의 일환으로 제작된 <이호섭 인물>(1982)은 작곡가 이호섭(李湖燮)을 촬영한 사진이다. 이호섭의 대표적인 가곡으로는 <그리움>, <기다림> 등이 있다.\",\n",
      "    \"read_count\": 4\n",
      "}\n",
      "Metadata: {'title': '이호섭 인물', 'artist': '임응식', 'year': '1982', 'read_count': 4}\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "Content: {\n",
      "    \"title\": \"이순석 인물\",\n",
      "    \"title_ch\": \"李順石 人物\",\n",
      "    \"title_eng\": \"Portrait of Lee, Soon-Suk\",\n",
      "    \"artist\": \"임응식\",\n",
      "    \"artist_eng\": \"LIMB Eungsik\",\n",
      "    \"artwork_number\": 646,\n",
      "    \"year\": \"1969\",\n",
      "    \"size\": \"33.2×25.7\",\n",
      "    \"materials\": \"종이에 젤라틴실버프린트\",\n",
      "    \"category\": \"사진\",\n",
      "    \"description\": \"한국 사진계의 선구자인 임응식(1912-2001)은 사진의 기록성, 현실성 등 사진매체의 본질에 주목하여 인간 생활사를 표현하였던 작가이다. 그는 1950년대 이후 ‘생활주의 사진운동’을 일으켜 리얼리즘에 입각한 사진을 제작하였으며, 자신의 사진관에 대해 \\\"사진이란 인간생활의 기록이고 진실이다\\\"라고 하였다.임응식은 노년기에 들어서면서부터 친분이 있는 주위의 예술가들을 주제로 인물 사진을 찍었다. 사실주의에 입각하여 우리의 생활과 역사를 기록해오던 그가 유명 예술인의 모습을 촬영한 이유는, 늦기 전에 그들의 가치를 기록해 두어야 한다는 사명감 때문이었다. 그는 자신의 마지막 작업으로써 동료 예술인들을 필름에 담는 것은 자신의 ‘임무’라고 사진집『풍모』(1982)의 서문에서 밝힌 바 있다.이러한 작업의 일환으로 제작된 <이순석 인물>(1969)은 공예가 이순석(李順石)을 촬영한 사진이다. 인물의 오른쪽 옆모습을 촬영한 이 사진에는 얼굴 정면으로부터 오는 강한 빛으로 귀 뒤에 음영이 뚜렷하게 표현되고 있으며, 무표정한 얼굴은 엄격한 인상을 전해준다.\",\n",
      "    \"read_count\": 16\n",
      "}\n",
      "Metadata: {'title': '이순석 인물', 'artist': '임응식', 'year': '1969', 'read_count': 16}\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "Content: {\n",
      "    \"title\": \"김광섭 인물\",\n",
      "    \"title_ch\": \"金珖燮 人物\",\n",
      "    \"title_eng\": \"Portrait of Kim, Kwang-Seob\",\n",
      "    \"artist\": \"임응식\",\n",
      "    \"artist_eng\": \"LIMB Eungsik\",\n",
      "    \"artwork_number\": 549,\n",
      "    \"year\": \"1974\",\n",
      "    \"size\": \"33×26\",\n",
      "    \"materials\": \"종이에 젤라틴실버프린트\",\n",
      "    \"category\": \"사진\",\n",
      "    \"description\": \"한국 사진계의 선구자인 임응식(1912-2001)은 사진의 기록성, 현실성 등 사진매체의 본질에 주목하여 인간 생활사를 표현하였던 작가이다. 그는 1950년대 이후 ‘생활주의 사진운동’을 일으켜 리얼리즘(Realism)에 입각한 사진을 제작하였으며, 자신의 사진관에 대해 \\\"사진이란 인간생활의 기록이고 진실이다\\\"라고 하였다.임응식은 노년기에 들어서면서부터 친분이 있는 주위의 예술가들을 주제로 인물 사진을 찍었다. 사실주의에 입각하여 우리의 생활과 역사를 기록해오던 그가 유명 예술인의 모습을 촬영한 이유는 늦기 전에 그들의 가치를 기록해 두어야 한다는 사명감 때문이었다. 그는 자신의 마지막 작업으로써 동료 예술인들을 필름에 담는 것은 자신의 ‘임무’라고 사진집『풍모』(1982)의 서문에서 밝힌 바 있다.이러한 작업의 일환으로 제작된 <김광섭 인물>(1974)는 시인 김광섭(金珖燮)을 촬영한 사진이다. 김광섭은 우리나라 근대시의 대표작 중의 하나인 <성북동 비둘기>를 쓴 시인으로 세계일보 사장과 경희대 교수를 역임하였다.이 사진은 타계하기 3년 전에 제작된 것으로, 안경 속에서도 빛나는 두 눈과 다소곳이 다문 입술은 시와 인생에 대한 그의 진지한 태도가 잘 드러난다. 이는 전통 초상화에서 말하는 소위 전신(傳神)이 잘 드러난 작품이라 할 수 있다.\",\n",
      "    \"read_count\": 8\n",
      "}\n",
      "Metadata: {'title': '김광섭 인물', 'artist': '임응식', 'year': '1974', 'read_count': 8}\n",
      "--------------------------------------------------\n",
      "Document 4:\n",
      "Content: {\n",
      "    \"title\": \"김중업 인물\",\n",
      "    \"title_ch\": \"金重業 人物\",\n",
      "    \"title_eng\": \"Portrait of Kim, Jung-Up\",\n",
      "    \"artist\": \"임응식\",\n",
      "    \"artist_eng\": \"LIMB Eungsik\",\n",
      "    \"artwork_number\": 577,\n",
      "    \"year\": \"1981\",\n",
      "    \"size\": \"33.1×26\",\n",
      "    \"materials\": \"종이에 젤라틴실버프린트\",\n",
      "    \"category\": \"사진\",\n",
      "    \"description\": \"한국 사진계의 선구자인 임응식(1912-2001)은 사진의 기록성, 현실성 등 사진매체의 본질에 주목하여 인간 생활사를 표현하였던 작가이다. 그는 1950년대 이후 ‘생활주의 사진운동’을 일으켜 리얼리즘(Realism)에 입각한 사진을 제작하였으며, 자신의 사진관에 대해 \\\"사진이란 인간생활의 기록이고 진실이다\\\"라고 하였다.임응식은 노년기에 들어서면서부터 친분이 있는 주위의 예술가들을 주제로 인물 사진을 찍었다. 사실주의에 입각하여 우리의 생활과 역사를 기록해오던 그가 유명 예술인의 모습을 촬영한 이유는, 늦기 전에 그들의 가치를 기록해 두어야 한다는 사명감 때문이었다. 그는 자신의 마지막 작업으로써 동료 예술인들을 필름에 담는 것은 자신의 ‘임무’라고 사진집『풍모』(1982)의 서문에서 밝힌 바 있다.이러한 작업의 일환으로 제작된 <김중업 인물>(1981)은 건축가 김중업(金重業)을 촬영한 사진이다. 프랑스의 건축가 르 꼬르뷔제(Le Corbusier)에게 사사 하였으며, 서울대학교 공대와 홍익대 교수를 역임하였던 김중업의 대표 건축물로는 '주한불란서 대사관'이 있다. 이 사진에는 실내로 스며든 자연 채광을 통해 인물의 얼굴윤곽이 잘 드러나있다.\",\n",
      "    \"read_count\": 19\n",
      "}\n",
      "Metadata: {'title': '김중업 인물', 'artist': '임응식', 'year': '1981', 'read_count': 19}\n",
      "--------------------------------------------------\n",
      "Document 5:\n",
      "Content: {\n",
      "    \"title\": \"이은상 인물\",\n",
      "    \"title_ch\": \"李殷相 人物\",\n",
      "    \"title_eng\": \"Portrait of Lee, Eun-Sang\",\n",
      "    \"artist\": \"임응식\",\n",
      "    \"artist_eng\": \"LIMB Eungsik\",\n",
      "    \"artwork_number\": 651,\n",
      "    \"year\": \"1979\",\n",
      "    \"size\": \"26×33\",\n",
      "    \"materials\": \"종이에 젤라틴실버프린트\",\n",
      "    \"category\": \"사진\",\n",
      "    \"description\": \"한국 사진계의 선구자인 임응식(1912-2001)은 사진의 기록성, 현실성 등 사진매체의 본질에 주목하여 인간 생활사를 표현하였던 작가이다. 그는 1950년대 이후 ‘생활주의 사진운동’을 일으켜 리얼리즘(Realism)에 입각한 사진을 제작하였으며, 자신의 사진관에 대해 \\\"사진이란 인간생활의 기록이고 진실이다\\\"라고 하였다.임응식은 노년기에 들어서면서부터 친분이 있는 주위의 예술가들을 주제로 인물 사진을 찍었다. 사실주의에 입각하여 우리의 생활과 역사를 기록해오던 그가 유명 예술인의 모습을 촬영한 이유는, 늦기 전에 그들의 가치를 기록해 두어야 한다는 사명감 때문이었다. 그는 자신의 마지막 작업으로써 동료 예술인들을 필름에 담는 것은 자신의 ‘임무’라고 사진집『풍모』(1982)의 서문에서 밝힌 바 있다.이러한 작업의 일환으로 제작된 <이은상 인물>(1979)은 시인 이은상(李殷相)을 촬영한 사진이다. 이은상의 대표작으로는『이충무공 일대기』(1946)가 있다.돋보기를 쓰고 무엇인가를 열심히 이야기하려는 그의 모습이 인상적이다.\",\n",
      "    \"read_count\": 3\n",
      "}\n",
      "Metadata: {'title': '이은상 인물', 'artist': '임응식', 'year': '1979', 'read_count': 3}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"Content: {doc.page_content}\")  # 문서의 실제 내용\n",
    "    print(f\"Metadata: {doc.metadata}\")    # 메타데이터 (예: 출처, 페이지 등)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25b13d46-a624-421e-80bd-f1f041d77b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서 수: 5\n",
      "\n",
      "문서 1:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.4776\n",
      "  전체 내용: 작품명: 토끼풀 / N/A / Clover\n",
      "\n",
      "작가: 이중섭 / LEE Jungseop\n",
      "\n",
      "작품 번호: 10001\n",
      "\n",
      "제작 연도: 1941\n",
      "\n",
      "크기: 9×14\n",
      "\n",
      "재료: 종이에 펜, 수채 물감\n",
      "\n",
      "카테고리: 드로잉\n",
      "\n",
      "작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈토끼풀〉은 이중섭이 이 시기 제작한 여러 점의 엽서화 중 하나로, 토끼풀 도상은 그의 그림에 반복적으로 등장하였다. 화면 중앙에 분리된 꽃과 잎을 큼지막한 도안처럼 연출하고 있고, 화면 좌우 사선으로 꽃줄기와 뾰족한 풀잎을 배치하여 구도적인 면에서 조화를 이뤄냈다. 잎과 줄기, 꽃봉오리 사이 수채 특유의 맑은 적녹 대비가 화면에 생동감을 부여한다. 펜촉으로 주저함 없는 선을 그리고, 이 위에 수채 물감을 빠르게 올린 듯 펜 선의 번진 흔적이 두드러진다. 오른쪽 아래 작가의 것으로 보이는 손자국은 엽서화 제작의 현장감을 전한다. 토끼풀의 꽃과 잎이 갖는 소박한 외양과, 행운과 평화 등으로 통용되는 꽃말 등으로 미루어 일상의 소박한 행복을 염원하는 작가의 심리가 그림 속에 반영된 것으로 보인다.\n",
      "\n",
      "문서 2:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.5907\n",
      "  전체 내용: 작품명: 토끼풀과 새가 있는 바닷가  / N/A / Seashore with Clover and Birds\n",
      "\n",
      "작가: 이중섭 / LEE Jungseop\n",
      "\n",
      "작품 번호: 10018\n",
      "\n",
      "제작 연도: 1941\n",
      "\n",
      "크기: 9×14\n",
      "\n",
      "재료: 종이에 펜, 수채 물감\n",
      "\n",
      "카테고리: 드로잉\n",
      "\n",
      "작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈토끼풀과 새가 있는 바닷가〉는 바닷가 부근의 풍경과 곳곳에 있는 동식물을 그린 드로잉 작업이다. 작가는 펜의 간결한 선으로 먼발치의 산, 지평선, 모래사장의 질감, 그곳을 거니는 인간과 동물들을 그려 놓고, 토끼풀을 마치 가장 가까운 거리에 있는 듯 커다랗게 표현했다. 그림 속 바다는 하늘색 수채 물감으로 옅게 칠해져 육지와 구분되어 있으며, 잔잔하고 평화로운 느낌을 준다. 왼쪽 하단에는 인간과 강아지 같은 존재가 조그맣게 그려져 산과 함께 드로잉 속 공간을 입체적으로 보이게 만든다. 이 모든 광경을 관통하듯 가로지르는 토끼풀이 평화로운 풍경에 역동성을 더하면서 목가적인 동화의 한 장면을 연상시킨다.\n",
      "\n",
      "문서 3:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.7527\n",
      "  전체 내용: 작품명: 오줌싸개와 닭과 개구리 / N/A / Child Wetting the Bed with Chicken and Frog\n",
      "\n",
      "작가: 이중섭 / LEE Jungseop\n",
      "\n",
      "작품 번호: 9939\n",
      "\n",
      "제작 연도: 1950\n",
      "\n",
      "크기: 28×41\n",
      "\n",
      "재료: 종이에 유화 물감\n",
      "\n",
      "카테고리: 회화 II\n",
      "\n",
      "작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈오줌싸개와 닭과 개구리〉는 작품명처럼 인물과 닭과 개구리가 묘사된 유화 작품이다. 새와 닭은 이중섭 작품 중 소와 더불어 가장 오랫동안 다뤄졌던 소재 중 하나이다. 한 남자가 교미하고 있는 한 쌍의 닭을 향해 오줌을 싸고 있다. 이에 놀란 닭들은 서로에게서 황급히 떨어져 당황스러운 표정으로 남자를 바라보고 있으며, 이 모든 광경을 개구리가 관찰하고 있다. 거칠고 투박하지만 속도감 있는 붓 터치를 통해 화면에는 다급한 상황과 긴장감이 생생히 감돈다. 화면 속에 연출된 일상적이면서도 엉뚱한 상황을 통해 이중섭 특유의 관찰력과 해학성을 느낄 수 있다.\n",
      "\n",
      "문서 4:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.7716\n",
      "  전체 내용: 작품명: 오줌싸는 아이 / N/A / Child Urinating\n",
      "\n",
      "작가: 이중섭 / LEE Jungseop\n",
      "\n",
      "작품 번호: 9960\n",
      "\n",
      "제작 연도: 1950\n",
      "\n",
      "크기: 8.6×15.2\n",
      "\n",
      "재료: 은지에 새김, 유화 물감\n",
      "\n",
      "카테고리: 회화 II\n",
      "\n",
      "작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈오줌싸는 아이〉에서는 벌거벗고 뒤엉켜 놀고 있는 여러 명의 아이들을 향해 화면 왼편에 위치한 아이가 마찬가지로 벌거벗은 채로 오줌을 갈기고 있다. 특별히 놀라거나 피하지 않고 눈을 감은 편안한 얼굴로 그 당황스러운 상황을 대하고 있어 익살스러운 느낌을전한다. 아이들의 천진난만함이 극대화되고 인간의 원초적인 모습을 그려낸 듯 보이기도 하다. 여러 명의 아이들이 등장하는 이중섭의 작품들에서는 통상적으로 긴 끈이나 천이 그들 사이를 연결하는 요소로써 활용된다. 이 작품에서는 오줌 줄기가 인물과 인물을 연결해 주는 듯 보인다. 화면 하단 좌측에 작게 그려져 있는 게는 작품이 지닌 해학성을 한층 높인다.\n",
      "\n",
      "문서 5:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.7717\n",
      "  전체 내용: 작품명: 투계 / 鬪鷄 / Fighting Fowls\n",
      "\n",
      "작가: 이중섭 / LEE Jungseop\n",
      "\n",
      "작품 번호: 99\n",
      "\n",
      "제작 연도: 1955\n",
      "\n",
      "크기: 28.5×40.5\n",
      "\n",
      "재료: 카드보드에 유화 물감\n",
      "\n",
      "카테고리: 회화 II\n",
      "\n",
      "작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평양의 종로공립보통학교에서 임용련에게 사사한 후 1935년에 일본으로 건너가 동경 제국미술학교(帝国美術学校)에서 공부했으나, 곧 학교를 그만두고 문화학원(文化学院) 미술과로 옮겼다. 동경 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하여 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 동경 문화학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸고, 한국전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었다. 가족과 헤어진 후 부산에서 피란시절을 보낼 때는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 전쟁 후 잠시 동안 꿈에 부풀어 작업할 때는 당당하고 힘찬 기세가 화면에 가득하지만, 곧 빚에 시달리며 가족과 재회할 수 있는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.  <투계>는 두 마리의 닭이 싸우는 모습을 그린 작품으로, 화면 위쪽에 그려진 붉은색 닭과 아래에 있는 푸른색의 닭이 서로 마주보며 신경을 곤두세우고 있다. 물감을 유화용 나이프로 긁어내는 방식으로 거칠게 표현함으로써, 당장이라도 물어뜯을 듯 공격적인 자세를 취하고 있는 닭의 역동적인 모습을 생생하게 그려 냈다. 이 작품은 작가가 고분 벽화에서 영감을 받은 것으로, 그의 개인적 고난과 시대적 고민이 반영되어 있다.\n"
     ]
    }
   ],
   "source": [
    "# 검색 수행: 유사도 점수와 함께 반환\n",
    "docs_and_scores = retriever.vectorstore.similarity_search_with_score(query, k=5)\n",
    "\n",
    "# 검색된 문서 수 출력\n",
    "print(f\"검색된 문서 수: {len(docs_and_scores)}\")\n",
    "\n",
    "# 각 문서의 파일명, 전체 내용, 유사도 점수 출력\n",
    "for i, (doc, score) in enumerate(docs_and_scores, 1):\n",
    "    print(f\"\\n문서 {i}:\")\n",
    "    print(f\"  파일명: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(f\"  유사도 점수: {score:.4f}\")\n",
    "    print(f\"  전체 내용: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227476a-1804-4ac4-89dc-4197c5ed6f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
