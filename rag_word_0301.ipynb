{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e06783-f083-424c-9ace-51f3c3bf5e00",
   "metadata": {},
   "source": [
    "### 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacafc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt  # íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f425499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # PyTorch ë²„ì „\n",
    "print(torch.version.cuda)  # PyTorchê°€ ì‚¬ìš©í•˜ëŠ” CUDA ë²„ì „\n",
    "print(torch.cuda.is_available())  # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d49d96-9721-43a6-8482-9158d25c93fe",
   "metadata": {},
   "source": [
    "### 2. ë¬¸ì„œ split ë° Chromaë¥¼ í™œìš©í•œ vector store êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d82f23-0f73-4879-8a69-46d5237a47b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chae/env_0217/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¡œê·¸ì¸ ìƒíƒœì…ë‹ˆë‹¤. ì‚¬ìš©ì: chaeeee\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(f\"ë¡œê·¸ì¸ ìƒíƒœì…ë‹ˆë‹¤. ì‚¬ìš©ì: {user_info['name']}\")\n",
    "except Exception as e:\n",
    "    print(\"ë¡œê·¸ì¸ë˜ì§€ ì•Šì•˜ê±°ë‚˜ í† í°ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ea6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import os, json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. JSON íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "json_path = \"./json_data.json\"  # ë‹¨ì¼ JSON íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "# 2. JSON ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "# 3. {}ë¥¼ ê¸°ì¤€ìœ¼ë¡œ JSON ë°ì´í„° ë¶„í•  ë° Document ê°ì²´ ìƒì„±\n",
    "documents = []\n",
    "\n",
    "for data in tqdm(all_data, desc=\"Generating Documents\", unit=\"entry\", ncols=80):\n",
    "    metadata = {\n",
    "        \"title\": data.get('title', 'N/A'),\n",
    "        \"artist\": data.get('artist', 'N/A'),\n",
    "        \"year\": data.get('year', 'N/A'),\n",
    "        \"read_count\": data.get('read_count', 0)\n",
    "    }\n",
    "\n",
    "    # JSON ë°ì´í„°ì˜ ê° í•­ëª©ì„ Document ê°ì²´ë¡œ ë³€í™˜\n",
    "    doc_content = json.dumps(data, ensure_ascii=False, indent=4)\n",
    "    documents.append(Document(\n",
    "        page_content=doc_content.strip(),\n",
    "        metadata=metadata\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102d292-48e8-4eeb-9280-79dc003ed796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • Document ê°ì²´ì˜ í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸\n",
    "len(documents[11001].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec14a4-2333-4381-8152-dc30d011ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800ìë¥¼ ì´ˆê³¼í•˜ëŠ” Document ê°œìˆ˜ ì„¸ê¸°\n",
    "over_800_count = sum(1 for doc in documents if len(doc.page_content) > 800)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"800ìë¥¼ ì´ˆê³¼í•˜ëŠ” Document ê°œìˆ˜: {over_800_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1ef186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.3.1, however, your version is 3.2.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss  # FAISS ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”\n",
    "\n",
    "# 1. ì„ë² ë”© ì´ˆê¸°í™”\n",
    "embedding_model = SentenceTransformer(\"nlpai-lab/KURE-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce036d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ë¬¸ì„œ ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„° ë¶„ë¦¬\n",
    "texts = [doc.page_content for doc in documents]  # ë¬¸ì„œ í…ìŠ¤íŠ¸\n",
    "metadatas = [doc.metadata for doc in documents]  # ë¬¸ì„œ ë©”íƒ€ë°ì´í„°\n",
    "\n",
    "# 3. ë¬¸ì„œ ì„ë² ë”© ìƒì„±\n",
    "embeddings = embedding_model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23144ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
    "embedding_dim = embeddings.shape[1]  # ë²¡í„° ì°¨ì› í™•ì¸\n",
    "faiss_index = faiss.IndexFlatL2(embedding_dim)  # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤\n",
    "faiss_index.add(embeddings)  # ë²¡í„° ì¶”ê°€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba322337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# 5. Docstore ìƒì„±\n",
    "# ê° ë¬¸ì„œì— ê³ ìœ  IDë¥¼ ë¶€ì—¬í•´ InMemoryDocstore ìƒì„±\n",
    "docstore = InMemoryDocstore({i : doc for i, doc in enumerate(documents)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd078ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "def embed_query(text):\n",
    "    return embedding_model.encode([text])[0]  # ë‹¨ì¼ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©\n",
    "\n",
    "index_to_docstore_id = {i: i for i in range(len(documents))}\n",
    "\n",
    "faiss_db = FAISS(\n",
    "    embedding_function=embed_query,\n",
    "    index=faiss_index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "# 7. FAISS ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥\n",
    "faiss_db.save_local(\"./faiss_artworks_0304_artworks\")\n",
    "print(\"FAISS ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "query = \"ë°•ìŠ¹ë¬´ì˜ ì„¤ê²½\"\n",
    "results = faiss_db.similarity_search(query, k=5)\n",
    "\n",
    "# 10. ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\n",
    "for result in results:\n",
    "    print(\"ë¬¸ì„œ í…ìŠ¤íŠ¸:\", result.page_content)\n",
    "    print(\"ë¬¸ì„œ ë©”íƒ€ë°ì´í„°:\", result.metadata)\n",
    "    print('=------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"nlpai-lab/KURE-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a00995-3f64-49d2-8b0f-033e8b640085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# ê¸°ì¡´ DB ë¡œë“œ \n",
    "persist_directory = \"./faiss_combined\"\n",
    "\n",
    "try:\n",
    "    faiss_db = FAISS.load_local(\n",
    "        folder_path=persist_directory,\n",
    "        embeddings=embedding_model,\n",
    "        allow_dangerous_deserialization=True  # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ì—ì„œë§Œ ì‚¬ìš©\n",
    "    )\n",
    "    \n",
    "    # embedding_function ìˆ˜ì •\n",
    "    faiss_db.embedding_function = lambda text: (\n",
    "        embedding_model.encode(text) if isinstance(text, str) else embedding_model.encode(str(text))\n",
    "    )\n",
    "    \n",
    "    print(\"FAISS ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "except Exception as e:\n",
    "    print(f\"FAISS ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4607b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4bit ì–‘ìí™” í™œì„±í™”\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # ê³„ì‚° íƒ€ì… ì„¤ì • (float16ì´ ì¼ë°˜ì )\n",
    "    bnb_4bit_use_double_quant=True,  # ë”ë¸” ì–‘ìí™” ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "    bnb_4bit_quant_type=\"nf4\",  # NormalFloat4 (NF4) ì‚¬ìš©\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0bffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4-bit ì–‘ìí™” í™œì„±í™”\n",
    "    bnb_4bit_compute_dtype=\"float16\",  # ê³„ì‚° ì •ë°€ë„ ì„¤ì •\n",
    "    bnb_4bit_quant_type=\"nf4\",  # NF4 ì–‘ìí™” ë°©ì‹ ì‚¬ìš© (íš¨ìœ¨ì )\n",
    "    bnb_4bit_use_double_quant=True,  # ì´ì¤‘ ì–‘ìí™” ì‚¬ìš©\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40645602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ (CUDA ì‚¬ìš©)\n",
    "model_id = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,  # âœ… ì˜¬ë°”ë¥¸ ì–‘ìí™” ì„¤ì • ì ìš©\n",
    "    device_map=\"auto\",  # âœ… ìë™ GPU ë°°ì¹˜\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6446fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,  # ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ ì¦ê°€\n",
    "    do_sample=True,        # ìƒ˜í”Œë§ í™œì„±í™”\n",
    "    temperature=0.1,      \n",
    "    top_k=50,             \n",
    "    repetition_penalty=1.05\n",
    ")\n",
    "# LangChainì˜ HuggingFacePipeline ì‚¬ìš©\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "deepseek_template = \"\"\"\n",
    "<|system|>\n",
    "You are a friendly chatbot specializing in artworks and general conversations.\n",
    "Your primary role is to answer questions **accurately based on the provided document (context)**. \n",
    "If the requested information is not found in the document, respond with:\n",
    "\"ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\" \n",
    "\n",
    "However, if the question is a general conversation or does not relate to the document, you should respond naturally as a conversational chatbot. \n",
    "You can talk about art history, artists, exhibitions, and general topics such as daily life, technology, and culture. \n",
    "Maintain a friendly and engaging tone, ensuring all responses are written in Korean.\n",
    "Use **beautiful Markdown formatting** (headings, bullet points, **bold** or *italic* text) to enhance readability.\n",
    "You must include the artwork number in your response.\n",
    "\n",
    "<|context|>\n",
    "{context}\n",
    "\n",
    "<|user|>\n",
    "Question: {question}\n",
    "\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exaone_template = '''\n",
    "<|system|>\n",
    "You are an AI assistant tasked with refining and polishing the provided logical reasoning into a final answer in Korean.  \n",
    "Your role is to produce a clear, concise, and well-structured response that maintains the original meaning and key details.  \n",
    "Ensure that your final answer is written in Korean and uses **beautiful Markdown formatting** (e.g., headings, bullet points, **bold** or *italic* text) to enhance readability.  \n",
    "Focus solely on refining the content without adding any new information.\n",
    "You must include the artwork number in your response.\n",
    "\n",
    "<|reasoning|>\n",
    "{reasoning}\n",
    "\n",
    "<|user|>\n",
    "Based on the above reasoning, please generate a refined and final answer in Korean.\n",
    "\n",
    "<|assistant|>\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# DeepSeek í…œí”Œë¦¿ ìƒì„±\n",
    "deepseek_prompt = ChatPromptTemplate.from_template(deepseek_template)\n",
    "\n",
    "# EXAONE í…œí”Œë¦¿ ìƒì„±\n",
    "exaone_prompt = ChatPromptTemplate.from_template(exaone_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "747bc299-6dde-4a89-beeb-0f330ac28baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = '''\n",
    "<|system|>\n",
    "You are a friendly chatbot specializing in artworks and general conversations.\n",
    "Your primary role is to answer questions strictly based on the information provided in the document (context). \n",
    "If the requested information is not found in the document, respond with:\n",
    "\"The document does not contain this information.\" \n",
    "\n",
    "However, if the question is a general conversation or does not relate to the document, you should respond naturally as a conversational chatbot. \n",
    "You can talk about art history, artists, exhibitions, and general topics such as daily life, technology, and culture. \n",
    "Maintain a friendly and engaging tone, ensuring all responses are written in Korean.\n",
    "Use **beautiful Markdown formatting** (headings, bullet points, bold or italic text) to enhance readability.\n",
    "You must include artwork number.\n",
    "\n",
    "<|context|>\n",
    "{context}\n",
    "\n",
    "<|user|>\n",
    "Question: {question}\n",
    "\n",
    "<|assistant|>\n",
    "'''\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "137611cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_db.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                # ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜\n",
    "        \"fetch_k\": 15,         # ë” ë§ì€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "        \"mmr\": True,           # MMR í™œì„±í™”\n",
    "        \"mmr_beta\": 0.3      # ë‹¤ì–‘ì„±ê³¼ ê´€ë ¨ì„± ê°„ ê· í˜•\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e8023be-86e0-487d-b773-df209eac7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MarkdownOutputParser:\n",
    "    \"\"\"Enhanced Markdown parser with additional formatting options.\"\"\"\n",
    "\n",
    "    def __call__(self, llm_output):\n",
    "        \"\"\"Extracts the assistant's response from after the </think> tag and formats it in Markdown.\"\"\"\n",
    "        if not llm_output or llm_output.strip() == \"\":\n",
    "            return \"âŒ ëª¨ë¸ì—ì„œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "        # \"</think>\" ì´í›„ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        match = re.search(r\"</think>\\s*(.*)\", llm_output, re.DOTALL)\n",
    "        extracted_text = match.group(1).strip() if match else llm_output.strip()\n",
    "\n",
    "        # Markdown í˜•ì‹ ì ìš©\n",
    "        formatted_output = f\"\"\"\n",
    "### **ğŸ”¹ ëª¨ë¸ ì‘ë‹µ ê²°ê³¼**\n",
    "\n",
    "{extracted_text}\n",
    "\"\"\"\n",
    "        return formatted_output.strip()  # ì–‘ ë ê³µë°± ì œê±°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84f0b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MarkdownOutputParser2:\n",
    "    \"\"\"Enhanced Markdown parser with additional formatting options.\"\"\"\n",
    "\n",
    "    def __call__(self, llm_output):\n",
    "        \"\"\"Extracts the assistant's response from after the </think> tag and formats it in Markdown.\"\"\"\n",
    "        if not llm_output or llm_output.strip() == \"\":\n",
    "            return \"âŒ ëª¨ë¸ì—ì„œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "        # \"</think>\" ì´í›„ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        match = re.search(r\"<\\|assistant\\|>\\s*(.*)\", llm_output, re.DOTALL)\n",
    "        extracted_text = match.group(1).strip() if match else llm_output.strip()\n",
    "\n",
    "        # Markdown í˜•ì‹ ì ìš©\n",
    "        formatted_output = f\"\"\"\n",
    "### **ğŸ”¹ ëª¨ë¸ ì‘ë‹µ ê²°ê³¼**\n",
    "\n",
    "{extracted_text}\n",
    "\"\"\"\n",
    "        return formatted_output.strip()  # ì–‘ ë ê³µë°± ì œê±°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4072d98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:23<00:00,  3.43s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# ğŸ”¹ EXAONE ëª¨ë¸ ë¡œë“œ\n",
    "exaone_model_id = \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\"\n",
    "exaone_tokenizer = AutoTokenizer.from_pretrained(exaone_model_id)\n",
    "exaone_model = AutoModelForCausalLM.from_pretrained(\n",
    "    exaone_model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"cuda\",  # CUDAì—ì„œ ìë™ ë°°ì¹˜\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b1bd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1464/2480121385.py:15: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  exaone_llm = HuggingFacePipeline(pipeline=exaone_pipe)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "exaone_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=exaone_model,\n",
    "    tokenizer=exaone_tokenizer,\n",
    "    max_new_tokens=1024,  # ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ ì¦ê°€\n",
    "    do_sample=True,        # ìƒ˜í”Œë§ í™œì„±í™”\n",
    "    temperature=0.1,      \n",
    "    top_k=50,             \n",
    "    repetition_penalty=1.05\n",
    ")\n",
    "# LangChainì˜ HuggingFacePipeline ì‚¬ìš©\n",
    "exaone_llm = HuggingFacePipeline(pipeline=exaone_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "123efb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableMap\n",
    "\n",
    "chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": retriever,               # Retrieverì—ì„œ ë°˜í™˜ëœ ê°’ì„ ê°€ì ¸ì˜´\n",
    "        \"question\": RunnablePassthrough()   # ì§ˆë¬¸ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬\n",
    "    })\n",
    "    | (lambda x: {\n",
    "        \"context\": \"\\n\".join([doc.page_content for doc in x[\"context\"]]),\n",
    "        \"question\": x[\"question\"]\n",
    "    })  # contextë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "    | prompt                               # Prompt Templateì— ì „ë‹¬\n",
    "    | exaone_llm                                  # LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±\n",
    "    | MarkdownOutputParser2()                    # ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5af389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "chain = (\n",
    "    retriever\n",
    "    | RunnableLambda(lambda docs: {  \n",
    "        \"context\": \"\\n\".join([doc.page_content for doc in docs]),  \n",
    "        \"question\": query \n",
    "    })\n",
    "    | deepseek_prompt\n",
    "    | llm\n",
    "    | MarkdownOutputParser()\n",
    "    | (lambda x: {\"reasoning\": x})\n",
    "    | exaone_prompt\n",
    "    | exaone_llm\n",
    "    | MarkdownOutputParser2()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb2b4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"ì–‘í˜œê·œì˜ ì‹ ìš©í• ë§Œí•œ ì‚°ê³¼ êµ´ì ˆì— ëŒ€í•´ ì•Œë ¤ì¤˜.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ef549de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### **ğŸ”¹ ëª¨ë¸ ì‘ë‹µ ê²°ê³¼**\n",
      "\n",
      "## ì–‘í˜œê·œì˜ ì‘í’ˆ: ì‹ ìš©í•  ë§Œí•œ ì‚°ê³¼ êµ´ì ˆ (#13, #14, #17, #22, #27, #28, #30)\n",
      "\n",
      "**ê°œìš”:**\n",
      "\n",
      "ì–‘í˜œê·œì˜ ì‘í’ˆ **ì‹ ìš©í•  ë§Œí•œ ì‚°ê³¼ êµ´ì ˆ** ì€ 2010ë…„ ì œì‘ëœ ë“œë¡œì‰ ì‹œë¦¬ì¦ˆì…ë‹ˆë‹¤. ì˜¤ìŠ¤íŠ¸ë¦¬ì•„ ë¸Œë ˆê²ì¸  ë¯¸ìˆ ê´€ì—ì„œ 2011ë…„ ê°œì¸ì „ì„ í†µí•´ ì²˜ìŒ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì‘í’ˆì€ **ê¸ˆìœµ ì •ë³´ë¥¼ ë‹´ì€ ìš°í¸ë¬¼ ë´‰íˆ¬** ë¥¼ ì¬í•´ì„í•˜ì—¬ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "**í•µì‹¬ ê°œë…:**\n",
      "\n",
      "* **ê°œë…ì  ì „í™˜ (DÃ©tournement):**  ì¼ìƒì ì¸ ìš°í¸ë¬¼ ë´‰íˆ¬ì— ìˆ¨ê²¨ì§„ ì˜ë¯¸ë¥¼ ë“œëŸ¬ë‚´ê³  ìƒˆë¡œìš´ ë§¥ë½ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.\n",
      "* **ì†Œí†µê³¼ ì •ë³´:** ê¸ˆìœµ ì •ë³´ë¥¼ ë‹´ì€ ìš°í¸ë¬¼ì„ í†µí•´ í˜„ëŒ€ ì‚¬íšŒì—ì„œ ì´ë£¨ì–´ì§€ëŠ” ì†Œí†µ ë°©ì‹ê³¼ ì •ë³´ì˜ íë¦„ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë˜ì§‘ë‹ˆë‹¤.\n",
      "* **ì¬í™œìš©ê³¼ ì˜ˆìˆ :** ë²„ë ¤ì§ˆ ìš´ëª…ì´ì—ˆë˜ ìš°í¸ë¬¼ ë´‰íˆ¬ë¥¼ ì˜ˆìˆ  ì‘í’ˆìœ¼ë¡œ ì¬íƒ„ìƒì‹œì¼œ ë¬¼ì§ˆì˜ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì œì‹œí•©ë‹ˆë‹¤.\n",
      "\n",
      "**êµ¬ì„±:**\n",
      "\n",
      "* **ê°œë³„ ì‘í’ˆ:**  <ì‹ ìš©í•  ë§Œí•œ ì‚° #22>, <ì‹ ìš©í•  ë§Œí•œ ì‚° #17>, <ì‹ ìš©í•  ë§Œí•œ ì‚° #30>, <ì‹ ìš©í•  ë§Œí•œ êµ´ì ˆ #28>, <ì‹ ìš©í•  ë§Œí•œ êµ´ì ˆ #13>, <ì‹ ìš©í•  ë§Œí•œ êµ´ì ˆ #14>, <ì‹ ìš©í•  ë§Œí•œ êµ´ì ˆ #27> ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ê° ì‘í’ˆì€ ë²ˆí˜¸ë¡œ êµ¬ë¶„ë˜ë©°, ì „ì‹œì¥ ê³µê°„ê³¼ ìƒí˜¸ì‘ìš©í•˜ë„ë¡ ì„¤ì¹˜ë©ë‹ˆë‹¤.\n",
      "* **ì¬ë£Œ:** ì¹´ë“œë³´ë“œì— ë³´ì•ˆ í¸ì§€ ë´‰íˆ¬, ëª¨ëˆˆì¢…ì´, ì½œë¼ì£¼ê°€ ì£¼ìš” ì¬ë£Œë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ê¸°í•˜í•™ì  íŒ¨í„´ê³¼ ìƒ‰ìƒì˜ ì¡°í™”ë¥¼ í†µí•´ ì‹œê°ì  íš¨ê³¼ë¥¼ ì°½ì¶œí•©ë‹ˆë‹¤.\n",
      "\n",
      "**ì˜ë¯¸:**\n",
      "\n",
      "ì–‘í˜œê·œëŠ” ì´ ì‘í’ˆì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "* **ì¼ìƒ ì† ì˜ë¯¸ ì°¾ê¸°:** í‰ë²”í•œ ë¬¼ê±´ ì†ì— ìˆ¨ê²¨ì§„ ì˜ë¯¸ì™€ ê°€ì¹˜ë¥¼ ë°œê²¬í•˜ê³  ì¬í•´ì„í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
      "* **ë¬¼ì§ˆì˜ ìˆœí™˜:** ë²„ë ¤ì§€ëŠ” ë¬¼ì§ˆì— ì˜ˆìˆ ì  ìƒëª…ë ¥ì„ ë¶ˆì–´ë„£ì–´ ì§€ì† ê°€ëŠ¥í•œ ì‚¬íšŒì— ëŒ€í•œ ê³ ì°°ì„ ì œì‹œí•©ë‹ˆë‹¤.\n",
      "* **ì •ë³´ ì‹œëŒ€ì˜ ì†Œí†µ:** ê¸ˆìœµ ì •ë³´ë¥¼ ë§¤ê°œë¡œ í•œ í˜„ëŒ€ ì‚¬íšŒì˜ ì†Œí†µ ë°©ì‹ê³¼ ê·¸ ì´ë©´ì— ìˆ¨ê²¨ì§„ ë¬¸ì œì ì„ ì§ˆë¬¸í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"question\": query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "501b6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Content: ì‘í’ˆëª…: ì‹ ìš©í•  ë§Œí•œ ì‚°ê³¼ êµ´ì ˆ #13, #14, #17, #22, #27, #28, #30 / N/A / Trustworthy Mountains and Refractions #13, #14, #17, #22, #27, #28, #30\n",
      "\n",
      "ì‘ê°€: ì–‘í˜œê·œ / YANG Haegue\n",
      "\n",
      "ì‘í’ˆ ë²ˆí˜¸: 8088\n",
      "\n",
      "ì œì‘ ì—°ë„: 2010\n",
      "\n",
      "í¬ê¸°: 99Ã—69Ã—(7)\n",
      "\n",
      "ì¬ë£Œ: ì¹´ë“œë³´ë“œì— ë³´ì•ˆ í¸ì§€ ë´‰íˆ¬, ëª¨ëˆˆì¢…ì´, ì½œë¼ì£¼\n",
      "\n",
      "ì¹´í…Œê³ ë¦¬: ë“œë¡œì‰\n",
      "\n",
      "ì‘í’ˆ ì„¤ëª…: ì–‘í˜œê·œ(1971- )ëŠ” ì„œìš¸ëŒ€ ì¡°ì†Œê³¼ë¥¼ ì¡¸ì—…í•˜ê³  ë…ì¼ í”„ë‘í¬í‘¸ë¥´íŠ¸ êµ­ë¦½í•™êµ ìŠˆí…Œë¸ìŠë ˆì—ì„œ ë§ˆì´ìŠ¤í„°ìŠëŸ¬ í•™ìœ„ë¥¼ ì·¨ë“í–ˆë‹¤. 1994ë…„ì´ë˜ í”„ë‘í¬í‘¸ë¥´íŠ¸, ë² ë¥¼ë¦°, ì„œìš¸ì„ ê¸°ë°˜ìœ¼ë¡œ êµ­ì œ ë¯¸ìˆ ë¬´ëŒ€ì—ì„œ ì™•ì„±í•˜ê²Œ í™œë™í•˜ë©° ëŒ€ê·œëª¨ ì„¤ì¹˜, ì¡°ê°, í‰ë©´ ë“± ë‹¤ì–‘í•œ ë§¤ì²´ë¥¼ ì•„ìš°ë¥´ëŠ” ì‘ì—…ì„ ì„ ë³´ì—¬ì™”ë‹¤.<ì‹ ìš©í•  ë§Œí•œ ì‚°ê³¼ êµ´ì ˆ #13, #14, #17, #22, #27, #28, #30>(2010)ì€ 2011ë…„ ì˜¤ìŠ¤íŠ¸ë¦¬ì•„ ë¸Œë ˆê²ì¸  ë¯¸ìˆ ê´€ì—ì„œ ì„ ë³´ì˜€ë˜ ë²„ì „ìœ¼ë¡œ <ì‹ ìš©í•  ë§Œí•œ ì‚° #22>, <ì‹ ìš©í•  ë§Œí•œ ì‚° #17>, <ì‹ ìš©í•  ë§Œí•œ ì‚° #30>, <ì‹ ìš©í•  ë§Œí•œ êµ´ì ˆ #28>, <ì‹ ìš©í•  ë§Œí•œ êµ´ì ˆ #13>, <ì‹ ìš©í•  ë§Œí•œ êµ´ì ˆ #14>, <ì‹ ìš©í•  ë§Œí•œ êµ´ì ˆ #27>ì˜ êµ¬ì„±ìœ¼ë¡œ ê¸ˆìœµ ì •ë³´ë¥¼ ë‹´ì€ ìš°í¸ë¬¼ ë´‰íˆ¬ì˜ ê°œë…ì  ì „í™˜(dÃ©tournement)ì— ì§‘ì¤‘í•œ ì´ˆê¸° ì‘ì—…ì´ë¼ í•  ìˆ˜ ìˆë‹¤. ì€í–‰ ì¹´ë“œì˜ ë¹„ë°€ë²ˆí˜¸ ë“±, ê¸ˆìœµ ì •ë³´ë¥¼ ë‹´ì€ ìš°í¸ë¬¼ì´ ë‹´ê²¨ ì˜¤ëŠ” í¸ì§€ ë´‰íˆ¬ì˜ ë‚´ì§€ë¥¼ ì£¼ ì¬ë£Œë¡œ í•œ ê¼´ë¼ì¥¬ë¥¼ í†µí•´, ì¼ìƒì—ì„œ ë³´ì´ëŠ” í˜¹ì€ ê°€ë ¤ì§„ ì†Œí†µì— ëŒ€í•œ ë¬¼ìŒì„ ë˜ì§„ë‹¤. ê¼´ë¼ì£¼ë¡œ ì¡°í˜•ëœ í‰ë©´ì ì¸ ì´ë¯¸ì§€ëŠ” ê¸°í•˜, ëŒ€ì¹­, ê·¸ë¦¬ê³  ìƒ‰ìƒì˜ ë‹¨ê³„ì  ì°¨ì´ ë“± ì‹œê°ì  íš¨ê³¼ë¥¼ íƒêµ¬í•œ ê²°ê³¼ë¬¼ì¸ ê²ƒì´ë‹¤. ì‘ê°€ëŠ” ì‚°ì—… ìƒì‚°ë¬¼ì¸ í¸ì§€ ë´‰íˆ¬ì˜ ìˆ˜ëª… ì£¼ê¸°ì— ëŒ€í•´ì„œ ì´ì•¼ê¸° í•˜ê³  ìˆëŠ”ë°, ì—¬ê¸°ì—ëŠ” í¸ì§€ ë´‰íˆ¬ì˜ ì´ë™ ê±°ë¦¬, ê¸°ëŠ¥, ì†Œì¬ ë° ë‹¤ì–‘í•œ ë””ìì¸ íŒ¨í„´ ë“±ì´ í¬í•¨ëœë‹¤. ì´ì œ ì‘ê°€ëŠ” ì´ì œê» ê°€ë ¤ì§€ê±°ë‚˜ ë³´í˜¸ë˜ì—ˆë˜ í¸ì§€ ë´‰íˆ¬ ì•ˆì˜ ë©”ì‹œì§€ë“¤ì„ ì¬ì¡°í•©í•¨ìœ¼ë¡œì¨, í¸ì§€ ë´‰íˆ¬ì˜ ë‹¨ëª…ì ì¸ ì¬ë£Œì  ì†ì„±ì„ ë“œëŸ¬ë‚¸ë‹¤. ê·¸ë ‡ê²Œ ì´ë¯¸ ì‚¬ìš©ëœ í›„ ì¡´ì¬ ê°€ì¹˜ê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ì—¬ê²¨ì§€ëŠ” ê³µì‚°í’ˆì— â€˜ì œ 2ì˜ ì¸ìƒâ€™ì„ ë¶€ì—¬í•œ ê²ƒì´ë‹¤. ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ì œëª©ì„ ì§€ë‹Œ ë‚±ê°œì˜ ê°œë³„ ì‘í’ˆë“¤ì€ ì „ì‹œì¥ì˜ ê±´ì¶• ê³µê°„ì— ëŒ€ì‘í•˜ë©° ì‘í’ˆ ë‚´ë¶€ì˜ ê¸°í•˜í•™ì  íŒ¨í„´ì„ í™•ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ì¹˜ëœë‹¤.\n",
      "Metadata: {'ì‘í’ˆëª…': 'ì‹ ìš©í•  ë§Œí•œ ì‚°ê³¼ êµ´ì ˆ #13, #14, #17, #22, #27, #28, #30 / N/A / Trustworthy Mountains and Refractions #13, #14, #17, #22, #27, #28, #30', 'ì‘ê°€': 'ì–‘í˜œê·œ / YANG Haegue', 'ì œì‘ ì—°ë„': '2010', 'ì¹´í…Œê³ ë¦¬': 'ë“œë¡œì‰'}\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "Content: ì‘í’ˆëª…: ì ‘í ìˆ˜ ìˆëŠ” ê²ƒë“¤ì˜ ì²´ì¡° / N/A / Gymnastics of the Foldables\n",
      "\n",
      "ì‘ê°€: ì–‘í˜œê·œ / YANG Haegue\n",
      "\n",
      "ì‘í’ˆ ë²ˆí˜¸: 6682\n",
      "\n",
      "ì œì‘ ì—°ë„: 2006\n",
      "\n",
      "í¬ê¸°: 32.8Ã—26.2Ã—(15)\n",
      "\n",
      "ì¬ë£Œ: í‘ë°±ì‚¬ì§„\n",
      "\n",
      "ì¹´í…Œê³ ë¦¬: ì‚¬ì§„\n",
      "\n",
      "ì‘í’ˆ ì„¤ëª…: ì–‘í˜œê·œëŠ” ìµœê·¼ í•œêµ­ì¸ ì‘ê°€ ì¤‘ ê°€ì¥ í™œë°œíˆ êµ­ì œì ì¸ ë¬´ëŒ€ì—ì„œ í™œë™í•˜ëŠ” ì‘ê°€ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ì„œìš¸ëŒ€ ì¡°ì†Œê³¼ì™€ í”„ë‘í¬í‘¸ë¥´íŠ¸ ì¡°í˜•ì˜ˆìˆ ì•„ì¹´ë°ë¯¸ë¥¼ ì¡¸ì—…í•œ í›„ ì£¼ë¡œ ë² ë¥¼ë¦°ì— ë¨¸ë¬¼ë©´ì„œ í•œêµ­ì„ ì˜¤ê°€ë©° ì‘í’ˆ í™œë™ì„ í•˜ê³  ìˆëŠ” ê·¸ë…€ëŠ” 2006ë…„ ìƒíŒŒìš¸ë¡œ ë¹„ì—”ë‚ ë ˆ, 2008ë…„ í† ë¦¬ë…¸ íŠ¸ë¦¬ì—”ë‚ ë ˆ, í”¼ì¸ ë²„ê·¸, LA, ëŸ°ë˜, í”„ë‘í¬í‘¸ë¥´íŠ¸ ë“±ì—ì„œ ì „ì‹œë¥¼ ê°€ì¡Œìœ¼ë©° 2009ë…„ ë² ë‹ˆìŠ¤ ë¹„ì—”ë‚ ë ˆì˜ í•œêµ­ê´€ ì‘ê°€ë¡œ ì„ ì •ë˜ë©´ì„œ êµ­ì œì  ê´€ì‹¬ì„ ëª¨ì•˜ë‹¤.ì–‘í˜œê·œì˜ ì‘ì—…ì€ í‰ë²”í•˜ê³  ì†Œì†Œí•œ ì¼ìƒì  ê²½í—˜ê³¼ ê¸°ì–µì—ì„œ ì‘í’ˆì˜ ì†Œì¬ë¥¼ ì°¾ì•„ ì´ë¥¼ ê°œë…ì ìœ¼ë¡œ ì¬í•´ì„í•˜ëŠ” ê²ƒì´ë‹¤. ë‹¤ì–‘í•œ ê°ê°ì„ ì˜ˆìˆ ì  ê²½í—˜ìœ¼ë¡œ ì¹˜í™˜ì‹œí‚¤ëŠ” ê·¸ë…€ì˜ ì‘ì—…ì€ ì—¬ì„±ì ì¸ ê°ì„±ê³¼ ì‚¬ë¬¼ì„ ë°”ë¼ë³´ëŠ” ì„¸ë°€í•œ ì‹œì„ ì„ íŠ¹ì§•ìœ¼ë¡œ í•œë‹¤.ì´ ì‘í’ˆì€ ì†Œì†Œí•œ ì¼ìƒì  ê²½í—˜ì—ì„œ ì˜ˆìˆ ì  ì†Œì¬ë¥¼ ì°¾ëŠ” ì‘ê°€ì˜ ê°œë…ì„ ê°€ì¥ ê°„ë‹¨í•˜ê³ ë„ ëª…ì§•í•˜ê²Œ ë³´ì—¬ì£¼ëŠ” ì‘í’ˆìœ¼ë¡œ ì–‘í˜œê·œì˜ ì´ˆê¸° ì‚¬ì§„ì‘ì—… ì¤‘ í•˜ë‚˜ì´ë‹¤. ìš°ë¦¬ê°€ ë§¤ì¼ ì ‘í•˜ëŠ” ë¹¨ë˜ ê±µë³´ëŒ€ë¥¼ ì—¬ëŸ¬ ìì„¸ë¡œ ë³€í˜•ì‹œì¼œ ë§ˆì¹˜ ì›€ì§ì´ëŠ” ë™ì‘ìœ¼ë¡œ ì²´ì¡°ë¥¼ í•˜ê³  ìˆëŠ” ê²ƒê³¼ ê°™ì€ í˜•ìƒì˜ ì—°ì†ì„ ë§Œë“ ë‹¤. ì‚¬ì§„ë“¤ì€ ë§¤ìš° ë©´ë°€í•˜ê²Œ ì—°ì¶œë˜ì—ˆê³  ì§€ê·¹íˆ ë¯¸ë‹ˆë©€í•œ ë°©ì‹ìœ¼ë¡œ ì„¸ì‹¬í•˜ê²Œ ì´¬ì˜ë˜ì—ˆë‹¤. ì´ëŸ¬í•œ ì´ë¯¸ì§€ëŠ” ì•½ê°„ì˜ ìœ ë¨¸ì™€ í•¨ê»˜ íŠ¹ë³„í•œ ê°ì •ì„ ë¶ˆëŸ¬ ì¼ìœ¼í‚¤ëŠ”ë° ê·¸ ê°ì •ì€ ê²°ì½” ìœ ì¾Œí•˜ì§€ë§Œì€ ì•Šì€ ê²ƒì´ë‹¤. ë‹¤ì–‘í•œ ê°ê°ì„ ì˜ˆìˆ ì  ê²½í—˜ìœ¼ë¡œ ì¹˜í™˜ì‹œí‚¤ëŠ” ê·¸ë…€ì˜ ì‘ì—…ì€ ì—¬ì„±ì ì¸ ê°ì„±ê³¼ ì‚¬ë¬¼ì„ ë°”ë¼ë³´ëŠ” ì„¸ë°€í•œ ì‹œì„ ì„ íŠ¹ì§•ìœ¼ë¡œ í•œë‹¤.\n",
      "Metadata: {'ì‘í’ˆëª…': 'ì ‘í ìˆ˜ ìˆëŠ” ê²ƒë“¤ì˜ ì²´ì¡° / N/A / Gymnastics of the Foldables', 'ì‘ê°€': 'ì–‘í˜œê·œ / YANG Haegue', 'ì œì‘ ì—°ë„': '2006', 'ì¹´í…Œê³ ë¦¬': 'ì‚¬ì§„'}\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "Content: ì‘í’ˆëª…: ì—¬ì„±í˜•ì›ì£¼ë¯¼-1.êµ¬ë³€(å£è¾¯), 2.ì‹œê³¨ì‹ ê¸°(ç¥æ°£), 3.ì² ì§€ë‚œ í¬í™”(é£½å’Œ), 4.ìŒë ¥, 5.ìˆ™ì„±, 6.ìƒê¸°ëœ ê²°ì‹¤ / N/A / Female Natives\n",
      "\n",
      "ì‘ê°€: ì–‘í˜œê·œ / YANG Haegue\n",
      "\n",
      "ì‘í’ˆ ë²ˆí˜¸: 6681\n",
      "\n",
      "ì œì‘ ì—°ë„: 2010\n",
      "\n",
      "í¬ê¸°: 1.185Ã—106Ã—106, 2.192Ã—123Ã—150, 3.197Ã—103Ã—103, 4.191Ã—84Ã—84, 5.235Ã—105Ã—105, 6.180Ã—110Ã—110\n",
      "\n",
      "ì¬ë£Œ: ì˜·ê±¸ì´, ë°”í€´, ì „êµ¬, ì „ì„ , ì¡°í™”, ë°©ìš¸, ëˆ, ë°§ì¤„, ê¸ˆì† ì²´ì¸, í„¸ì‹¤, ë§ë¦° ìƒê°•, ê¸ˆì† ê³ ë¦¬, ì•Œë£¨ë¯¸ëŠ„ ë°˜ì‚¬ê¸°, ì–‘ì²  ê¹¡í†µ, ì†ì´ ë¹ˆ ê³µ, ì¡°ê°œ ê»ë°ê¸°, ì§€ì í† , ë§ë¦° ì¸ì‚¼, ì±„ìƒ‰í•œ ëª©ì¬ ê³µ, í™”ì¥ í¼í”„, ë§ë¦° ëª©ì´ë²„ì„¯, ìˆ , í—¤ì–´ ë¡¤, ê¸ˆì† ì§‘ê²Œ, ìœ ë¦¬ ë¹„ì¦ˆ, ìŠ¤íŒ½ê¸€ íŒ¨ì¹˜\n",
      "\n",
      "ì¹´í…Œê³ ë¦¬: ì¡°ê°ã†ì„¤ì¹˜\n",
      "\n",
      "ì‘í’ˆ ì„¤ëª…: ì–‘í˜œê·œëŠ” ìµœê·¼ í•œêµ­ì¸ ì‘ê°€ ì¤‘ ê°€ì¥ í™œë°œíˆ êµ­ì œì ì¸ ë¬´ëŒ€ì—ì„œ í™œë™í•˜ëŠ” ì‘ê°€ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ì„œìš¸ëŒ€ ì¡°ì†Œê³¼ì™€ í”„ë‘í¬í‘¸ë¥´íŠ¸ ì¡°í˜•ì˜ˆìˆ ì•„ì¹´ë°ë¯¸ë¥¼ ì¡¸ì—…í•œ í›„ ì£¼ë¡œ ë² ë¥¼ë¦°ì— ë¨¸ë¬¼ë©´ì„œ í•œêµ­ì„ ì˜¤ê°€ë©° ì‘í’ˆ í™œë™ì„ í•˜ê³  ìˆëŠ” ê·¸ë…€ëŠ” 2006ë…„ ìƒíŒŒìš¸ë¡œ ë¹„ì—”ë‚ ë ˆ, 2008ë…„ í† ë¦¬ë…¸ íŠ¸ë¦¬ì—”ë‚ ë ˆ, í”¼ì¸ ë²„ê·¸, LA, ëŸ°ë˜, í”„ë‘í¬í‘¸ë¥´íŠ¸ ë“±ì—ì„œ ì „ì‹œë¥¼ ê°€ì¡Œìœ¼ë©° 2009ë…„ ë² ë‹ˆìŠ¤ ë¹„ì—”ë‚ ë ˆì˜ í•œêµ­ê´€ ì‘ê°€ë¡œ ì„ ì •ë˜ë©´ì„œ êµ­ì œì  ê´€ì‹¬ì„ ëª¨ì•˜ë‹¤.ì–‘í˜œê·œì˜ ì‘ì—…ì€ í‰ë²”í•˜ê³  ì†Œì†Œí•œ ì¼ìƒì  ê²½í—˜ê³¼ ê¸°ì–µì—ì„œ ì‘í’ˆì˜ ì†Œì¬ë¥¼ ì°¾ì•„ ì´ë¥¼ ê°œë…ì ìœ¼ë¡œ ì¬í•´ì„í•˜ëŠ” ê²ƒì´ë‹¤. ë‹¤ì–‘í•œ ê°ê°ì„ ì˜ˆìˆ ì  ê²½í—˜ìœ¼ë¡œ ì¹˜í™˜ì‹œí‚¤ëŠ” ê·¸ë…€ì˜ ì‘ì—…ì€ ì—¬ì„±ì ì¸ ê°ì„±ê³¼ ì‚¬ë¬¼ì„ ë°”ë¼ë³´ëŠ” ì„¸ë°€í•œ ì‹œì„ ì„ íŠ¹ì§•ìœ¼ë¡œ í•œë‹¤.ì´ ì‘í’ˆì€ ì£¼ë³€ì˜ ì¼ìƒì  ì‚¬ë¬¼ë“¤ì„ ì˜·ê±¸ì´ì— ê±¸ê³  ê·¸ ìœ„ì— ë¨í”„ë¥¼ ê±¸ì¹œ ì†Œìœ„ 'ê´‘ì›ì¡°ê°' ì‹œë¦¬ì¦ˆë¡œ ìƒë‹¹íˆ ë„ë¦¬ ì•Œë ¤ì§€ê²Œ ë˜ì—ˆë‹¤. ì´ëŸ¬í•œ ë¹› ì¡°ê°í’ˆì€ ê°ê°ì´ ë§ˆì¹˜ í•˜ë‚˜ì˜ ì¸ê²©ì²´ì²˜ëŸ¼ ë³´ì´ê³  ì´ë“¤ì€ ì„œë¡œ 'êµ°'ì„ ì´ë£¬ì±„ ì „ì‹œì¥ì— ë„ë ¤ ìˆë‹¤. ê°œì¸ê³¼ ê°œì¸ì˜ ì§‘í•©ì²´ë¡œì„œì˜ ì‚¬íšŒê°€ ì§€ë‹ˆëŠ” ê´€ê³„ë¥¼ ì€ìœ ì ìœ¼ë¡œ ë³´ì—¬ì£¼ê³  ìˆëŠ” ì´ ì‘í’ˆë“¤ì€ ì–´ì©” ìˆ˜ ì—†ì´ ì–½íˆê³  ì†ë°•ë˜ì§€ë§Œ ê°ìì˜ ë¹›ì„ ì§€ë‹Œ ì¸ê°„ì˜ ì‚¶ì— ëŒ€í•´ ìˆ™ê³ í•˜ê²Œ í•œë‹¤. ì´ 6ê°œì˜ ê°œë³„ ì¡´ì¬ê°€ í•œ ì‘í’ˆì„ ì´ë£¨ëŠ” <ì—¬ì„±í˜• ì›ì£¼ë¯¼-No.1 êµ¬ë³€(å£è¾¯), No.2 ì‹œê³¨ì‹ ê¸°(ç¥æ°£), No.3 ì² ì§€ë‚œ í¬í™”(é£½å’Œ), No.4 ìŒë ¥, No.5 ìˆ™ì„±, No.6 ìƒê¸°ëœ ê²°ì‹¤(Female Natives- No.1    Oratoricals, No.2 Possessed Hillbilly, No.3 Saturation out  ofSeason, No.4 Lunar Calendar, No.5 Maturing, No.6 Fruitful Glow)>ì€ ê´‘ì› ì¡°ê° ì‹œë¦¬ì¦ˆ ì¤‘ ê·¸ ê·œëª¨ì™€ ì™„ì„±ë„ê°€ ë§¤ìš° ë›°ì–´ë‚˜ë‹¤. ì¸ì¡°ë¡œ ëœ ì‹¸êµ¬ë ¤ ê½ƒì¥ì‹ë“¤ì´ í™”ë ¤í•˜ë‹¤ê¸°ë³´ë‹¤ ì˜¤íˆë ¤ ì• ì¡°ë¥¼ ìì•„ë‚´ëŠ” ì´ ì‘í’ˆë“¤ì€ ë¸Œë ˆê²ì¸  ë¯¸ìˆ ê´€ì˜ ê°œì¸ì „ì— ì¶œí’ˆë˜ì–´ í˜¸í‰ì„ ë°›ì•˜ë‹¤.\n",
      "Metadata: {'ì‘í’ˆëª…': 'ì—¬ì„±í˜•ì›ì£¼ë¯¼-1.êµ¬ë³€(å£è¾¯), 2.ì‹œê³¨ì‹ ê¸°(ç¥æ°£), 3.ì² ì§€ë‚œ í¬í™”(é£½å’Œ), 4.ìŒë ¥, 5.ìˆ™ì„±, 6.ìƒê¸°ëœ ê²°ì‹¤ / N/A / Female Natives', 'ì‘ê°€': 'ì–‘í˜œê·œ / YANG Haegue', 'ì œì‘ ì—°ë„': '2010', 'ì¹´í…Œê³ ë¦¬': 'ì¡°ê°ã†ì„¤ì¹˜'}\n",
      "--------------------------------------------------\n",
      "Document 4:\n",
      "Content: ì‘í’ˆëª…: ì•‰ì•„ìˆëŠ” ì‚° 1 / N/A / A Mountain Sitting Cross Legged\n",
      "\n",
      "ì‘ê°€: í•œì• ê·œ / HAHN Aikyu\n",
      "\n",
      "ì‘í’ˆ ë²ˆí˜¸: 6287\n",
      "\n",
      "ì œì‘ ì—°ë„: 1992\n",
      "\n",
      "í¬ê¸°: 54Ã—90Ã—35\n",
      "\n",
      "ì¬ë£Œ: ë°±í† ì¡°í•©í†  1280\n",
      "\n",
      "ì¹´í…Œê³ ë¦¬: ê³µì˜ˆ\n",
      "\n",
      "ì‘í’ˆ ì„¤ëª…: í•œì• ê·œ(1953- )ëŠ” 1994ë…„ ìì‹ ì´ ê°œì¸ì „ì—ì„œ \"ìµœê·¼ì— í•´ì˜¨ ë‚˜ì˜ ì‘ì—…ì€ í¬ê²Œ ë‘ ë¶€ë¥˜ë¡œ ë‚˜ë‰˜ëŠ”ë° ê·¸ í•˜ë‚˜ëŠ” ê·¸ë•Œ ê·¸ë•Œ ëŠë‚€ ë‹¨ìƒë“¤ì„ ê·¸ë¦¼ ì¼ê¸°ë¥¼ ê·¸ë¦¬ë“¯, ì¼ê¸°ë¥¼ ì“°ë“¯ ê·¸ë ¤ë‚˜ê°„ ê²ƒì´ê³  ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ë‚˜ì˜ ì—¬ì„±ì— ê´€í•œ ìƒê°ë“¤ì„ ë¶€í’€ë¦¬ê³  ê°ìƒ‰í•˜ì—¬ ë§Œë“  ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  ëª¨ë“  ê²ƒì€ ë¶ˆí•©ë¦¬í•˜ê³ , ëª¨ìˆœë˜ê³ , ë³‘ì ì´ê³ , ë‚©ë“í•  ìˆ˜ ì—†ëŠ” í˜„ì‹¤ì˜ ìƒí™©ì— ëŒ€í•œ 'ì™œ'ë¼ëŠ” ì§ˆë¬¸ì—ì„œ ì‹œì‘í•œë‹¤.\" ë¼ê³  ë°íŒ ë°” ìˆë‹¤.ì´ì™€ ê°™ì€ í‘œí˜„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ <ì•‰ì•„ìˆëŠ” ì‚° 1>(1992)ì€ ì—¬ì„±ì„ ë§ˆì¹˜ ëª¨ì‹ ìœ¼ë¡œì„œ íŒŒì•…í•˜ì—¬ ì‚¬íšŒì˜ êµ¬ì¡°ì  ì–µì•• ì†ì—ì„œ ë“ ë“ íˆ ìì‹ ì„ ì§€ì¼œë‚´ëŠ” ì—¬ì„±ì„ ì‘í’ˆìœ¼ë¡œ í‘œí˜„í•œ ê²ƒì´ë‹¤. 'ì—¬ì„±'ê³¼ 'ì—¬ì„±ì„±'ì˜ íƒêµ¬ë¥¼ í†µí•´ ì—¬ì„±ê³¼ ê´€ë ¨ëœ ì‚¬íšŒì˜ ì–µì••ì´ë‚˜ êµ¬ì¡°ì  ëª¨ìˆœì„ ì¼ê´€ë˜ê²Œ í‘œí˜„í•œ í•œì• ê·œì˜ ì‘í’ˆì€ í˜ë¯¸ë‹ˆì¦˜(Feminism) ë¯¸ìˆ ì„ ì—°êµ¬í•˜ëŠ”ë° ë„ì›€ì´ ë  ê²ƒì´ë‹¤.\n",
      "Metadata: {'ì‘í’ˆëª…': 'ì•‰ì•„ìˆëŠ” ì‚° 1 / N/A / A Mountain Sitting Cross Legged', 'ì‘ê°€': 'í•œì• ê·œ / HAHN Aikyu', 'ì œì‘ ì—°ë„': '1992', 'ì¹´í…Œê³ ë¦¬': 'ê³µì˜ˆ'}\n",
      "--------------------------------------------------\n",
      "Document 5:\n",
      "Content: ì‘í’ˆëª…: ê¸°ëª…ì ˆì§€ë„ / N/A / Still-Life with Vessels and Plants \n",
      "\n",
      "ì‘ê°€: ë³€ì„±ê·œ / BYUN Sungkyu\n",
      "\n",
      "ì‘í’ˆ ë²ˆí˜¸: 8406\n",
      "\n",
      "ì œì‘ ì—°ë„: N/A\n",
      "\n",
      "í¬ê¸°: 104.3x25.6, 104.5x29.3, 104.5x29.1, 104x29.3, 104.3x27.5, 104.3x28, 104.3x27.1, 104x25.5\n",
      "\n",
      "ì¬ë£Œ: ì¢…ì´ì— ë¨¹, ìƒ‰\n",
      "\n",
      "ì¹´í…Œê³ ë¦¬: íšŒí™” I\n",
      "\n",
      "ì‘í’ˆ ì„¤ëª…: ì„ì •(çŸ³äº­) ë³€ì„±ê·œ(åæˆåœ­, 1890-1962)ëŠ” ëŒ€êµ¬ì—ì„œ í•œì˜ì‚¬ë¡œ í•œì˜ì›ì„ ê²½ì˜í•˜ë©´ì„œ ì·¨ë¯¸ë¡œ ê·¸ë¦¼ì„ ë°°ì› ë‹¤. ê·¸ëŠ” ì‚¬êµ°ìë¥¼ í¬í•¨í•˜ì—¬ ê¸°ëª…ì ˆì§€, ì‚°ìˆ˜, ì¸ë¬¼, í™”ì¡° ë“± ì—¬ëŸ¬ ë¶„ì•¼ì˜ ê·¸ë¦¼ì„ ê·¸ë ¸ë‹¤. ê·¸ëŠ” ì„œì˜ˆì—ë„ ëŠ¥í•´ ê²½ë¶ ì§€ì—­ì— ìˆëŠ” ì •ìì˜ í˜„íŒì„ ë§ì´ ì¼ìœ¼ë©° ê·¸ì˜ ëŒ€í‘œì ì¸ í˜„íŒìœ¼ë¡œëŠ” â€˜ì•„ì–‘ë£¨(å³¨æ´‹æ¨“)â€™ê°€ ìˆë‹¤. ê·¸ì˜ ì‘í’ˆì€ í˜„ì¬ ëŒ€êµ¬ ì§€ì—­ì— ë‹¤ìˆ˜ ì „í•˜ë©° í•œêµ­ì„œì˜ˆë°•ë¬¼ê´€ ë“±ì—ë„ ì‘í’ˆì´ ì†Œì¥ë˜ì–´ ìˆë‹¤. ê·¸ëŠ” ì„œì–‘í™”ê°€ë¡œ ìœ ëª…í•œ ë³€ì¢…í•˜(åé˜å¤, 1926-2000)ì˜ ë¶€ì¹œì´ê¸°ë„ í•˜ë‹¤.â€˜ê¸°ëª…ì ˆì§€ë„(å™¨çš¿æŠ˜æåœ–)â€™ë€ ë¬¸ì¸ ì·¨í–¥ì˜ ì—¬ëŸ¬ ê°€ì§€ ê·¸ë¦‡ê³¼ ê½ƒê°€ì§€, ê³¼ì¼, ê´´ì„, ë¬¸ë°©êµ¬ ë“±ì˜ ì†Œì¬ë“¤ì„ í•œ í™”ë©´ì— ê·¸ë¦° ê²ƒì´ë©° ì£¼ë¡œ ê°ìƒ ë° ì¥ì‹ ìš©ë„ë¡œ ì œì‘ë˜ì—ˆë‹¤. ì´ ì‘í’ˆì€ ì„¸ë¡œë¡œ ê¸´ 8í­ì˜ í™”ë©´ì— ë§¤í™”, ì—°ê½ƒ, ëŒ€ë‚˜ë¬´, ì†Œë‚˜ë¬´ ë“± ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ê½ƒê°€ì§€ë¡œ ê¾¸ë©°ì§„ í™”ë¶„ê³¼ ì²­ë™ê¸° ë“±ì˜ ê¸°ë¬¼ì„ ì„œë¡œ ì—‡ê°ˆë¦¬ê²Œ ì‚¬ì„  êµ¬ë„ë¡œ ë°°ì¹˜í•˜ì—¬ ë¬˜ì‚¬í•œ ì‘í’ˆìœ¼ë¡œ, í™”ë©´ ì˜¤ë¥¸ìª½ì—ëŠ” ê°ê°ì˜ í™”ë©´ì— ë“±ì¥í•˜ëŠ” ê½ƒë‚˜ë¬´ì™€ ì—°ê´€ëœ ì œì‹œê°€ ì í˜€ ìˆë‹¤.[í™”ì œ í’€ì´]â—‡ ì œ1í­ä¼¼å…±æ±é¢¨åˆ¥æœ‰å›  ë´„ë°”ëŒì„ í•¨ê»˜ í•œ ë“¯í•œ íŠ¹ë³„í•œ ì¸ì—° ìˆì–´çµ³ç¾…é«˜æ²ä¸å‹æ˜¥ ë¶‰ì€ ë¹„ë‹¨ì˜· ë†’ì´ ë§ë©° ì¶˜í¥ì„ ì´ê¸°ì§€ ëª»í•˜ë„¤.â—‡ ì œ2í­éœœç¦½æ¬²ä¸‹å…ˆå¸çœ¼ ê²¨ìš¸ ì² ìƒˆê°€ ë‚ ì•„ê°€ê³  ì‹¶ì„ ë•ŒëŠ” ë¨¼ì € (ë§¤í™”ë¥¼) í›”ì³ë³´ê³ ç²‰è¶å¦‚çŸ¥åˆæ–·é­‚ ë¶„ë¶„íˆ ë‚˜ëŠ” ë‚˜ë¹„ (ë§¤í™”ì˜ ì•„ë¦„ë‹¤ì›€ì„) ì•Œë©´ ì‘ë‹¹ ë„‹ì„ ìƒìœ¼ë¦¬.â—‡ ì œ3í­è¬å·è©©æ›¸çœçœæ´»è¨ˆ ë§Œê¶Œì˜ ì‹œë¬¸ê³¼ ì„œí™”ëŠ” ì°¸ìœ¼ë¡œ ìƒí™œì˜ ê³„ì±…ì´ìš”ä¸€ç›†æ¢…ç«¹è‡ªæ·¸é¦™ ë§¤í™”ì™€ ëŒ€ ì‹¬ê¸´ í™”ë¶„ í•˜ë‚˜ëŠ” ìŠ¤ìŠ¤ë¡œ ë§‘ì€ í–¥ê¸° ë‚´ ë¿œëŠ”ë‹¤.â—‡ ì œ4í­æœˆç¼ºéœœæ¿ƒç´°è˜‚ç™¼ ë‹¬ì€ ì´ì§€ëŸ¬ì§€ê³  ì„œë¦¬ ì§™ë”ë‹ˆ ê°€ëŠ” ê½ƒìˆ ì´ í”¼ì–´ë‚¬ë„¤.æ­¤èŠ±å…ƒå±¬æ¡‚å ‚ä»™ ì´ ê½ƒì€ ì›ë˜ ê³„ìˆ˜ë‚˜ë¬´ ì§‘ ì‚´ë˜ ì‹ ì„ ì˜ ê²ƒì´ì—ˆë‹¤ì§€.â—‡ ì œ5í­éœ²æ¿•ç´…èŠ³è¤‡æœ¶é‡ ë¶‰ì€ ê½ƒ ì—¬ëŸ¬ ì†¡ì´ ì´ìŠ¬ì— ê±°ë“­ ì –ì–´ë“¤ê³ ,é¢¨æ–ç¶ å¸¶ä¸€æé•· í‘¸ë¥¸ ë  ê°™ì€ ê¸°ë‹¤ë€ ê°€ì§€ë¥¼ ë°”ëŒì´ í”ë“ ë‹¤.â—‡ ì œ6í­åƒç´…ç™¾æœçš†é›¶è½ ì˜¨ê°– ê½ƒê³¼ ê³¼ì¼ë“¤ ì£„ ë–¨ì–´ì§€ëŠ”ë°æ¢§è‘‰è•­è•­çˆ¾ç¨é¦™ ì˜¤ë™ì ì“¸ì“¸í•˜ë‹ˆ ë„ˆ í™€ë¡œ í–¥ê¸°ë¡­êµ¬ë‚˜.â—‡ ì œ7í­é›ªç™½çŒ©ç´…å¤šåˆ¥ç¨® ëˆˆì²˜ëŸ¼ í° ê²ƒ, ì›ìˆ­ì´ ê°™ì´ ë¶‰ì€ ê²ƒ, ì¢…ë¥˜ê°€ ë§ê¸°ë„ í•˜ì§€ë§Œ,ä¹ŸçŸ¥é»ƒè‰²ã¡å±…é ­ ê·¸ ì¤‘ì—ì„œ í™©ìƒ‰ ê½ƒì„ ê°€ì¥ ìœ¼ëœ¸ì— ë†“ëŠ”ë‹¤ ì•Œê³  ìˆë‹¤ë„¤.â—‡ ì œ8í­ç›†ä¸­åƒè“‹ä¸çŸ¥å¹´ í™”ë¶„ ì† ëˆ„ìš´ ì†Œë‚˜ë¬´ ë‚˜ì´ë¥¼ ì•Œì§€ ëª»í•˜ëŠ”ë°åŠæ‹‚ç«¹(?)åŠé¿çƒŸ ë°˜ì¯¤ ë–¨ì¹œ ëŒ€ë‚˜ë¬´ â€˜ë¬´ì—‡â€™ì´ ë°˜ì¯¤ ì—°ê¸°ë¥¼ í”¼í–ˆêµ¬ë‚˜.\n",
      "Metadata: {'ì‘í’ˆëª…': 'ê¸°ëª…ì ˆì§€ë„ / N/A / Still-Life with Vessels and Plants', 'ì‘ê°€': 'ë³€ì„±ê·œ / BYUN Sungkyu', 'ì œì‘ ì—°ë„': 'N/A', 'ì¹´í…Œê³ ë¦¬': 'íšŒí™” I'}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1464/3695306690.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"Content: {doc.page_content}\")  # ë¬¸ì„œì˜ ì‹¤ì œ ë‚´ìš©\n",
    "    print(f\"Metadata: {doc.metadata}\")    # ë©”íƒ€ë°ì´í„° (ì˜ˆ: ì¶œì²˜, í˜ì´ì§€ ë“±)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b13d46-a624-421e-80bd-f1f041d77b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ ìˆ˜í–‰: ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ë°˜í™˜\n",
    "docs_and_scores = retriever.vectorstore.similarity_search_with_score(query, k=5)\n",
    "\n",
    "# ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ ì¶œë ¥\n",
    "print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs_and_scores)}\")\n",
    "\n",
    "# ê° ë¬¸ì„œì˜ íŒŒì¼ëª…, ì „ì²´ ë‚´ìš©, ìœ ì‚¬ë„ ì ìˆ˜ ì¶œë ¥\n",
    "for i, (doc, score) in enumerate(docs_and_scores, 1):\n",
    "    print(f\"\\në¬¸ì„œ {i}:\")\n",
    "    print(f\"  íŒŒì¼ëª…: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(f\"  ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}\")\n",
    "    print(f\"  ì „ì²´ ë‚´ìš©: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a46bc8",
   "metadata": {},
   "source": [
    "### PDF DBì— ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227476a-1804-4ac4-89dc-4197c5ed6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from langchain_core.documents import Document\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# 1. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "embedding_model = SentenceTransformer(\"nlpai-lab/KURE-v1\")\n",
    "\n",
    "# 2. FAISS ì¸ë±ìŠ¤ ë¡œë“œ ë° L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤ ì‚¬ìš©\n",
    "def load_existing_faiss_db(index_path, embedding_dim):\n",
    "    try:\n",
    "        faiss_index = faiss.read_index(index_path)  # ê¸°ì¡´ FAISS DB ë¡œë“œ\n",
    "        print(f\"FAISS index loaded from {index_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading FAISS index from {index_path}. Error: {e}\")\n",
    "        # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤ ìƒˆë¡œ ìƒì„± (embedding_dim: ë²¡í„° ì°¨ì›)\n",
    "        faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
    "        print(\"ìƒˆë¡œìš´ FAISS L2 ì¸ë±ìŠ¤ ìƒì„±.\")\n",
    "    return faiss_index\n",
    "\n",
    "\n",
    "# 3. PDFì—ì„œ í…ìŠ¤íŠ¸ì™€ í‘œë¥¼ ë¬¸ë‹¨ë³„ë¡œ ì¶”ì¶œ\n",
    "def extract_text_paragraphs(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF ë¬¸ì„œì—ì„œ ë¬¸ë‹¨ë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í‘œëŠ” ì œì™¸)\n",
    "    \"\"\"\n",
    "    doc_list = []\n",
    "    pdf_doc = fitz.open(pdf_path)  # PyMuPDFë¡œ PDF ì—´ê¸°\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num in range(len(pdf_doc)):\n",
    "            page = pdf_doc[page_num]\n",
    "\n",
    "            # í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ êµ¬ë¶„)\n",
    "            text = page.get_text(\"text\")\n",
    "            paragraphs = text.split(\"\\n\\n\")  # ë¹ˆ ì¤„ë¡œ ë¬¸ë‹¨ êµ¬ë¶„\n",
    "\n",
    "            # í‘œ ì¶”ì¶œ\n",
    "            tables = pdf.pages[page_num].extract_tables()\n",
    "            table_texts = []\n",
    "            if tables:\n",
    "                for table in tables:\n",
    "                    df = pd.DataFrame(table[1:], columns=table[0])  # ì²« í–‰ì„ ì»¬ëŸ¼ìœ¼ë¡œ ì„¤ì •\n",
    "                    table_texts.append(df.to_string())\n",
    "            else:\n",
    "                table_texts = []  # í‘œê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "            # ë¬¸ì„œ ê°ì²´ ìƒì„± (ë¬¸ë‹¨ë³„ë¡œ ì¶”ê°€)\n",
    "            for para in paragraphs:\n",
    "                doc = Document(\n",
    "                    page_content=para + \"\\n\\n\" + \"\\n\\n\".join(table_texts),  # ë¬¸ë‹¨ + í‘œ í¬í•¨\n",
    "                    metadata={\"page\": page_num + 1}  # í˜ì´ì§€ ì •ë³´ í¬í•¨\n",
    "                )\n",
    "                doc_list.append(doc)\n",
    "\n",
    "    return doc_list\n",
    "\n",
    "# 4. í…ìŠ¤íŠ¸ ë²¡í„°í™” (SentenceTransformer ì‚¬ìš©)\n",
    "def text_to_vector(text):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (SentenceTransformer ì‚¬ìš©)\n",
    "    \"\"\"\n",
    "    vector = embedding_model.encode(text)  # ë°”ë¡œ numpy ë°°ì—´ ë°˜í™˜\n",
    "    return vector\n",
    "\n",
    "\n",
    "# 5. FAISS DBì— ìƒˆë¡œìš´ ë¬¸ì„œ ì¶”ê°€ (ê¸°ì¡´ ì¸ë±ìŠ¤ IDì™€ ê²¹ì¹˜ì§€ ì•Šê²Œ ì¶”ê°€)\n",
    "def add_pdf_to_faiss(pdf_path, faiss_index, docstore, index_to_docstore_id):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ PDFì—ì„œ ë¬¸ë‹¨ì„ ì¶”ì¶œí•˜ê³  FAISS ì¸ë±ìŠ¤ì— ì¶”ê°€ (ì§„í–‰ ìƒí™© ì¶œë ¥)\n",
    "    \"\"\"\n",
    "    # ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ì— ì¶”ê°€ëœ ë²¡í„° ìˆ˜ íŒŒì•… (ìƒˆë¡œìš´ ë²¡í„° IDê°€ ê¸°ì¡´ê³¼ ê²¹ì¹˜ì§€ ì•Šë„ë¡ í•¨)\n",
    "    existing_vector_count = faiss_index.ntotal\n",
    "    print(f\"ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ì˜ ë²¡í„° ìˆ˜: {existing_vector_count}\")\n",
    "\n",
    "    # PDFì—ì„œ ë¬¸ë‹¨ë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "    documents = extract_text_paragraphs(pdf_path)\n",
    "    \n",
    "    # ë¬¸ì„œì˜ ì´ ë¬¸ë‹¨ ìˆ˜\n",
    "    total_paragraphs = len(documents)\n",
    "    \n",
    "    # ë¬¸ë‹¨ ë²¡í„°í™”\n",
    "    vectors = []\n",
    "    for idx, doc in enumerate(documents):\n",
    "        # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "        progress = (idx + 1) / total_paragraphs * 100\n",
    "        print(f\"ì§„í–‰ ìƒí™©: {progress:.2f}% - {idx+1}/{total_paragraphs} ë¬¸ë‹¨ ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # ë¬¸ë‹¨ ë²¡í„°í™”\n",
    "        vector = text_to_vector(doc.page_content)\n",
    "        vectors.append(vector)\n",
    "\n",
    "        # ë¬¸ì„œ IDì™€ ë¬¸ì„œ ë‚´ìš© ì €ì¥ (docstore)\n",
    "        doc_id = existing_vector_count + len(vectors) - 1  # docstoreì— ìƒˆ ë¬¸ì„œì˜ IDëŠ” ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ + 1\n",
    "        docstore[doc_id] = doc\n",
    "        index_to_docstore_id[existing_vector_count + idx] = str(doc_id)  # ë²¡í„° IDì™€ ë¬¸ì„œ ID ì—°ê²°\n",
    "\n",
    "    # ë²¡í„°ë¥¼ FAISS DBì— ì¶”ê°€\n",
    "    vectors = np.array(vectors).astype('float32')\n",
    "    \n",
    "    # ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ì— ë²¡í„° ì¶”ê°€\n",
    "    faiss_index.add(vectors)\n",
    "\n",
    "    # FAISS DB ì €ì¥\n",
    "    faiss.write_index(faiss_index, \"./faiss_artworks_0303/index.faiss\")\n",
    "    print(f\"FAISS index updated and saved to './faiss_artworks_0303/index.faiss'.\")\n",
    "\n",
    "# 6. ì „ì²´ ì‹¤í–‰ íë¦„\n",
    "if __name__ == \"__main__\":\n",
    "    # ë²¡í„° ì°¨ì› í¬ê¸° (SentenceTransformer ëª¨ë¸ì— ë§ëŠ” ì°¨ì›)\n",
    "    embedding_dim = 768  # ì˜ˆì‹œ: KURE-v1 ëª¨ë¸ì€ 768ì°¨ì›\n",
    "\n",
    "    # ê¸°ì¡´ FAISS DB ë¡œë“œ (ê¸°ì¡´ ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)\n",
    "    faiss_index = load_existing_faiss_db(\"./faiss_artworks_0303/index.faiss\", embedding_dim)\n",
    "\n",
    "    # ë¬¸ì„œ ì €ì¥ì†Œ ì´ˆê¸°í™” (ë¬¸ì„œ IDì™€ ë‚´ìš© ë§¤í•‘)\n",
    "    docstore = {}\n",
    "    index_to_docstore_id = {i: i for i in range(len(docstore))}\n",
    "\n",
    "    # ìƒˆë¡œìš´ PDF íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
    "    pdf_path = './PDF/dataset/artworks_10.pdf'\n",
    "\n",
    "    # ìƒˆ PDF ë¬¸ì„œë¥¼ ê¸°ì¡´ FAISS DBì— ì¶”ê°€\n",
    "    add_pdf_to_faiss(pdf_path, faiss_index, docstore, index_to_docstore_id)\n",
    "\n",
    "    # ìƒˆë¡œìš´ ë¬¸ì„œê°€ docstoreì— ì˜ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "    print(f\"í˜„ì¬ ë¬¸ì„œ ì €ì¥ì†Œì— ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜: {len(docstore)}\")\n",
    "    print(f\"ì²« ë²ˆì§¸ ë¬¸ì„œ ID: {list(docstore.keys())[0]}\")\n",
    "    print(f\"ì²« ë²ˆì§¸ ë¬¸ì„œ ë‚´ìš©: {docstore[list(docstore.keys())[0]].page_content[:100]}...\")  # ì²« 100ê¸€ìë§Œ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734ff200",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2317b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ë¬¸ì„œ ID: {list(docstore.keys())[10]}\")\n",
    "print(f\"ì²« ë²ˆì§¸ ë¬¸ì„œ ë‚´ìš©: {docstore[list(docstore.keys())[10]].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"ë¶€ì‚° ì „ì°¨ êµ¬ì¡°ì•ˆì „ì§„ë‹¨ ë° ë³´ì¡´ì²˜ë¦¬ì—ì„œ ì°¨ëŸ‰ êµ¬ì¡°ëŠ” ì–´ë–»ê²Œ ë˜ì—ˆëŠ”ê°€?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe29183",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"question\": query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62d908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§¤í•‘ëœ ë¬¸ì„œ ID í™•ì¸\n",
    "for vector_id in range(faiss_index.ntotal):\n",
    "    if vector_id in index_to_docstore_id:\n",
    "        doc_id = index_to_docstore_id[vector_id]\n",
    "        print(f\"ë²¡í„° ID: {vector_id}, ë¬¸ì„œ ID: {doc_id}, ë¬¸ì„œ ë‚´ìš©: {docstore[doc_id].page_content[:100]}...\")\n",
    "    else:\n",
    "        print(f\"ë²¡í„° ID: {vector_id}ì— ëŒ€í•œ ë¬¸ì„œ IDê°€ ë§¤í•‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be890d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_0217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
