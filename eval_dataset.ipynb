{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG 성능 테스트를 위한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드|\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# LangSmith 추적 비활성화\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA 데이터셋이 생성되었습니다: ./qa_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# JSON 파일 로드\n",
    "json_path = \"./json_data.json\"  # JSON 파일 경로\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    artworks = json.load(f)\n",
    "\n",
    "# 질문 템플릿\n",
    "question_templates = {\n",
    "    \"year\": \"'{artist}'의 '{title}'은(는) 몇 년도에 제작되었나요?\",\n",
    "    \"size\": \"'{artist}'의 '{title}' 크기는 어떻게 되나요?\",\n",
    "    \"materials\": \"'{artist}'의 '{title}' 제작에 사용된 소재는 무엇인가요?\",\n",
    "    \"category\": \"'{artist}'의 '{title}'은(는) 어떤 카테고리에 속하나요?\",\n",
    "    \"artwork_number\": \"'{artist}'의 '{title}'의 작품 번호는 무엇인가요?\"\n",
    "}\n",
    "\n",
    "# 평가 데이터 생성\n",
    "qa_dataset = []\n",
    "random.shuffle(artworks)  # 무작위로 섞기\n",
    "selected_artworks = artworks[:100]  # 100개 선택\n",
    "\n",
    "for artwork in selected_artworks:\n",
    "    available_keys = [key for key in question_templates if key in artwork and artwork[key]]  # 값이 존재하는 필드만 사용\n",
    "    if available_keys:\n",
    "        selected_key = random.choice(available_keys)  # 랜덤하게 하나 선택\n",
    "        question = question_templates[selected_key].format(artist=artwork['artist'], title=artwork['title'])\n",
    "        answer = artwork[selected_key]\n",
    "\n",
    "        qa_dataset.append({\n",
    "            \"text\": f\"<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response in Korean that appropriately completes the request.\\n\\n\"\n",
    "                    f\"### Instruction:\\n{question}\\n\\n\"\n",
    "                    f\"### Input:\\n\\n\\n\"\n",
    "                    f\"### Response:\\n{answer}<|endoftext|>\"\n",
    "        })\n",
    "\n",
    "# JSON 파일 저장\n",
    "json_output_path = \"./qa_dataset.json\"\n",
    "with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"QA 데이터셋이 생성되었습니다: {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ QA 데이터셋이 생성되었습니다: ./qa_dataset_full_info_0209.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# JSON 파일 로드\n",
    "json_path = \"./json_data.json\"  # JSON 파일 경로\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    artworks = json.load(f)\n",
    "\n",
    "# 평가 데이터 생성\n",
    "qa_dataset = []\n",
    "random.shuffle(artworks)  # 무작위로 섞기\n",
    "selected_artworks = artworks[:100]  # 100개 선택\n",
    "\n",
    "for artwork in selected_artworks:\n",
    "    if \"artist\" in artwork and \"title\" in artwork:\n",
    "        question = f\"'{artwork['artist']}'의 '{artwork['title']}'에 대해 설명해주세요.\"\n",
    "\n",
    "        # ✅ key 없이 value만 추출하여 문자열로 변환\n",
    "        answer = \" \".join(str(value) for value in artwork.values() if value)  # 빈 값 제외하고 이어붙이기\n",
    "\n",
    "        qa_dataset.append({\n",
    "            \"text\": f\"<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response in Korean that appropriately completes the request.\\n\\n\"\n",
    "                    f\"### Instruction:\\n{question}\\n\\n\"\n",
    "                    f\"### Input:\\n\\n\\n\"\n",
    "                    f\"### Response:\\n{answer}<|endoftext|>\"\n",
    "        })\n",
    "\n",
    "# JSON 파일 저장\n",
    "json_output_path = \"./qa_dataset_full_info_0209.json\"\n",
    "with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"✅ QA 데이터셋이 생성되었습니다: {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data/qa_dataset.json 파일에서 데이터 불러오기\n",
    "with open(\"./qa_dataset_full_info_0209.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "# 데이터 100개 랜덤 추출\n",
    "random.seed(42)  # 재현성을 위한 시드 설정\n",
    "sampled_data = random.sample(data_list, 100)\n",
    "\n",
    "# Langsmith 형식으로 변환 함수\n",
    "def convert_to_langsmith_format(data_list):\n",
    "    questions, answers = [], []\n",
    "    for data in data_list:\n",
    "        text = data[\"text\"]\n",
    "        \n",
    "        # Instruction 추출\n",
    "        instruction_start = text.find(\"### Instruction:\\n\") + len(\"### Instruction:\\n\")\n",
    "        instruction_end = text.find(\"\\n\\n### Input:\")\n",
    "        question = text[instruction_start:instruction_end].strip()\n",
    "        \n",
    "        # Response 추출\n",
    "        response_start = text.find(\"### Response:\\n\") + len(\"### Response:\\n\")\n",
    "        response_end = text.find(\"<|endoftext|>\")\n",
    "        answer = text[response_start:response_end].strip()\n",
    "        \n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "    return pd.DataFrame({\"question\": questions, \"answer\": answers})\n",
    "\n",
    "# 변환 실행\n",
    "df = convert_to_langsmith_format(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'이기영'의 '정 -01.02'에 대해 설명해주세요.</td>\n",
       "      <td>{\\n    \"title\": \"정 -01.02\",\\n    \"title_ch\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'장성순'의 '작품 59-B'에 대해 설명해주세요.</td>\n",
       "      <td>{\\n    \"title\": \"작품 59-B\",\\n    \"title_ch\": \"N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'김차섭'의 '자화상'에 대해 설명해주세요.</td>\n",
       "      <td>{\\n    \"title\": \"자화상\",\\n    \"title_ch\": \"自畵像\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'신현조'의 '고부(姑婦)'에 대해 설명해주세요.</td>\n",
       "      <td>{\\n    \"title\": \"고부(姑婦)\",\\n    \"title_ch\": \"姑婦...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'윤향란'의 '버섯'에 대해 설명해주세요.</td>\n",
       "      <td>{\\n    \"title\": \"버섯\",\\n    \"title_ch\": \"N/A\",\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question  \\\n",
       "0  '이기영'의 '정 -01.02'에 대해 설명해주세요.   \n",
       "1   '장성순'의 '작품 59-B'에 대해 설명해주세요.   \n",
       "2       '김차섭'의 '자화상'에 대해 설명해주세요.   \n",
       "3    '신현조'의 '고부(姑婦)'에 대해 설명해주세요.   \n",
       "4        '윤향란'의 '버섯'에 대해 설명해주세요.   \n",
       "\n",
       "                                              answer  \n",
       "0  {\\n    \"title\": \"정 -01.02\",\\n    \"title_ch\": \"...  \n",
       "1  {\\n    \"title\": \"작품 59-B\",\\n    \"title_ch\": \"N...  \n",
       "2  {\\n    \"title\": \"자화상\",\\n    \"title_ch\": \"自畵像\",...  \n",
       "3  {\\n    \"title\": \"고부(姑婦)\",\\n    \"title_ch\": \"姑婦...  \n",
       "4  {\\n    \"title\": \"버섯\",\\n    \"title_ch\": \"N/A\",\\...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset_csv/qa_0209.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith 데이터셋 100개 업로드가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from langsmith import Client\n",
    "import pandas as pd\n",
    "\n",
    "# data/qa_dataset.json 파일에서 데이터 불러오기\n",
    "with open(\"./qa_dataset_0209.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "# 데이터 100개 랜덤 추출\n",
    "random.seed(42)  # 재현성을 위한 시드 설정\n",
    "sampled_data = random.sample(data_list, 100)\n",
    "\n",
    "# Langsmith 형식으로 변환 함수\n",
    "def convert_to_langsmith_format(data_list):\n",
    "    questions, answers = [], []\n",
    "    for data in data_list:\n",
    "        text = data[\"text\"]\n",
    "        \n",
    "        # Instruction 추출\n",
    "        instruction_start = text.find(\"### Instruction:\\n\") + len(\"### Instruction:\\n\")\n",
    "        instruction_end = text.find(\"\\n\\n### Input:\")\n",
    "        question = text[instruction_start:instruction_end].strip()\n",
    "        \n",
    "        # Response 추출\n",
    "        response_start = text.find(\"### Response:\\n\") + len(\"### Response:\\n\")\n",
    "        response_end = text.find(\"<|endoftext|>\")\n",
    "        answer = text[response_start:response_end].strip()\n",
    "        \n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "    return pd.DataFrame({\"question\": questions, \"answer\": answers})\n",
    "\n",
    "# 변환 실행\n",
    "df = convert_to_langsmith_format(sampled_data)\n",
    "\n",
    "# Langsmith Client 연결\n",
    "client = Client()\n",
    "dataset_name = \"RAG_EVAL_DATASET_NEW\"\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def create_dataset(client, dataset_name, description=None):\n",
    "    for dataset in client.list_datasets():\n",
    "        if dataset.name == dataset_name:\n",
    "            return dataset\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=description,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = create_dataset(client, dataset_name)\n",
    "\n",
    "# 생성된 데이터셋에 예제 추가\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in df[\"question\"].tolist()],\n",
    "    outputs=[{\"answer\": a} for a in df[\"answer\"].tolist()],\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n",
    "print(\"Langsmith 데이터셋 100개 업로드가 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'배만실'의 '태고의 흔적'은(는) 어떤 카테고리에 속하나요?</td>\n",
       "      <td>공예</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'황규백'의 '당구'은(는) 어떤 카테고리에 속하나요?</td>\n",
       "      <td>판화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'손일봉'의 '정자'의 작품 번호는 무엇인가요?</td>\n",
       "      <td>2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'임홍순'의 '고비' 크기는 어떻게 되나요?</td>\n",
       "      <td>120×30×6×(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'황규태'의 '픽셀'은(는) 어떤 카테고리에 속하나요?</td>\n",
       "      <td>사진</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             question        answer\n",
       "0  '배만실'의 '태고의 흔적'은(는) 어떤 카테고리에 속하나요?            공예\n",
       "1      '황규백'의 '당구'은(는) 어떤 카테고리에 속하나요?            판화\n",
       "2          '손일봉'의 '정자'의 작품 번호는 무엇인가요?          2434\n",
       "3            '임홍순'의 '고비' 크기는 어떻게 되나요?  120×30×6×(2)\n",
       "4      '황규태'의 '픽셀'은(는) 어떤 카테고리에 속하나요?            사진"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chae/faiss_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:25<00:00,  3.69s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "\n",
    "# 모델과 토크나이저 로드 (CUDA 사용)\n",
    "model_id = \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"cuda\",  # CUDA에서 자동 배치\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "/tmp/ipykernel_15545/1315975019.py:15: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 파이프라인 생성\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,  # 생성할 최대 토큰 수 증가\n",
    "    do_sample=True,        # 샘플링 활성화\n",
    "    temperature=0.1,      \n",
    "    top_k=50,             \n",
    "    repetition_penalty=1.05\n",
    ")\n",
    "# LangChain의 HuggingFacePipeline 사용\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = '''\n",
    "<|system|>\n",
    "You are a friendly chatbot specializing in artworks. \n",
    "Answer questions strictly based on the information provided in the document (context). \n",
    "If the requested information is not found in the document, respond with \"The document does not contain this information.\" \n",
    "Provide comprehensive answers, always include the artwork number, and ensure all answers are written in Korean. \n",
    "All answers should be formatted using beautiful Markdown syntax to make the response visually appealing and easy to read. \n",
    "Use headings, bullet points, and bold or italic text where appropriate to enrich the response.\n",
    "\n",
    "<|context|>\n",
    "{context}\n",
    "\n",
    "<|user|>\n",
    "Question: {question}\n",
    "\n",
    "<|assistant|>\n",
    "'''\n",
    "\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 데이터베이스가 성공적으로 로드되었습니다!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"nlpai-lab/KURE-v1\")\n",
    "\n",
    "\n",
    "# 기존 DB 로드 \n",
    "persist_directory = \"./faiss_artworks_0114_docx\"\n",
    "\n",
    "try:\n",
    "    faiss_db = FAISS.load_local(\n",
    "        folder_path=persist_directory,\n",
    "        embeddings=embedding_model,\n",
    "        allow_dangerous_deserialization=True  # 신뢰할 수 있는 소스에서만 사용\n",
    "    )\n",
    "    \n",
    "    # embedding_function 수정\n",
    "    faiss_db.embedding_function = lambda text: (\n",
    "        embedding_model.encode(text) if isinstance(text, str) else embedding_model.encode(str(text))\n",
    "    )\n",
    "    \n",
    "    print(\"FAISS 데이터베이스가 성공적으로 로드되었습니다!\")\n",
    "except Exception as e:\n",
    "    print(f\"FAISS 데이터베이스 로드 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_db.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                # 검색 결과 개수\n",
    "        \"fetch_k\": 20,         # 더 많은 결과 가져오기\n",
    "        \"mmr\": True,           # MMR 활성화\n",
    "        \"mmr_beta\": 0.8      # 다양성과 관련성 간 균형\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class MarkdownOutputParser:\n",
    "    \"\"\"Enhanced Markdown parser with additional formatting options.\"\"\"\n",
    "\n",
    "    def __call__(self, llm_output):\n",
    "        # <assistant> 이후의 텍스트만 추출\n",
    "        match = re.search(r\"<\\|assistant\\|>\\s*(.*)\", llm_output, re.DOTALL)\n",
    "        if match:\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # 마크다운 코드 블록으로 출력 포맷\n",
    "            return f\"### 모델 결과\\n\\n{extracted_text}\\n\\n\"\n",
    "        else:\n",
    "            # <assistant> 태그가 없는 경우 원래 출력 반환\n",
    "            return f\"### 모델 결과\\n\\n{llm_output.strip()}\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough, RunnableMap\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": retriever,               # Retriever에서 반환된 값을 가져옴\n",
    "        \"question\": RunnablePassthrough()   # 질문은 그대로 전달\n",
    "    })\n",
    "    | (lambda x: {\n",
    "        \"context\": \"\\n\".join([doc.page_content for doc in x[\"context\"]]),\n",
    "        \"question\": x[\"question\"]\n",
    "    })  # context를 문자열로 변환\n",
    "    | prompt                               # Prompt Template에 전달\n",
    "    | llm                                  # LLM으로 응답 생성\n",
    "    | MarkdownOutputParser()                    # 응답을 문자열로 변환\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 모델 결과\n",
      "\n",
      "**노란 저고리**는 **김종태** 작가의 작품입니다.  \n",
      "**작품 번호**: 128  \n",
      "**제작 연도**: 1929\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"노란저고리는 누구 작품인가요?\"\n",
    "response = chain.invoke({\"question\": query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '### 모델 결과\\n\\n**노란 저고리**는 **김종태** 작가의 작품입니다. 작품 번호는 **PA-00128**입니다.\\n\\n'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자 질문 예시\n",
    "llm_answer = ask_question(\n",
    "    {\"question\": \"노란저고리는 누구 작품인가요?\"}\n",
    ")\n",
    "llm_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator prompt 출력을 위한 함수\n",
    "def print_evaluator_prompt(evaluator):\n",
    "    return evaluator.evaluator.prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-Answer Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a teacher grading a quiz.\n",
      "You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
      "\n",
      "Example Format:\n",
      "QUESTION: question here\n",
      "STUDENT ANSWER: student's answer here\n",
      "TRUE ANSWER: true answer here\n",
      "GRADE: CORRECT or INCORRECT here\n",
      "\n",
      "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
      "\n",
      "QUESTION: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n",
      "STUDENT ANSWER: \u001b[33;1m\u001b[1;3m{result}\u001b[0m\n",
      "TRUE ANSWER: \u001b[33;1m\u001b[1;3m{answer}\u001b[0m\n",
      "GRADE:\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# qa 평가자 생성\n",
    "qa_evalulator = LangChainStringEvaluator(\"qa\")\n",
    "\n",
    "# 프롬프트 출력\n",
    "print_evaluator_prompt(qa_evalulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: RAG_EVAL_DATASET, ID: b2eb4069-1183-45d7-a21e-5ede0db30bca\n",
      "Dataset Name: RAG_EVAL_DATASET_NEW, ID: 77cefd19-3314-4440-8ba8-f05ea51fb422\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# LangSmith에 존재하는 데이터셋 리스트 출력\n",
    "datasets = list(client.list_datasets())\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Dataset Name: {dataset.name}, ID: {dataset.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'RAG_EVAL-2da95c4c' at:\n",
      "https://smith.langchain.com/o/a89b03f2-9920-4620-a0d1-5b700d444e04/datasets/d5f446c6-5b3c-47fd-a73e-d8d0c7079921/compare?selectedSessions=31a85e88-5669-4f38-b899-4eb854f5d13a\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [06:56,  4.16s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"RAG_EVAL_DATASET_NEW\"\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[qa_evalulator],\n",
    "    experiment_prefix=\"RAG_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"QA Evaluator 를 활용한 평가 (1024)\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: RAG_EVAL_DATASET, ID: b2eb4069-1183-45d7-a21e-5ede0db30bca\n",
      "Dataset Name: RAG_EVAL_DATASET_NEW, ID: 77cefd19-3314-4440-8ba8-f05ea51fb422\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'김기승'의 '진신(전서)'에 대해 설명해주세요.\"} outputs={'answer': '원곡(原谷) 김기승(1909-2000)은 한국 현대 서예사의 대표적인 작가이다. 1946년 소전(素筌) 손재형(孫在馨) 문하에 들어가 본격적인 서예공부를 시작하였고, 《제1-4회 대한민국미술전람회》(1949, 1953-1955)까지 잇달아 서예부 특선을 차지하여 문교부장관상을 수상하였다. 1955년에는 대성서예원(大成書藝院)을 설립하였고, 1978년에는 원곡서예상(原谷書藝賞)을 제정하기도 하였다.김기승은 《제10회 대한민국미술전람회》(1961)의 취지문에서 \"한국적 향기와 한국인의 체취를 풍기는 작품을 제작하기 위하여 온몸을 혹사하면서까지 많은 노력을 기울였으며, 서예의 경지를 어느 단계에 끌어올리려고 정성을 다하였다\"라고 언급한 바 있다. 한국적 정취를 효과적으로 드러내면서도 특정 형식이나 글자 형태에 제한되지 않고 새롭고 율동적인 필세와 개성적인 감각을 추구하는 김기승의 작품들은 작가의 이러한 취지를 잘 드러낸다.또한 김기승은 원곡체(原谷體)를 만들어내고 묵영(墨映)을 창안하는 등, 서예계의 원로임에도 불구하고 새로움을 추구하는 데 게을리 하지 않은 작가이다. 원곡 자신이 전위적이라고 말하는 \\'묵영\\'이란 청묵(靑墨)의 번짐을 사용하거나 먹물의 농담을 이용하여 시각효과를 부각시킨 회화적 서예이다. 일부에서 묵영을 \\'전통을 무시한 예술\\'이라고 몰아붙이자 \"전통을 지키기 위해서는 다각적인 실험작업을 통해 새로운 조형언어를 만들어내야 한다\"고 맞설 정도로 원곡은 새로움을 추구하였다.이 작품에서 김기승은 \\'眞神(진신: 참 정신)’이라는 내용을 전서(篆書)로 표현하였는데, ‘진(眞)’자는 안정감이 있게 하고 ‘신(神)’자는 정신이 날아오르는 듯 표현을 하였다. 차분한 필획과 갈필이 적당하게 들어 있는 활달한 필획이 조화를 잘 이루었고 ‘진(眞)’자 아래에 자리한 협서(脇書)와 좌측에 쓴 협서도 전체 작품과 조화를 잘 이루고 있다.[작품해석]참 정신, 문에 이르기를 참 정신이라.태초 창조시에는, 천지가 높이 매달려 있고, 해와 달 뭇 별들이, 밤낮을 밝게 비추었으며, 만류의 연월과 일시가 분명하게 되었다.'} metadata={'dataset_split': ['base']} id=UUID('a33469a8-b612-4688-b5f0-a16057a397ee') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18379, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18379, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'이유태'의 '설악영봉(雪嶽靈峯)'에 대해 설명해주세요.\"} outputs={'answer': '금강산이나 한국의 자연풍경을 실경적 시각으로 해석하고 있는 현초(玄艸) 이유태(1916-1999)의 <설악영봉>(1965)은 수려한 담채미와 깊이 있는 먹색, 자유로운 필선의 조화를 바탕으로 제작되었다. 특히, 먹색의 농담조절과 갈필(渴筆)준을 이용한 용필법은 이 작품의 전통적 해석과 현대적 표현감각을 뒷받침하는 중요한 요소라고 말할 수 있다. 동양화의 전통 구도법 중 하나인 평원법과 고원법을 응용하여 표현된 이 작품은 가느다란 선묘의 율동이 두드러지면서도 고즈넉한 자연의 이미지가 은자적인 정서미로 승화되고 있으며 예부터 전래되어온 우리 전통 동양화의 조형적 기법과 특성을 잘 보여주는 매우 뛰어난 이유태의 대표작 중 하나라고 볼 수 있다.평소 마치 바탕의 화지에서 우러나는 듯한 맑은 느낌의 수묵 구사 기법은 그의 작품을 특징 지워주는 중요한 표현 요소로 작가는 초기 진채(眞彩)와 먹색 위주의 산수화에서 후기로 갈수록 점차 담채가 주요한 실경(實景)의 사경(寫景) 산수화풍을 제작하기도 하였던 것이다.'} metadata={'dataset_split': ['base']} id=UUID('afc13964-e552-4523-86ec-df5422e9a439') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18370, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18370, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'김영대'의 '와성' 크기는 어떻게 되나요?\"} outputs={'answer': '78×130×68'} metadata={'dataset_split': ['base']} id=UUID('d1f99316-21e1-43ad-ab7d-059088e23a52') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18362, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18362, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'한용진'의 '작품 62' 제작에 사용된 소재는 무엇인가요?\"} outputs={'answer': '종이에 목판'} metadata={'dataset_split': ['base']} id=UUID('4783a17e-eb74-46e8-ad52-9776b7c80d3c') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18354, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18354, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'김정숙 a'의 '비상'은(는) 어떤 카테고리에 속하나요?\"} outputs={'answer': '조각ㆍ설치'} metadata={'dataset_split': ['base']} id=UUID('ed2096fc-7ad6-4149-991b-5a53836a9caa') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18345, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18345, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n"
     ]
    }
   ],
   "source": [
    "# LangSmith에서 데이터셋 불러오기\n",
    "datasets = client.list_datasets()\n",
    "for dataset in datasets:\n",
    "    print(f\"Dataset Name: {dataset.name}, ID: {dataset.id}\")\n",
    "\n",
    "# 데이터셋에서 데이터 샘플 확인 (제너레이터 → 리스트 변환)\n",
    "examples = list(client.list_examples(dataset_id=dataset.id))  # 리스트로 변환\n",
    "\n",
    "# 처음 5개만 출력\n",
    "for example in examples[:5]:  \n",
    "    print(example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요.', '반갑습니다.', '내', '이름은', '채림입니다.']\n",
      "['안녕하세용', '반갑습니다~^^', '내', '이름은', '채림입니다!!']\n",
      "============================================================\n",
      "['안녕', '하', '세요', '.', '반갑', '습니다', '.', '나', '의', '이름', '은', '채림', '이', 'ᆸ니다', '.']\n",
      "['안녕', '하', '세요', 'ᆼ', '반갑', '습니다', '~', '^^', '나', '의', '이름', '은', '채림', '이', 'ᆸ니다', '!!']\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.kiwi_tokenizer import KiwiTokenizer\n",
    "\n",
    "# 토크나이저 선언\n",
    "kiwi_tokenizer = KiwiTokenizer()\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세용 반갑습니다~^^ 내 이름은 채림입니다!!\"\n",
    "\n",
    "# 토큰화\n",
    "print(sent1.split())\n",
    "print(sent2.split())\n",
    "\n",
    "print(\"===\" * 20)\n",
    "\n",
    "# 토큰화\n",
    "print(kiwi_tokenizer.tokenize(sent1))\n",
    "print(kiwi_tokenizer.tokenize(sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\n",
      "[rouge1] 0.75862\n",
      "[rouge2] 0.59259\n",
      "[rougeL] 0.75862\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 내 이름은 채림입니다. 안녕하세요. 반갑습니다.\n",
      "[rouge1] 1.00000\n",
      "[rouge2] 0.92857\n",
      "[rougeL] 0.53333\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\"\n",
    "sent3 = \"내 이름은 채림입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(\n",
    "    [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=False, tokenizer=KiwiTokenizer()\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"[1] {sent1}\\n[2] {sent2}\\n[rouge1] {scorer.score(sent1, sent2)['rouge1'].fmeasure:.5f}\\n[rouge2] {scorer.score(sent1, sent2)['rouge2'].fmeasure:.5f}\\n[rougeL] {scorer.score(sent1, sent2)['rougeL'].fmeasure:.5f}\"\n",
    ")\n",
    "print(\"===\" * 20)\n",
    "print(\n",
    "    f\"[1] {sent1}\\n[2] {sent3}\\n[rouge1] {scorer.score(sent1, sent3)['rouge1'].fmeasure:.5f}\\n[rouge2] {scorer.score(sent1, sent3)['rouge2'].fmeasure:.5f}\\n[rougeL] {scorer.score(sent1, sent3)['rougeL'].fmeasure:.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕 하 세요 . 반갑 습니다 . 나 의 이름 은 채림 이 ᆸ니다 .\n",
      "안녕 하 세여 반갑 습니다 ~~~ 나 의 이름 은 채림 이 ᆸ니다 !!\n",
      "나 의 이름 은 채림 이 ᆸ니다 . 안녕 하 세요 . 반갑 습니다 .\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\"\n",
    "sent3 = \"내 이름은 채림입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "# 토큰화\n",
    "print(kiwi_tokenizer.tokenize(sent1, type=\"sentence\"))\n",
    "print(kiwi_tokenizer.tokenize(sent2, type=\"sentence\"))\n",
    "print(kiwi_tokenizer.tokenize(sent3, type=\"sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\n",
      "[score] 0.75503\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 내 이름은 채림입니다. 안녕하세요. 반갑습니다.\n",
      "[score] 0.95739\n"
     ]
    }
   ],
   "source": [
    "bleu_score = sentence_bleu(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"sentence\")],\n",
    "    kiwi_tokenizer.tokenize(sent2, type=\"sentence\"),\n",
    ")\n",
    "print(f\"[1] {sent1}\\n[2] {sent2}\\n[score] {bleu_score:.5f}\")\n",
    "print(\"===\" * 20)\n",
    "\n",
    "bleu_score = sentence_bleu(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"sentence\")],\n",
    "    kiwi_tokenizer.tokenize(sent3, type=\"sentence\"),\n",
    ")\n",
    "print(f\"[1] {sent1}\\n[2] {sent3}\\n[score] {bleu_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/chae/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\n",
      "[score] 0.73077\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 내 이름은 채림입니다. 안녕하세요. 반갑습니다.\n",
      "[score] 0.96800\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate import meteor_score\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\"\n",
    "sent3 = \"내 이름은 채림입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "meteor = meteor_score.meteor_score(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"list\")],\n",
    "    kiwi_tokenizer.tokenize(sent2, type=\"list\"),\n",
    ")\n",
    "\n",
    "print(f\"[1] {sent1}\\n[2] {sent2}\\n[score] {meteor:.5f}\")\n",
    "print(\"===\" * 20)\n",
    "\n",
    "meteor = meteor_score.meteor_score(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"list\")],\n",
    "    kiwi_tokenizer.tokenize(sent3, type=\"list\"),\n",
    ")\n",
    "print(f\"[1] {sent1}\\n[2] {sent3}\\n[score] {meteor:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\n",
      "[score] 0.88842\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 내 이름은 채림입니다. 안녕하세요. 반갑습니다.\n",
      "[score] 0.99265\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\"\n",
    "sent3 = \"내 이름은 채림입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "# SentenceTransformer 모델 로드\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# 문장들을 인코딩\n",
    "sent1_encoded = model.encode(sent1, convert_to_tensor=True)\n",
    "sent2_encoded = model.encode(sent2, convert_to_tensor=True)\n",
    "sent3_encoded = model.encode(sent3, convert_to_tensor=True)\n",
    "\n",
    "# sent1과 sent2 사이의 코사인 유사도 계산\n",
    "cosine_similarity = util.pytorch_cos_sim(sent1_encoded, sent2_encoded).item()\n",
    "print(f\"[1] {sent1}\\n[2] {sent2}\\n[score] {cosine_similarity:.5f}\")\n",
    "\n",
    "print(\"===\" * 20)\n",
    "\n",
    "# sent1과 sent3 사이의 코사인 유사도 계산\n",
    "cosine_similarity = util.pytorch_cos_sim(sent1_encoded, sent3_encoded).item()\n",
    "print(f\"[1] {sent1}\\n[2] {sent3}\\n[score] {cosine_similarity:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate import meteor_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "\n",
    "# 토크나이저 병렬화 설정(HuggingFace 모델 사용)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "\n",
    "def rouge_evaluator(metric: str = \"rouge1\") -> dict:\n",
    "    # wrapper function 정의\n",
    "    def _rouge_evaluator(run: Run, example: Example) -> dict:\n",
    "        # 출력값과 정답 가져오기\n",
    "        student_answer = run.outputs.get(\"answer\", \"\")\n",
    "        reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "        # ROUGE 점수 계산\n",
    "        scorer = rouge_scorer.RougeScorer(\n",
    "            [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True, tokenizer=KiwiTokenizer()\n",
    "        )\n",
    "        scores = scorer.score(reference_answer, student_answer)\n",
    "\n",
    "        # ROUGE 점수 반환\n",
    "        rouge = scores[metric].fmeasure\n",
    "\n",
    "        return {\"key\": \"ROUGE\", \"score\": rouge}\n",
    "\n",
    "    return _rouge_evaluator\n",
    "\n",
    "\n",
    "def bleu_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"sentence\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"sentence\")\n",
    "\n",
    "    # BLEU 점수 계산\n",
    "    bleu_score = sentence_bleu([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"BLEU\", \"score\": bleu_score}\n",
    "\n",
    "\n",
    "def meteor_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"list\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"list\")\n",
    "\n",
    "    # METEOR 점수 계산\n",
    "    meteor = meteor_score.meteor_score([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"METEOR\", \"score\": meteor}\n",
    "\n",
    "\n",
    "def semscore_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # SentenceTransformer 모델 로드\n",
    "    model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "    # 문장 임베딩 생성\n",
    "    student_embedding = model.encode(student_answer, convert_to_tensor=True)\n",
    "    reference_embedding = model.encode(reference_answer, convert_to_tensor=True)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    cosine_similarity = util.pytorch_cos_sim(\n",
    "        student_embedding, reference_embedding\n",
    "    ).item()\n",
    "\n",
    "    return {\"key\": \"sem_score\", \"score\": cosine_similarity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Heuristic-EVAL-c226f7a4' at:\n",
      "https://smith.langchain.com/o/a89b03f2-9920-4620-a0d1-5b700d444e04/datasets/5aae75ae-47e4-48e5-823c-eb233a86f9b9/compare?selectedSessions=fe8da49f-37f6-4c33-b673-2f14fff635db\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [06:14, 37.46s/it]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 평가자 정의\n",
    "heuristic_evalulators = [\n",
    "    rouge_evaluator(metric=\"rougeL\"),\n",
    "    bleu_evaluator,\n",
    "    meteor_evaluator,\n",
    "    semscore_evaluator,\n",
    "]\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"ds-0204\"\n",
    "\n",
    "# 실험 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=heuristic_evalulators,\n",
    "    experiment_prefix=\"Heuristic-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Heuristic-EVAL (Rouge, BLEU, METEOR, SemScore) 을 사용하여 평가\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langsmith를 활용하지 않은 로컬 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 1/10 질문 완료: 한국 추상회화의 독특한 접근 방식으로 잘 알려진 박항섭의 작품은 특히 개인적, 역사적 주제에 대한 탐구라는 측면에서 그의 독특한 세계관을 어떻게 반영하고 있나요? -> SemScore: 0.7849, ROUGE-1: 0.6667, ROUGE-2: 0.0000, BLEU: 0.0776, METEOR: 0.3715\n",
      "✅ 2/10 질문 완료: 홍정희 작가의 작품 '광산-희망'에 사용된 콜라주 기법은 어떻게 사용되었나요? -> SemScore: 0.9507, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0731, METEOR: 0.3773\n",
      "✅ 3/10 질문 완료: 최종태 작가의 '생각 속의 여인'의 특징과 화풍은 무엇인가요? -> SemScore: 0.7896, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0580, METEOR: 0.3217\n",
      "✅ 4/10 질문 완료: 박항섭과 김경원의 작품에서 볼 수 있는 한국 추상회화의 특징은 무엇인가요? -> SemScore: 0.9314, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0650, METEOR: 0.3387\n",
      "✅ 5/10 질문 완료: 한국의 풍경과 가족을 강조한 1957년 이수옥의 작품으로 여인과 두 아이가 등장하는 작품은 무엇인가요? -> SemScore: 0.8470, ROUGE-1: 0.4000, ROUGE-2: 0.0000, BLEU: 0.0295, METEOR: 0.3886\n",
      "✅ 6/10 질문 완료: 박성환의 '군무'(1976)는 한국의 풍경과 개인의 변화를 어떻게 묘사하고 있을까요? -> SemScore: 0.8926, ROUGE-1: 0.4000, ROUGE-2: 0.0000, BLEU: 0.0666, METEOR: 0.4056\n",
      "✅ 7/10 질문 완료: 장완 감독의 '침묵'에서 색과 빛은 어떻게 사실적인 단순함과 역동적인 표현의 매력적인 분위기를 불러일으킬 수 있을까요? -> SemScore: 0.6551, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0785, METEOR: 0.3540\n",
      "✅ 8/10 질문 완료: 박성환의 '군무'는 형태와 색채를 이용해 군무의 개성과 변화를 어떻게 표현할까요? -> SemScore: 0.8863, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0663, METEOR: 0.3298\n",
      "✅ 9/10 질문 완료: 오늘날의 문화적 변화는 박항섭의 1977년작 '마술사의 여행'에서 실존적이고 초현실적인 주제를 어떻게 변화시킬 수 있을까요? -> SemScore: 0.6309, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0018, METEOR: 0.0730\n",
      "✅ 10/10 질문 완료: 이수옥 작가의 '가족 초상화'에서 노란색과 갈색은 따뜻함을 자아냅니다. 색채 이론에 따라 다른 환경에서 이 색들이 어떻게 따뜻함을 전달할 수 있을까요? -> SemScore: 0.7364, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0009, METEOR: 0.0773\n",
      "✅ 평가 완료! 결과가 'evaluation_results_0206.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate import meteor_score\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "\n",
    "# 모델 및 토크나이저 초기화\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "kiwi = Kiwi()\n",
    "\n",
    "csv_file_path = 'dataset_csv/gpt_qa_translate.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    question = str(row['question'].strip())\n",
    "    ground_truth = str(row['ground_truth']).strip()\n",
    "\n",
    "    # ✅ RAG 모델을 이용해 답변 생성\n",
    "    model_answer = ask_question({\"question\": question})\n",
    "    model_text = model_answer[\"answer\"]  # ✅ 중요!\n",
    "\n",
    "    # ✅ SemScore 계산\n",
    "    ground_embedding = model.encode(ground_truth, convert_to_tensor=True)\n",
    "    model_embedding = model.encode(model_text, convert_to_tensor=True)\n",
    "    sem_score = util.pytorch_cos_sim(model_embedding, ground_embedding).item()\n",
    "\n",
    "    # ✅ ROUGE 점수 계산 (ROUGE-L 제거)\n",
    "    rouge = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"], use_stemmer=True)\n",
    "    rouge_scores = rouge.score(ground_truth, model_text)\n",
    "    rouge1 = rouge_scores[\"rouge1\"].fmeasure\n",
    "    rouge2 = rouge_scores[\"rouge2\"].fmeasure\n",
    "\n",
    "    # ✅ BLEU 점수 계산 (Smoothing 추가)\n",
    "    reference_tokens = [token.form for token in kiwi.tokenize(ground_truth)]\n",
    "    student_tokens = [token.form for token in kiwi.tokenize(model_text)]\n",
    "    smoothing = SmoothingFunction().method1  # BLEU 스무딩 적용\n",
    "    bleu_score = sentence_bleu([reference_tokens], student_tokens, smoothing_function=smoothing)\n",
    "\n",
    "    # ✅ METEOR 점수 계산\n",
    "    meteor = meteor_score.meteor_score([reference_tokens], student_tokens)\n",
    "\n",
    "    # ✅ 결과 저장\n",
    "    results.append([i + 1, question, model_text, ground_truth, rouge1, rouge2, bleu_score, meteor, sem_score])\n",
    "\n",
    "    print(f\"✅ {i+1}/{len(df)} 질문 완료: {question} -> SemScore: {sem_score:.4f}, ROUGE-1: {rouge1:.4f}, ROUGE-2: {rouge2:.4f}, BLEU: {bleu_score:.4f}, METEOR: {meteor:.4f}\")\n",
    "\n",
    "# ✅ CSV 저장\n",
    "csv_output = \"evaluation_results_0209.csv\"\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    \"Index\", \"Question\", \"RAG Answer\", \"Ground Truth\",\n",
    "    \"ROUGE-1\", \"ROUGE-2\", \"BLEU\", \"METEOR\", \"SemScore\"\n",
    "])\n",
    "df_results.to_csv(csv_output, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ 평가 완료! 결과가 '{csv_output}' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 1/100 질문 완료: '한진만'의 '월명리'에 대해 설명해주세요. -> SemScore: 0.6682, ROUGE-1: 0.8000, ROUGE-2: 0.5455, BLEU: 0.2094, METEOR: 0.5077\n",
      "✅ 2/100 질문 완료: '전국광'의 '매스의 내면-3부작'에 대해 설명해주세요. -> SemScore: 0.7051, ROUGE-1: 0.6809, ROUGE-2: 0.6222, BLEU: 0.2306, METEOR: 0.3766\n",
      "✅ 3/100 질문 완료: '노수현'의 '산수화'에 대해 설명해주세요. -> SemScore: 0.5749, ROUGE-1: 0.3125, ROUGE-2: 0.2000, BLEU: 0.2060, METEOR: 0.2988\n",
      "✅ 4/100 질문 완료: '김차섭'의 '자화상'에 대해 설명해주세요. -> SemScore: 0.7235, ROUGE-1: 0.4286, ROUGE-2: 0.1538, BLEU: 0.0659, METEOR: 0.4126\n",
      "✅ 5/100 질문 완료: '베른트 베허 + 힐라 베허'의 '벽과 배관'에 대해 설명해주세요. -> SemScore: 0.8382, ROUGE-1: 0.5600, ROUGE-2: 0.4167, BLEU: 0.2594, METEOR: 0.3945\n",
      "✅ 6/100 질문 완료: '유영국'의 '작품005'에 대해 설명해주세요. -> SemScore: 0.6050, ROUGE-1: 0.4068, ROUGE-2: 0.2105, BLEU: 0.1418, METEOR: 0.2673\n",
      "✅ 7/100 질문 완료: '김지원'의 '정물화 2'에 대해 설명해주세요. -> SemScore: 0.7430, ROUGE-1: 0.7200, ROUGE-2: 0.4348, BLEU: 0.2738, METEOR: 0.4908\n",
      "✅ 8/100 질문 완료: '서승원'의 '동시성 86-72'에 대해 설명해주세요. -> SemScore: 0.8476, ROUGE-1: 0.8889, ROUGE-2: 0.7059, BLEU: 0.1094, METEOR: 0.4013\n",
      "✅ 9/100 질문 완료: '박기원'의 '넓이'에 대해 설명해주세요. -> SemScore: 0.7322, ROUGE-1: 0.3590, ROUGE-2: 0.1622, BLEU: 0.0926, METEOR: 0.4105\n",
      "✅ 10/100 질문 완료: '수에다케 에이이치'의 '표본상자'에 대해 설명해주세요. -> SemScore: 0.5650, ROUGE-1: 0.5385, ROUGE-2: 0.3333, BLEU: 0.2017, METEOR: 0.3424\n",
      "✅ 11/100 질문 완료: '조습'의 '습이를 살려내라'에 대해 설명해주세요. -> SemScore: 0.7000, ROUGE-1: 0.4762, ROUGE-2: 0.2000, BLEU: 0.1391, METEOR: 0.2599\n",
      "✅ 12/100 질문 완료: '임민욱'의 '불의 절벽 2'에 대해 설명해주세요. -> SemScore: 0.7524, ROUGE-1: 0.7317, ROUGE-2: 0.6154, BLEU: 0.2199, METEOR: 0.4250\n",
      "✅ 13/100 질문 완료: '이응노'의 '고향집(1)'에 대해 설명해주세요. -> SemScore: 0.8338, ROUGE-1: 0.5714, ROUGE-2: 0.4444, BLEU: 0.0896, METEOR: 0.1879\n",
      "✅ 14/100 질문 완료: '피아오 광시에 '의 '2006 No.4'에 대해 설명해주세요. -> SemScore: 0.8137, ROUGE-1: 0.7179, ROUGE-2: 0.5946, BLEU: 0.3173, METEOR: 0.4216\n",
      "✅ 15/100 질문 완료: '장성순'의 '작품 59-B'에 대해 설명해주세요. -> SemScore: 0.8170, ROUGE-1: 0.7111, ROUGE-2: 0.5581, BLEU: 0.2329, METEOR: 0.4525\n",
      "✅ 16/100 질문 완료: '김숙진'의 '불상'에 대해 설명해주세요. -> SemScore: 0.6228, ROUGE-1: 0.5926, ROUGE-2: 0.2400, BLEU: 0.1167, METEOR: 0.4714\n",
      "✅ 17/100 질문 완료: '권부문'의 '낙산 #8168'에 대해 설명해주세요. -> SemScore: 0.8480, ROUGE-1: 0.7317, ROUGE-2: 0.5128, BLEU: 0.1819, METEOR: 0.4391\n",
      "✅ 18/100 질문 완료: '오인환'의 '남자가 남자를 만나는 곳, 서울'에 대해 설명해주세요. -> SemScore: 0.6710, ROUGE-1: 0.3200, ROUGE-2: 0.2609, BLEU: 0.2197, METEOR: 0.3473\n",
      "✅ 19/100 질문 완료: '조부수'의 '관현악 편곡'에 대해 설명해주세요. -> SemScore: 0.8219, ROUGE-1: 0.6154, ROUGE-2: 0.4167, BLEU: 0.2384, METEOR: 0.3697\n",
      "✅ 20/100 질문 완료: '문신'의 '무제'에 대해 설명해주세요. -> SemScore: 0.8285, ROUGE-1: 0.1591, ROUGE-2: 0.0465, BLEU: 0.1018, METEOR: 0.3042\n",
      "✅ 21/100 질문 완료: '니콜라 물랭'의 '웜드워'에 대해 설명해주세요. -> SemScore: 0.8672, ROUGE-1: 0.7368, ROUGE-2: 0.7059, BLEU: 0.2193, METEOR: 0.4527\n",
      "✅ 22/100 질문 완료: '김태순'의 '찻상'에 대해 설명해주세요. -> SemScore: 0.6922, ROUGE-1: 0.3404, ROUGE-2: 0.2667, BLEU: 0.1473, METEOR: 0.3513\n",
      "✅ 23/100 질문 완료: '이중섭'의 '꽃과 손'에 대해 설명해주세요. -> SemScore: 0.6407, ROUGE-1: 0.4000, ROUGE-2: 0.3478, BLEU: 0.1294, METEOR: 0.2355\n",
      "✅ 24/100 질문 완료: '신학철'의 '대지'에 대해 설명해주세요. -> SemScore: 0.7050, ROUGE-1: 0.6897, ROUGE-2: 0.3704, BLEU: 0.0686, METEOR: 0.4193\n",
      "✅ 25/100 질문 완료: '오지호'의 '목탄 뎃상풍경'에 대해 설명해주세요. -> SemScore: 0.7178, ROUGE-1: 0.5455, ROUGE-2: 0.4000, BLEU: 0.0718, METEOR: 0.3963\n",
      "✅ 26/100 질문 완료: '유철연'의 '목격자의 증언'에 대해 설명해주세요. -> SemScore: 0.6496, ROUGE-1: 0.6667, ROUGE-2: 0.4545, BLEU: 0.1589, METEOR: 0.4723\n",
      "✅ 27/100 질문 완료: '박성삼'의 '목기'에 대해 설명해주세요. -> SemScore: 0.5703, ROUGE-1: 0.7200, ROUGE-2: 0.5217, BLEU: 0.1410, METEOR: 0.4464\n",
      "✅ 28/100 질문 완료: '장영숙'의 '종이'에 대해 설명해주세요. -> SemScore: 0.6886, ROUGE-1: 0.1053, ROUGE-2: 0.0000, BLEU: 0.1513, METEOR: 0.3072\n",
      "✅ 29/100 질문 완료: '이준'의 '조춘(早春)'에 대해 설명해주세요. -> SemScore: 0.8957, ROUGE-1: 0.5000, ROUGE-2: 0.3158, BLEU: 0.2326, METEOR: 0.3161\n",
      "✅ 30/100 질문 완료: '조르주 라포르트'의 '팽폴의 배'에 대해 설명해주세요. -> SemScore: 0.8048, ROUGE-1: 0.7879, ROUGE-2: 0.7742, BLEU: 0.0142, METEOR: 0.3808\n",
      "✅ 31/100 질문 완료: '유강열'의 '작품'에 대해 설명해주세요. -> SemScore: 0.6883, ROUGE-1: 0.1176, ROUGE-2: 0.0241, BLEU: 0.0193, METEOR: 0.1659\n",
      "✅ 32/100 질문 완료: '배병우'의 '제주오름시리즈 Ⅳ'에 대해 설명해주세요. -> SemScore: 0.7086, ROUGE-1: 0.5517, ROUGE-2: 0.5185, BLEU: 0.1530, METEOR: 0.3233\n",
      "✅ 33/100 질문 완료: '이상범'의 '추강모연(秋江暮煙)'에 대해 설명해주세요. -> SemScore: 0.6858, ROUGE-1: 0.4000, ROUGE-2: 0.3030, BLEU: 0.1520, METEOR: 0.2235\n",
      "✅ 34/100 질문 완료: '김정숙 a'의 '뒤틀림'에 대해 설명해주세요. -> SemScore: 0.4941, ROUGE-1: 0.5000, ROUGE-2: 0.2400, BLEU: 0.1562, METEOR: 0.3772\n",
      "✅ 35/100 질문 완료: '황현숙'의 '풍경'에 대해 설명해주세요. -> SemScore: 0.8667, ROUGE-1: 0.4286, ROUGE-2: 0.2593, BLEU: 0.0997, METEOR: 0.4336\n",
      "✅ 36/100 질문 완료: '윤향란'의 '버섯'에 대해 설명해주세요. -> SemScore: 0.3428, ROUGE-1: 0.2400, ROUGE-2: 0.0870, BLEU: 0.1966, METEOR: 0.3079\n",
      "✅ 37/100 질문 완료: '임응식'의 '낙선재'에 대해 설명해주세요. -> SemScore: 0.6941, ROUGE-1: 0.2759, ROUGE-2: 0.1481, BLEU: 0.0715, METEOR: 0.3575\n",
      "✅ 38/100 질문 완료: '장우성'의 '야매(夜梅)'에 대해 설명해주세요. -> SemScore: 0.5157, ROUGE-1: 0.3750, ROUGE-2: 0.2667, BLEU: 0.1069, METEOR: 0.2541\n",
      "✅ 39/100 질문 완료: '문범'의 '떨어지는 꽃잎'에 대해 설명해주세요. -> SemScore: 0.7752, ROUGE-1: 0.4375, ROUGE-2: 0.1333, BLEU: 0.1870, METEOR: 0.2997\n",
      "✅ 40/100 질문 완료: '후루이케 다이스케'의 '17개 권위에 대한 문제점의 정의'에 대해 설명해주세요. -> SemScore: 0.8431, ROUGE-1: 0.7895, ROUGE-2: 0.5000, BLEU: 0.2291, METEOR: 0.4818\n",
      "✅ 41/100 질문 완료: '이일호'의 '무제'에 대해 설명해주세요. -> SemScore: 0.8461, ROUGE-1: 0.6364, ROUGE-2: 0.4000, BLEU: 0.3386, METEOR: 0.4109\n",
      "✅ 42/100 질문 완료: '임응식'의 '고목'에 대해 설명해주세요. -> SemScore: 0.5782, ROUGE-1: 0.5714, ROUGE-2: 0.3158, BLEU: 0.1556, METEOR: 0.3391\n",
      "✅ 43/100 질문 완료: '이응노'의 '구성'에 대해 설명해주세요. -> SemScore: 0.6907, ROUGE-1: 0.1538, ROUGE-2: 0.0000, BLEU: 0.0819, METEOR: 0.3287\n",
      "✅ 44/100 질문 완료: '송번수'의 'I Love DMZ'에 대해 설명해주세요. -> SemScore: 0.8166, ROUGE-1: 0.6667, ROUGE-2: 0.3913, BLEU: 0.0965, METEOR: 0.2460\n",
      "✅ 45/100 질문 완료: '신순남'의 '아내와 자화상'에 대해 설명해주세요. -> SemScore: 0.6633, ROUGE-1: 0.3273, ROUGE-2: 0.1887, BLEU: 0.0702, METEOR: 0.3866\n",
      "✅ 46/100 질문 완료: '차대덕'의 '자화상'에 대해 설명해주세요. -> SemScore: 0.7984, ROUGE-1: 0.7273, ROUGE-2: 0.3000, BLEU: 0.1935, METEOR: 0.3330\n",
      "✅ 47/100 질문 완료: '육명심'의 '예술가의 초상 시리즈 - 이종우'에 대해 설명해주세요. -> SemScore: 0.7060, ROUGE-1: 0.4651, ROUGE-2: 0.2927, BLEU: 0.1654, METEOR: 0.2941\n",
      "✅ 48/100 질문 완료: '홍순모'의 '그 거룩한 처소에 계신 하나님은 고아의 아버지시며'에 대해 설명해주세요. -> SemScore: 0.6429, ROUGE-1: 0.4375, ROUGE-2: 0.2667, BLEU: 0.2075, METEOR: 0.3490\n",
      "✅ 49/100 질문 완료: '강요배'의 '오동잎'에 대해 설명해주세요. -> SemScore: 0.4768, ROUGE-1: 0.5926, ROUGE-2: 0.2400, BLEU: 0.2388, METEOR: 0.3692\n",
      "✅ 50/100 질문 완료: '성능경'의 '신문 읽기'에 대해 설명해주세요. -> SemScore: 0.7779, ROUGE-1: 0.7407, ROUGE-2: 0.5769, BLEU: 0.2071, METEOR: 0.5169\n",
      "✅ 51/100 질문 완료: '박길웅'의 '원초공간'에 대해 설명해주세요. -> SemScore: 0.7113, ROUGE-1: 0.3636, ROUGE-2: 0.0645, BLEU: 0.0282, METEOR: 0.3184\n",
      "✅ 52/100 질문 완료: '장민승'의 '입석부근'에 대해 설명해주세요. -> SemScore: 0.6622, ROUGE-1: 0.6364, ROUGE-2: 0.5000, BLEU: 0.1905, METEOR: 0.4282\n",
      "✅ 53/100 질문 완료: '김수명'의 '노변'에 대해 설명해주세요. -> SemScore: 0.8396, ROUGE-1: 0.6857, ROUGE-2: 0.4848, BLEU: 0.2299, METEOR: 0.4082\n",
      "✅ 54/100 질문 완료: '이종혁'의 '구성'에 대해 설명해주세요. -> SemScore: 0.8285, ROUGE-1: 0.7059, ROUGE-2: 0.5333, BLEU: 0.2118, METEOR: 0.4095\n",
      "✅ 55/100 질문 완료: '이치하라 아리노리'의 'SEM'에 대해 설명해주세요. -> SemScore: 0.6961, ROUGE-1: 0.7647, ROUGE-2: 0.6250, BLEU: 0.1770, METEOR: 0.4425\n",
      "✅ 56/100 질문 완료: '김정숙 a'의 '비상'에 대해 설명해주세요. -> SemScore: 0.3827, ROUGE-1: 0.1053, ROUGE-2: 0.0000, BLEU: 0.0682, METEOR: 0.2924\n",
      "✅ 57/100 질문 완료: '문신'의 '무제'에 대해 설명해주세요. -> SemScore: 0.8062, ROUGE-1: 0.1190, ROUGE-2: 0.0244, BLEU: 0.0773, METEOR: 0.2864\n",
      "✅ 58/100 질문 완료: '이철주'의 '장생'에 대해 설명해주세요. -> SemScore: 0.5805, ROUGE-1: 0.4242, ROUGE-2: 0.1290, BLEU: 0.1300, METEOR: 0.2573\n",
      "✅ 59/100 질문 완료: '임응식'의 '백태원 인물'에 대해 설명해주세요. -> SemScore: 0.8373, ROUGE-1: 0.3846, ROUGE-2: 0.0833, BLEU: 0.1853, METEOR: 0.3153\n",
      "✅ 60/100 질문 완료: '정은영 a'의 '모란과 나비'에 대해 설명해주세요. -> SemScore: 0.4595, ROUGE-1: 0.1538, ROUGE-2: 0.0000, BLEU: 0.1073, METEOR: 0.2304\n",
      "✅ 61/100 질문 완료: '심재영'의 '천지현황-순례자'에 대해 설명해주세요. -> SemScore: 0.5670, ROUGE-1: 0.5625, ROUGE-2: 0.2667, BLEU: 0.2389, METEOR: 0.5152\n",
      "✅ 62/100 질문 완료: '최명영'의 '평면조건 B-8516'에 대해 설명해주세요. -> SemScore: 0.7669, ROUGE-1: 0.7027, ROUGE-2: 0.4571, BLEU: 0.0943, METEOR: 0.3963\n",
      "✅ 63/100 질문 완료: '신영헌'의 '평양 대동교의 비극(원제:대동강의 피격)'에 대해 설명해주세요. -> SemScore: 0.7814, ROUGE-1: 0.5957, ROUGE-2: 0.3556, BLEU: 0.2395, METEOR: 0.3757\n",
      "✅ 64/100 질문 완료: '서세옥'의 '점의 변주'에 대해 설명해주세요. -> SemScore: 0.6799, ROUGE-1: 0.4651, ROUGE-2: 0.2439, BLEU: 0.1880, METEOR: 0.2817\n",
      "✅ 65/100 질문 완료: '임응식'의 '김대현 인물'에 대해 설명해주세요. -> SemScore: 0.8285, ROUGE-1: 0.5185, ROUGE-2: 0.2400, BLEU: 0.1786, METEOR: 0.3369\n",
      "✅ 66/100 질문 완료: '최종태'의 '사유소녀상'에 대해 설명해주세요. -> SemScore: 0.6516, ROUGE-1: 0.3939, ROUGE-2: 0.2188, BLEU: 0.1807, METEOR: 0.3158\n",
      "✅ 67/100 질문 완료: '하준수'의 '저스트'에 대해 설명해주세요. -> SemScore: 0.6380, ROUGE-1: 0.6154, ROUGE-2: 0.4865, BLEU: 0.1777, METEOR: 0.3680\n",
      "✅ 68/100 질문 완료: '황규백'의 '집'에 대해 설명해주세요. -> SemScore: 0.8136, ROUGE-1: 0.5517, ROUGE-2: 0.4444, BLEU: 0.1231, METEOR: 0.2640\n",
      "✅ 69/100 질문 완료: '임응식'의 '너와 지붕(상원사)'에 대해 설명해주세요. -> SemScore: 0.8979, ROUGE-1: 0.7805, ROUGE-2: 0.6154, BLEU: 0.3118, METEOR: 0.4331\n",
      "✅ 70/100 질문 완료: '주성태'의 '원죄'에 대해 설명해주세요. -> SemScore: 0.7222, ROUGE-1: 0.4286, ROUGE-2: 0.3077, BLEU: 0.2475, METEOR: 0.3177\n",
      "✅ 71/100 질문 완료: '박수근'의 '나무'에 대해 설명해주세요. -> SemScore: 0.7045, ROUGE-1: 0.5000, ROUGE-2: 0.4615, BLEU: 0.1368, METEOR: 0.2271\n",
      "✅ 72/100 질문 완료: '곽인식'의 '작품 62-206'에 대해 설명해주세요. -> SemScore: 0.8220, ROUGE-1: 0.5714, ROUGE-2: 0.3704, BLEU: 0.0745, METEOR: 0.2222\n",
      "✅ 73/100 질문 완료: '유영국'의 '작품004'에 대해 설명해주세요. -> SemScore: 0.6323, ROUGE-1: 0.5507, ROUGE-2: 0.2985, BLEU: 0.1936, METEOR: 0.3206\n",
      "✅ 74/100 질문 완료: '이완교'의 '기운생동 6'에 대해 설명해주세요. -> SemScore: 0.8229, ROUGE-1: 0.7500, ROUGE-2: 0.6316, BLEU: 0.0743, METEOR: 0.5146\n",
      "✅ 75/100 질문 완료: '황현숙'의 '풍경'에 대해 설명해주세요. -> SemScore: 0.7252, ROUGE-1: 0.3256, ROUGE-2: 0.2439, BLEU: 0.0848, METEOR: 0.4151\n",
      "✅ 76/100 질문 완료: '서세옥'의 '사람들'에 대해 설명해주세요. -> SemScore: 0.7170, ROUGE-1: 0.1081, ROUGE-2: 0.0278, BLEU: 0.0342, METEOR: 0.2739\n",
      "✅ 77/100 질문 완료: '서세옥'의 '춤추는 사람들'에 대해 설명해주세요. -> SemScore: 0.8575, ROUGE-1: 0.2500, ROUGE-2: 0.1111, BLEU: 0.0418, METEOR: 0.3093\n",
      "✅ 78/100 질문 완료: '김승희'의 '추수'에 대해 설명해주세요. -> SemScore: 0.6276, ROUGE-1: 0.8000, ROUGE-2: 0.4444, BLEU: 0.1394, METEOR: 0.4663\n",
      "✅ 79/100 질문 완료: '임응식'의 '노부부'에 대해 설명해주세요. -> SemScore: 0.6225, ROUGE-1: 0.6667, ROUGE-2: 0.5000, BLEU: 0.0200, METEOR: 0.0891\n",
      "✅ 80/100 질문 완료: '육명심'의 '예술가의 초상 시리즈 - 민정기'에 대해 설명해주세요. -> SemScore: 0.6010, ROUGE-1: 0.4000, ROUGE-2: 0.3684, BLEU: 0.2256, METEOR: 0.3259\n",
      "✅ 81/100 질문 완료: '허백련'의 '십군자'에 대해 설명해주세요. -> SemScore: 0.4750, ROUGE-1: 0.5833, ROUGE-2: 0.3478, BLEU: 0.2046, METEOR: 0.2741\n",
      "✅ 82/100 질문 완료: '이기영'의 '정 -01.02'에 대해 설명해주세요. -> SemScore: 0.7795, ROUGE-1: 0.6818, ROUGE-2: 0.6190, BLEU: 0.1475, METEOR: 0.3453\n",
      "✅ 83/100 질문 완료: '서희환'의 '복된 누리'에 대해 설명해주세요. -> SemScore: 0.6046, ROUGE-1: 0.5455, ROUGE-2: 0.3000, BLEU: 0.1172, METEOR: 0.3942\n",
      "✅ 84/100 질문 완료: '김순기'의 '과녁그림 No.1'에 대해 설명해주세요. -> SemScore: 0.6748, ROUGE-1: 0.7907, ROUGE-2: 0.6341, BLEU: 0.1535, METEOR: 0.3526\n",
      "✅ 85/100 질문 완료: '유영국'의 '작품005'에 대해 설명해주세요. -> SemScore: 0.5973, ROUGE-1: 0.3667, ROUGE-2: 0.2069, BLEU: 0.1323, METEOR: 0.2620\n",
      "✅ 86/100 질문 완료: '이미경'의 '이희승 시 새해(궁체 현대문흘림)'에 대해 설명해주세요. -> SemScore: 0.7028, ROUGE-1: 0.8000, ROUGE-2: 0.7692, BLEU: 0.0719, METEOR: 0.4711\n",
      "✅ 87/100 질문 완료: '신옥주'의 '지평에서'에 대해 설명해주세요. -> SemScore: 0.8048, ROUGE-1: 0.8462, ROUGE-2: 0.7500, BLEU: 0.0270, METEOR: 0.0779\n",
      "✅ 88/100 질문 완료: '이재효'의 '0121-1110=1 0309'에 대해 설명해주세요. -> SemScore: 0.7353, ROUGE-1: 0.8333, ROUGE-2: 0.6957, BLEU: 0.1867, METEOR: 0.5299\n",
      "✅ 89/100 질문 완료: '송성용'의 '행서(8곡병)'에 대해 설명해주세요. -> SemScore: 0.7455, ROUGE-1: 0.8148, ROUGE-2: 0.7200, BLEU: 0.2976, METEOR: 0.5650\n",
      "✅ 90/100 질문 완료: '이중섭'의 '포도 따는 남자 '에 대해 설명해주세요. -> SemScore: 0.5777, ROUGE-1: 0.3571, ROUGE-2: 0.1538, BLEU: 0.1243, METEOR: 0.2455\n",
      "✅ 91/100 질문 완료: '유영국'의 '작품004'에 대해 설명해주세요. -> SemScore: 0.6005, ROUGE-1: 0.4375, ROUGE-2: 0.2581, BLEU: 0.1735, METEOR: 0.2972\n",
      "✅ 92/100 질문 완료: '전미숙'의 '기억의 풍경-전남 석곡'에 대해 설명해주세요. -> SemScore: 0.7293, ROUGE-1: 0.5385, ROUGE-2: 0.3333, BLEU: 0.1720, METEOR: 0.2826\n",
      "✅ 93/100 질문 완료: '이병규'의 '부친상'에 대해 설명해주세요. -> SemScore: 0.6065, ROUGE-1: 0.3636, ROUGE-2: 0.2581, BLEU: 0.1624, METEOR: 0.2891\n",
      "✅ 94/100 질문 완료: '김근중'의 '꽃세상 7-34'에 대해 설명해주세요. -> SemScore: 0.5761, ROUGE-1: 0.5500, ROUGE-2: 0.3684, BLEU: 0.1400, METEOR: 0.2825\n",
      "✅ 95/100 질문 완료: '신현조'의 '고부(姑婦)'에 대해 설명해주세요. -> SemScore: 0.8037, ROUGE-1: 0.5600, ROUGE-2: 0.2609, BLEU: 0.0182, METEOR: 0.0531\n",
      "✅ 96/100 질문 완료: '황재형'의 '가마타기'에 대해 설명해주세요. -> SemScore: 0.6538, ROUGE-1: 0.5217, ROUGE-2: 0.4762, BLEU: 0.1196, METEOR: 0.2990\n",
      "✅ 97/100 질문 완료: '로버트 라우센버그'의 '판지 IV'에 대해 설명해주세요. -> SemScore: 0.7201, ROUGE-1: 0.6818, ROUGE-2: 0.5238, BLEU: 0.0958, METEOR: 0.3532\n",
      "✅ 98/100 질문 완료: '김희중'의 '책방'에 대해 설명해주세요. -> SemScore: 0.7891, ROUGE-1: 0.6316, ROUGE-2: 0.5556, BLEU: 0.1187, METEOR: 0.3078\n",
      "✅ 99/100 질문 완료: '김기승'의 '동맹(전서) 고구려'에 대해 설명해주세요. -> SemScore: 0.7218, ROUGE-1: 0.3846, ROUGE-2: 0.2500, BLEU: 0.1185, METEOR: 0.2775\n",
      "✅ 100/100 질문 완료: '이인영'의 '만하'에 대해 설명해주세요. -> SemScore: 0.7101, ROUGE-1: 0.7027, ROUGE-2: 0.5143, BLEU: 0.1412, METEOR: 0.2746\n",
      "✅ 평가 완료! 결과가 'dataset_csv/qa_0209_result.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate import meteor_score\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "\n",
    "# ✅ 모델 및 토크나이저 초기화\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# ✅ JSON 파일 로드\n",
    "json_file_path = \"qa_dataset_full_info_0209.json\"  # JSON 파일 경로\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "# ✅ JSON 데이터를 DataFrame으로 변환\n",
    "qa_pairs = []\n",
    "for item in qa_data:\n",
    "    text_parts = item[\"text\"].split(\"### Instruction:\\n\")  # 질문 추출\n",
    "    if len(text_parts) > 1:\n",
    "        question_part = text_parts[1].split(\"\\n\\n### Input:\\n\\n\\n\")[0]  # 질문\n",
    "        answer_part = text_parts[1].split(\"### Response:\\n\")[1].replace(\"<|endoftext|>\", \"\").strip()  # 정답\n",
    "        qa_pairs.append({\"question\": question_part, \"ground_truth\": answer_part})\n",
    "\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# ✅ 평가 진행\n",
    "results = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    question = str(row[\"question\"].strip())\n",
    "    ground_truth = str(row[\"ground_truth\"]).strip()\n",
    "\n",
    "    # ✅ RAG 모델을 이용해 답변 생성\n",
    "    model_answer = ask_question({\"question\": question})\n",
    "    model_text = model_answer[\"answer\"]  # ✅ 중요!\n",
    "\n",
    "    # ✅ SemScore 계산\n",
    "    ground_embedding = model.encode(ground_truth, convert_to_tensor=True)\n",
    "    model_embedding = model.encode(model_text, convert_to_tensor=True)\n",
    "    sem_score = util.pytorch_cos_sim(model_embedding, ground_embedding).item()\n",
    "\n",
    "    # ✅ ROUGE 점수 계산 (ROUGE-L 제거)\n",
    "    rouge = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"], use_stemmer=True)\n",
    "    rouge_scores = rouge.score(ground_truth, model_text)\n",
    "    rouge1 = rouge_scores[\"rouge1\"].fmeasure\n",
    "    rouge2 = rouge_scores[\"rouge2\"].fmeasure\n",
    "\n",
    "    # ✅ BLEU 점수 계산 (Smoothing 추가)\n",
    "    reference_tokens = [token.form for token in kiwi.tokenize(ground_truth)]\n",
    "    student_tokens = [token.form for token in kiwi.tokenize(model_text)]\n",
    "    smoothing = SmoothingFunction().method1  # BLEU 스무딩 적용\n",
    "    bleu_score = sentence_bleu([reference_tokens], student_tokens, smoothing_function=smoothing)\n",
    "\n",
    "    # ✅ METEOR 점수 계산\n",
    "    meteor = meteor_score.meteor_score([reference_tokens], student_tokens)\n",
    "\n",
    "    # ✅ 결과 저장\n",
    "    results.append([i + 1, question, model_text, ground_truth, rouge1, rouge2, bleu_score, meteor, sem_score])\n",
    "\n",
    "    print(f\"✅ {i+1}/{len(df)} 질문 완료: {question} -> SemScore: {sem_score:.4f}, ROUGE-1: {rouge1:.4f}, ROUGE-2: {rouge2:.4f}, BLEU: {bleu_score:.4f}, METEOR: {meteor:.4f}\")\n",
    "\n",
    "# ✅ CSV 저장\n",
    "csv_output = \"dataset_csv/qa_0209_result.csv\"\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    \"Index\", \"Question\", \"RAG Answer\", \"Ground Truth\",\n",
    "    \"ROUGE-1\", \"ROUGE-2\", \"BLEU\", \"METEOR\", \"SemScore\"\n",
    "])\n",
    "df_results.to_csv(csv_output, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ 평가 완료! 결과가 '{csv_output}' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Question</th>\n",
       "      <th>RAG Answer</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>SemScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'한진만'의 '월명리'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 한진만의 '월명리' (작품번호: 3104) 설명\\n\\n...</td>\n",
       "      <td>월명리 月明里 Wolmyung Village 한진만 HAN Jinman 3104 1...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.209397</td>\n",
       "      <td>0.507745</td>\n",
       "      <td>0.668159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>'전국광'의 '매스의 내면-3부작'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 전국광의 '매스의 내면-3부작' 설명\\n\\n**작품 정...</td>\n",
       "      <td>매스의 내면-3부작 N/A Inner Mass Tryptich 전국광 CHUN Ko...</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.230634</td>\n",
       "      <td>0.376625</td>\n",
       "      <td>0.705114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>'노수현'의 '산수화'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 노수현의 '산수화' (작품 번호: 145) 설명\\n\\n...</td>\n",
       "      <td>산수화 山水畵 Landscape 노수현 NO Soohyeon 145 1956 124...</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.206014</td>\n",
       "      <td>0.298771</td>\n",
       "      <td>0.574933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>'김차섭'의 '자화상'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 김차섭의 '자화상' 설명\\n\\n**작품 정보:**\\n*...</td>\n",
       "      <td>자화상 自畵像 Self-Portrait 김차섭 KIM Tchahsup 2555 19...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.065907</td>\n",
       "      <td>0.412567</td>\n",
       "      <td>0.723489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>'베른트 베허 + 힐라 베허'의 '벽과 배관'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 베른트 베허 + 힐라 베허 - 벽과 배관 (Walls ...</td>\n",
       "      <td>벽과 배관 N/A Walls and Conduits 베른트 베허 + 힐라 베허 Be...</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.259360</td>\n",
       "      <td>0.394479</td>\n",
       "      <td>0.838224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                               Question  \\\n",
       "0      1               '한진만'의 '월명리'에 대해 설명해주세요.   \n",
       "1      2        '전국광'의 '매스의 내면-3부작'에 대해 설명해주세요.   \n",
       "2      3               '노수현'의 '산수화'에 대해 설명해주세요.   \n",
       "3      4               '김차섭'의 '자화상'에 대해 설명해주세요.   \n",
       "4      5  '베른트 베허 + 힐라 베허'의 '벽과 배관'에 대해 설명해주세요.   \n",
       "\n",
       "                                          RAG Answer  \\\n",
       "0  ### 모델 결과\\n\\n## 한진만의 '월명리' (작품번호: 3104) 설명\\n\\n...   \n",
       "1  ### 모델 결과\\n\\n## 전국광의 '매스의 내면-3부작' 설명\\n\\n**작품 정...   \n",
       "2  ### 모델 결과\\n\\n## 노수현의 '산수화' (작품 번호: 145) 설명\\n\\n...   \n",
       "3  ### 모델 결과\\n\\n## 김차섭의 '자화상' 설명\\n\\n**작품 정보:**\\n*...   \n",
       "4  ### 모델 결과\\n\\n## 베른트 베허 + 힐라 베허 - 벽과 배관 (Walls ...   \n",
       "\n",
       "                                        Ground Truth   ROUGE-1   ROUGE-2  \\\n",
       "0  월명리 月明里 Wolmyung Village 한진만 HAN Jinman 3104 1...  0.800000  0.545455   \n",
       "1  매스의 내면-3부작 N/A Inner Mass Tryptich 전국광 CHUN Ko...  0.680851  0.622222   \n",
       "2  산수화 山水畵 Landscape 노수현 NO Soohyeon 145 1956 124...  0.312500  0.200000   \n",
       "3  자화상 自畵像 Self-Portrait 김차섭 KIM Tchahsup 2555 19...  0.428571  0.153846   \n",
       "4  벽과 배관 N/A Walls and Conduits 베른트 베허 + 힐라 베허 Be...  0.560000  0.416667   \n",
       "\n",
       "       BLEU    METEOR  SemScore  \n",
       "0  0.209397  0.507745  0.668159  \n",
       "1  0.230634  0.376625  0.705114  \n",
       "2  0.206014  0.298771  0.574933  \n",
       "3  0.065907  0.412567  0.723489  \n",
       "4  0.259360  0.394479  0.838224  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "csv_file_path = \"dataset_csv/qa_0209_result.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMD 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 1/100 질문 완료: '한진만'의 '월명리'에 대해 설명해주세요. -> WMD: 0.5104\n",
      "✅ 2/100 질문 완료: '전국광'의 '매스의 내면-3부작'에 대해 설명해주세요. -> WMD: 0.4148\n",
      "✅ 3/100 질문 완료: '노수현'의 '산수화'에 대해 설명해주세요. -> WMD: 0.5195\n",
      "✅ 4/100 질문 완료: '김차섭'의 '자화상'에 대해 설명해주세요. -> WMD: 0.7805\n",
      "✅ 5/100 질문 완료: '베른트 베허 + 힐라 베허'의 '벽과 배관'에 대해 설명해주세요. -> WMD: 0.5560\n",
      "✅ 6/100 질문 완료: '유영국'의 '작품005'에 대해 설명해주세요. -> WMD: 0.7031\n",
      "✅ 7/100 질문 완료: '김지원'의 '정물화 2'에 대해 설명해주세요. -> WMD: 0.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 8/100 질문 완료: '서승원'의 '동시성 86-72'에 대해 설명해주세요. -> WMD: 0.5813\n",
      "✅ 9/100 질문 완료: '박기원'의 '넓이'에 대해 설명해주세요. -> WMD: 0.6769\n",
      "✅ 10/100 질문 완료: '수에다케 에이이치'의 '표본상자'에 대해 설명해주세요. -> WMD: 0.4796\n",
      "✅ 11/100 질문 완료: '조습'의 '습이를 살려내라'에 대해 설명해주세요. -> WMD: 0.5480\n",
      "✅ 12/100 질문 완료: '임민욱'의 '불의 절벽 2'에 대해 설명해주세요. -> WMD: 0.5266\n",
      "✅ 13/100 질문 완료: '이응노'의 '고향집(1)'에 대해 설명해주세요. -> WMD: 0.5938\n",
      "✅ 14/100 질문 완료: '피아오 광시에 '의 '2006 No.4'에 대해 설명해주세요. -> WMD: 0.6330\n",
      "✅ 15/100 질문 완료: '장성순'의 '작품 59-B'에 대해 설명해주세요. -> WMD: 0.4998\n",
      "✅ 16/100 질문 완료: '김숙진'의 '불상'에 대해 설명해주세요. -> WMD: 0.6680\n",
      "✅ 17/100 질문 완료: '권부문'의 '낙산 #8168'에 대해 설명해주세요. -> WMD: 0.7598\n",
      "✅ 18/100 질문 완료: '오인환'의 '남자가 남자를 만나는 곳, 서울'에 대해 설명해주세요. -> WMD: 0.6752\n",
      "✅ 19/100 질문 완료: '조부수'의 '관현악 편곡'에 대해 설명해주세요. -> WMD: 0.4341\n",
      "✅ 20/100 질문 완료: '문신'의 '무제'에 대해 설명해주세요. -> WMD: 0.6886\n",
      "✅ 21/100 질문 완료: '니콜라 물랭'의 '웜드워'에 대해 설명해주세요. -> WMD: 0.6630\n",
      "✅ 22/100 질문 완료: '김태순'의 '찻상'에 대해 설명해주세요. -> WMD: 0.6028\n",
      "✅ 23/100 질문 완료: '이중섭'의 '꽃과 손'에 대해 설명해주세요. -> WMD: 0.7035\n",
      "✅ 24/100 질문 완료: '신학철'의 '대지'에 대해 설명해주세요. -> WMD: 0.5632\n",
      "✅ 25/100 질문 완료: '오지호'의 '목탄 뎃상풍경'에 대해 설명해주세요. -> WMD: 0.7829\n",
      "✅ 26/100 질문 완료: '유철연'의 '목격자의 증언'에 대해 설명해주세요. -> WMD: 0.6997\n",
      "✅ 27/100 질문 완료: '박성삼'의 '목기'에 대해 설명해주세요. -> WMD: 0.7326\n",
      "✅ 28/100 질문 완료: '장영숙'의 '종이'에 대해 설명해주세요. -> WMD: 0.8283\n",
      "✅ 29/100 질문 완료: '이준'의 '조춘(早春)'에 대해 설명해주세요. -> WMD: 0.7012\n",
      "✅ 30/100 질문 완료: '조르주 라포르트'의 '팽폴의 배'에 대해 설명해주세요. -> WMD: 0.7896\n",
      "✅ 31/100 질문 완료: '유강열'의 '작품'에 대해 설명해주세요. -> WMD: 0.6926\n",
      "✅ 32/100 질문 완료: '배병우'의 '제주오름시리즈 Ⅳ'에 대해 설명해주세요. -> WMD: 0.6337\n",
      "✅ 33/100 질문 완료: '이상범'의 '추강모연(秋江暮煙)'에 대해 설명해주세요. -> WMD: 0.6348\n",
      "✅ 34/100 질문 완료: '김정숙 a'의 '뒤틀림'에 대해 설명해주세요. -> WMD: 0.7440\n",
      "✅ 35/100 질문 완료: '황현숙'의 '풍경'에 대해 설명해주세요. -> WMD: 0.7700\n",
      "✅ 36/100 질문 완료: '윤향란'의 '버섯'에 대해 설명해주세요. -> WMD: 0.5623\n",
      "✅ 37/100 질문 완료: '임응식'의 '낙선재'에 대해 설명해주세요. -> WMD: 0.6195\n",
      "✅ 38/100 질문 완료: '장우성'의 '야매(夜梅)'에 대해 설명해주세요. -> WMD: 0.8932\n",
      "✅ 39/100 질문 완료: '문범'의 '떨어지는 꽃잎'에 대해 설명해주세요. -> WMD: 0.5685\n",
      "✅ 40/100 질문 완료: '후루이케 다이스케'의 '17개 권위에 대한 문제점의 정의'에 대해 설명해주세요. -> WMD: 0.4693\n",
      "✅ 41/100 질문 완료: '이일호'의 '무제'에 대해 설명해주세요. -> WMD: 0.5559\n",
      "✅ 42/100 질문 완료: '임응식'의 '고목'에 대해 설명해주세요. -> WMD: 0.5076\n",
      "✅ 43/100 질문 완료: '이응노'의 '구성'에 대해 설명해주세요. -> WMD: 0.5951\n",
      "✅ 44/100 질문 완료: '송번수'의 'I Love DMZ'에 대해 설명해주세요. -> WMD: 0.5440\n",
      "✅ 45/100 질문 완료: '신순남'의 '아내와 자화상'에 대해 설명해주세요. -> WMD: 0.5956\n",
      "✅ 46/100 질문 완료: '차대덕'의 '자화상'에 대해 설명해주세요. -> WMD: 0.4814\n",
      "✅ 47/100 질문 완료: '육명심'의 '예술가의 초상 시리즈 - 이종우'에 대해 설명해주세요. -> WMD: 0.5137\n",
      "✅ 48/100 질문 완료: '홍순모'의 '그 거룩한 처소에 계신 하나님은 고아의 아버지시며'에 대해 설명해주세요. -> WMD: 0.5841\n",
      "✅ 49/100 질문 완료: '강요배'의 '오동잎'에 대해 설명해주세요. -> WMD: 0.6462\n",
      "✅ 50/100 질문 완료: '성능경'의 '신문 읽기'에 대해 설명해주세요. -> WMD: 0.5539\n",
      "✅ 51/100 질문 완료: '박길웅'의 '원초공간'에 대해 설명해주세요. -> WMD: 0.7936\n",
      "✅ 52/100 질문 완료: '장민승'의 '입석부근'에 대해 설명해주세요. -> WMD: 0.6456\n",
      "✅ 53/100 질문 완료: '김수명'의 '노변'에 대해 설명해주세요. -> WMD: 0.6635\n",
      "✅ 54/100 질문 완료: '이종혁'의 '구성'에 대해 설명해주세요. -> WMD: 0.4546\n",
      "✅ 55/100 질문 완료: '이치하라 아리노리'의 'SEM'에 대해 설명해주세요. -> WMD: 0.7218\n",
      "✅ 56/100 질문 완료: '김정숙 a'의 '비상'에 대해 설명해주세요. -> WMD: 0.6727\n",
      "✅ 57/100 질문 완료: '문신'의 '무제'에 대해 설명해주세요. -> WMD: 0.5882\n",
      "✅ 58/100 질문 완료: '이철주'의 '장생'에 대해 설명해주세요. -> WMD: 0.6093\n",
      "✅ 59/100 질문 완료: '임응식'의 '백태원 인물'에 대해 설명해주세요. -> WMD: 0.7100\n",
      "✅ 60/100 질문 완료: '정은영 a'의 '모란과 나비'에 대해 설명해주세요. -> WMD: 0.6418\n",
      "✅ 61/100 질문 완료: '심재영'의 '천지현황-순례자'에 대해 설명해주세요. -> WMD: 0.6557\n",
      "✅ 62/100 질문 완료: '최명영'의 '평면조건 B-8516'에 대해 설명해주세요. -> WMD: 0.6354\n",
      "✅ 63/100 질문 완료: '신영헌'의 '평양 대동교의 비극(원제:대동강의 피격)'에 대해 설명해주세요. -> WMD: 0.6288\n",
      "✅ 64/100 질문 완료: '서세옥'의 '점의 변주'에 대해 설명해주세요. -> WMD: 0.6007\n",
      "✅ 65/100 질문 완료: '임응식'의 '김대현 인물'에 대해 설명해주세요. -> WMD: 0.4152\n",
      "✅ 66/100 질문 완료: '최종태'의 '사유소녀상'에 대해 설명해주세요. -> WMD: 0.5959\n",
      "✅ 67/100 질문 완료: '하준수'의 '저스트'에 대해 설명해주세요. -> WMD: 0.5504\n",
      "✅ 68/100 질문 완료: '황규백'의 '집'에 대해 설명해주세요. -> WMD: 0.5981\n",
      "✅ 69/100 질문 완료: '임응식'의 '너와 지붕(상원사)'에 대해 설명해주세요. -> WMD: 0.5117\n",
      "✅ 70/100 질문 완료: '주성태'의 '원죄'에 대해 설명해주세요. -> WMD: 0.5573\n",
      "✅ 71/100 질문 완료: '박수근'의 '나무'에 대해 설명해주세요. -> WMD: 0.6684\n",
      "✅ 72/100 질문 완료: '곽인식'의 '작품 62-206'에 대해 설명해주세요. -> WMD: 0.4942\n",
      "✅ 73/100 질문 완료: '유영국'의 '작품004'에 대해 설명해주세요. -> WMD: 0.5725\n",
      "✅ 74/100 질문 완료: '이완교'의 '기운생동 6'에 대해 설명해주세요. -> WMD: 0.6664\n",
      "✅ 75/100 질문 완료: '황현숙'의 '풍경'에 대해 설명해주세요. -> WMD: 0.8326\n",
      "✅ 76/100 질문 완료: '서세옥'의 '사람들'에 대해 설명해주세요. -> WMD: 0.7260\n",
      "✅ 77/100 질문 완료: '서세옥'의 '춤추는 사람들'에 대해 설명해주세요. -> WMD: 0.7444\n",
      "✅ 78/100 질문 완료: '김승희'의 '추수'에 대해 설명해주세요. -> WMD: 0.4212\n",
      "✅ 79/100 질문 완료: '임응식'의 '노부부'에 대해 설명해주세요. -> WMD: 0.5247\n",
      "✅ 80/100 질문 완료: '육명심'의 '예술가의 초상 시리즈 - 민정기'에 대해 설명해주세요. -> WMD: 0.7935\n",
      "✅ 81/100 질문 완료: '허백련'의 '십군자'에 대해 설명해주세요. -> WMD: 0.6247\n",
      "✅ 82/100 질문 완료: '이기영'의 '정 -01.02'에 대해 설명해주세요. -> WMD: 0.6204\n",
      "✅ 83/100 질문 완료: '서희환'의 '복된 누리'에 대해 설명해주세요. -> WMD: 0.6911\n",
      "✅ 84/100 질문 완료: '김순기'의 '과녁그림 No.1'에 대해 설명해주세요. -> WMD: 0.5087\n",
      "✅ 85/100 질문 완료: '유영국'의 '작품005'에 대해 설명해주세요. -> WMD: 0.6644\n",
      "✅ 86/100 질문 완료: '이미경'의 '이희승 시 새해(궁체 현대문흘림)'에 대해 설명해주세요. -> WMD: 0.8450\n",
      "✅ 87/100 질문 완료: '신옥주'의 '지평에서'에 대해 설명해주세요. -> WMD: 0.6340\n",
      "✅ 88/100 질문 완료: '이재효'의 '0121-1110=1 0309'에 대해 설명해주세요. -> WMD: 0.5488\n",
      "✅ 89/100 질문 완료: '송성용'의 '행서(8곡병)'에 대해 설명해주세요. -> WMD: 0.4029\n",
      "✅ 90/100 질문 완료: '이중섭'의 '포도 따는 남자 '에 대해 설명해주세요. -> WMD: 0.6109\n",
      "✅ 91/100 질문 완료: '유영국'의 '작품004'에 대해 설명해주세요. -> WMD: 0.5956\n",
      "✅ 92/100 질문 완료: '전미숙'의 '기억의 풍경-전남 석곡'에 대해 설명해주세요. -> WMD: 0.6015\n",
      "✅ 93/100 질문 완료: '이병규'의 '부친상'에 대해 설명해주세요. -> WMD: 0.6326\n",
      "✅ 94/100 질문 완료: '김근중'의 '꽃세상 7-34'에 대해 설명해주세요. -> WMD: 0.5806\n",
      "✅ 95/100 질문 완료: '신현조'의 '고부(姑婦)'에 대해 설명해주세요. -> WMD: 0.7600\n",
      "✅ 96/100 질문 완료: '황재형'의 '가마타기'에 대해 설명해주세요. -> WMD: 0.7896\n",
      "✅ 97/100 질문 완료: '로버트 라우센버그'의 '판지 IV'에 대해 설명해주세요. -> WMD: 0.4952\n",
      "✅ 98/100 질문 완료: '김희중'의 '책방'에 대해 설명해주세요. -> WMD: 0.7342\n",
      "✅ 99/100 질문 완료: '김기승'의 '동맹(전서) 고구려'에 대해 설명해주세요. -> WMD: 0.6617\n",
      "✅ 100/100 질문 완료: '이인영'의 '만하'에 대해 설명해주세요. -> WMD: 0.6281\n",
      "✅ 평가 완료! 결과가 'dataset_csv/qa_0209_wmd_result.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from kiwipiepy import Kiwi\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# ✅ Kiwi 형태소 분석기 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# ✅ Word2Vec 모델 로드\n",
    "word_vectors = KeyedVectors.load(\"cc.ko.300.kv\")\n",
    "\n",
    "# ✅ JSON 파일 로드\n",
    "json_file_path = \"qa_dataset_full_info_0209.json\"\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "# ✅ JSON 데이터를 DataFrame으로 변환\n",
    "qa_pairs = []\n",
    "for item in qa_data:\n",
    "    text_parts = item[\"text\"].split(\"### Instruction:\\n\")  # 질문 추출\n",
    "    if len(text_parts) > 1:\n",
    "        question_part = text_parts[1].split(\"\\n\\n### Input:\\n\\n\\n\")[0]  # 질문\n",
    "        answer_part = text_parts[1].split(\"### Response:\\n\")[1].replace(\"<|endoftext|>\", \"\").strip()  # 정답\n",
    "        qa_pairs.append({\"question\": question_part, \"ground_truth\": answer_part})\n",
    "\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# ✅ 평가 진행\n",
    "results = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    question = str(row[\"question\"].strip())\n",
    "    ground_truth = str(row[\"ground_truth\"]).strip()\n",
    "\n",
    "    # ✅ RAG 모델을 이용해 답변 생성\n",
    "    model_answer = ask_question({\"question\": question})\n",
    "    model_text = model_answer[\"answer\"]\n",
    "\n",
    "    # ✅ WMD 점수 계산\n",
    "    def preprocess(text):\n",
    "        return [token.form for token in kiwi.tokenize(text) if token.form in word_vectors]\n",
    "\n",
    "    ground_tokens = preprocess(ground_truth)\n",
    "    model_tokens = preprocess(model_text)\n",
    "\n",
    "    if ground_tokens and model_tokens:\n",
    "        wmd_score = word_vectors.wmdistance(ground_tokens, model_tokens)\n",
    "    else:\n",
    "        wmd_score = float(\"inf\")  # WMD를 계산할 수 없는 경우 (빈 토큰 리스트)\n",
    "\n",
    "    # ✅ 결과 저장\n",
    "    results.append([i + 1, question, model_text, ground_truth, wmd_score])\n",
    "\n",
    "    print(f\"✅ {i+1}/{len(df)} 질문 완료: {question} -> WMD: {wmd_score:.4f}\")\n",
    "\n",
    "# ✅ CSV 저장\n",
    "csv_output = \"dataset_csv/qa_0209_wmd_result.csv\"\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    \"Index\", \"Question\", \"RAG Answer\", \"Ground Truth\", \"WMD\"\n",
    "])\n",
    "df_results.to_csv(csv_output, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ 평가 완료! 결과가 '{csv_output}' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-09 21:22:25--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ko.300.vec.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.168.167.115, 3.168.167.101, 3.168.167.7, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.168.167.115|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1267506825 (1.2G) [binary/octet-stream]\n",
      "Saving to: ‘cc.ko.300.vec.gz’\n",
      "\n",
      "cc.ko.300.vec.gz    100%[===================>]   1.18G  17.3MB/s    in 76s     \n",
      "\n",
      "2025-02-09 21:23:43 (15.9 MB/s) - ‘cc.ko.300.vec.gz’ saved [1267506825/1267506825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ko.300.vec.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip cc.ko.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# ✅ FastText 벡터 파일 로드 (encoding='latin1' 사용)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(\"cc.ko.300.vec\", binary=False, encoding=\"latin1\")\n",
    "\n",
    "# ✅ KeyedVectors 형식으로 저장\n",
    "word_vectors.save(\"cc.ko.300.kv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Question</th>\n",
       "      <th>RAG Answer</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>WMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'한진만'의 '월명리'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 한진만의 '월명리' (작품 번호: 3104) 설명\\n\\...</td>\n",
       "      <td>월명리 月明里 Wolmyung Village 한진만 HAN Jinman 3104 1...</td>\n",
       "      <td>0.510371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>'전국광'의 '매스의 내면-3부작'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 전국광의 '매스의 내면-3부작' 설명\\n\\n**작품 정...</td>\n",
       "      <td>매스의 내면-3부작 N/A Inner Mass Tryptich 전국광 CHUN Ko...</td>\n",
       "      <td>0.414766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>'노수현'의 '산수화'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 노수현의 '산수화' (작품 번호: 145) 설명\\n\\n...</td>\n",
       "      <td>산수화 山水畵 Landscape 노수현 NO Soohyeon 145 1956 124...</td>\n",
       "      <td>0.519465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>'김차섭'의 '자화상'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 김차섭의 '자화상' 설명\\n\\n**작품 정보:**\\n*...</td>\n",
       "      <td>자화상 自畵像 Self-Portrait 김차섭 KIM Tchahsup 2555 19...</td>\n",
       "      <td>0.780536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>'베른트 베허 + 힐라 베허'의 '벽과 배관'에 대해 설명해주세요.</td>\n",
       "      <td>### 모델 결과\\n\\n## 베른트 베허 + 힐라 베허 - **벽과 배관** (Wa...</td>\n",
       "      <td>벽과 배관 N/A Walls and Conduits 베른트 베허 + 힐라 베허 Be...</td>\n",
       "      <td>0.556015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                               Question  \\\n",
       "0      1               '한진만'의 '월명리'에 대해 설명해주세요.   \n",
       "1      2        '전국광'의 '매스의 내면-3부작'에 대해 설명해주세요.   \n",
       "2      3               '노수현'의 '산수화'에 대해 설명해주세요.   \n",
       "3      4               '김차섭'의 '자화상'에 대해 설명해주세요.   \n",
       "4      5  '베른트 베허 + 힐라 베허'의 '벽과 배관'에 대해 설명해주세요.   \n",
       "\n",
       "                                          RAG Answer  \\\n",
       "0  ### 모델 결과\\n\\n## 한진만의 '월명리' (작품 번호: 3104) 설명\\n\\...   \n",
       "1  ### 모델 결과\\n\\n## 전국광의 '매스의 내면-3부작' 설명\\n\\n**작품 정...   \n",
       "2  ### 모델 결과\\n\\n## 노수현의 '산수화' (작품 번호: 145) 설명\\n\\n...   \n",
       "3  ### 모델 결과\\n\\n## 김차섭의 '자화상' 설명\\n\\n**작품 정보:**\\n*...   \n",
       "4  ### 모델 결과\\n\\n## 베른트 베허 + 힐라 베허 - **벽과 배관** (Wa...   \n",
       "\n",
       "                                        Ground Truth       WMD  \n",
       "0  월명리 月明里 Wolmyung Village 한진만 HAN Jinman 3104 1...  0.510371  \n",
       "1  매스의 내면-3부작 N/A Inner Mass Tryptich 전국광 CHUN Ko...  0.414766  \n",
       "2  산수화 山水畵 Landscape 노수현 NO Soohyeon 145 1956 124...  0.519465  \n",
       "3  자화상 自畵像 Self-Portrait 김차섭 KIM Tchahsup 2555 19...  0.780536  \n",
       "4  벽과 배관 N/A Walls and Conduits 베른트 베허 + 힐라 베허 Be...  0.556015  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 로드\n",
    "csv_file_path = \"dataset_csv/qa_0209_wmd_result.csv\"\n",
    "df_results = pd.read_csv(csv_file_path)\n",
    "\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6244326500071223"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmd_mean = df_results['WMD'].mean()\n",
    "wmd_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean       0.624433\n",
       "std        0.104780\n",
       "min        0.402888\n",
       "25%        0.555425\n",
       "50%        0.626422\n",
       "75%        0.691509\n",
       "max        0.893228\n",
       "Name: WMD, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['WMD'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.624433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>0.104780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.402888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25%</td>\n",
       "      <td>0.555425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50%</td>\n",
       "      <td>0.626422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75%</td>\n",
       "      <td>0.691509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max</td>\n",
       "      <td>0.893228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Statistic       Value\n",
       "0     count  100.000000\n",
       "1      mean    0.624433\n",
       "2       std    0.104780\n",
       "3       min    0.402888\n",
       "4       25%    0.555425\n",
       "5       50%    0.626422\n",
       "6       75%    0.691509\n",
       "7       max    0.893228"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WMD 열의 통계 요약\n",
    "wmd_summary = df_results['WMD'].describe().to_frame().reset_index()\n",
    "wmd_summary.columns = [\"Statistic\", \"Value\"]\n",
    "\n",
    "# 데이터프레임 표시\n",
    "wmd_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
