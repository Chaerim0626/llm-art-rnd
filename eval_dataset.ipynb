{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG 성능 테스트를 위한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드|\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# LangSmith 추적 비활성화\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA 데이터셋이 생성되었습니다: ./qa_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# JSON 파일 로드\n",
    "json_path = \"./json_data.json\"  # JSON 파일 경로\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    artworks = json.load(f)\n",
    "\n",
    "# 질문 템플릿\n",
    "question_templates = {\n",
    "    \"year\": \"'{artist}'의 '{title}'은(는) 몇 년도에 제작되었나요?\",\n",
    "    \"size\": \"'{artist}'의 '{title}' 크기는 어떻게 되나요?\",\n",
    "    \"materials\": \"'{artist}'의 '{title}' 제작에 사용된 소재는 무엇인가요?\",\n",
    "    \"category\": \"'{artist}'의 '{title}'은(는) 어떤 카테고리에 속하나요?\",\n",
    "    \"artwork_number\": \"'{artist}'의 '{title}'의 작품 번호는 무엇인가요?\"\n",
    "}\n",
    "\n",
    "# 평가 데이터 생성\n",
    "qa_dataset = []\n",
    "random.shuffle(artworks)  # 무작위로 섞기\n",
    "selected_artworks = artworks[:100]  # 100개 선택\n",
    "\n",
    "for artwork in selected_artworks:\n",
    "    available_keys = [key for key in question_templates if key in artwork and artwork[key]]  # 값이 존재하는 필드만 사용\n",
    "    if available_keys:\n",
    "        selected_key = random.choice(available_keys)  # 랜덤하게 하나 선택\n",
    "        question = question_templates[selected_key].format(artist=artwork['artist'], title=artwork['title'])\n",
    "        answer = artwork[selected_key]\n",
    "\n",
    "        qa_dataset.append({\n",
    "            \"text\": f\"<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response in Korean that appropriately completes the request.\\n\\n\"\n",
    "                    f\"### Instruction:\\n{question}\\n\\n\"\n",
    "                    f\"### Input:\\n\\n\\n\"\n",
    "                    f\"### Response:\\n{answer}<|endoftext|>\"\n",
    "        })\n",
    "\n",
    "# JSON 파일 저장\n",
    "json_output_path = \"./qa_dataset.json\"\n",
    "with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"QA 데이터셋이 생성되었습니다: {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA 데이터셋이 생성되었습니다: ./qa_dataset_description.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# JSON 파일 로드\n",
    "json_path = \"./json_data.json\"  # JSON 파일 경로\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    artworks = json.load(f)\n",
    "\n",
    "# 평가 데이터 생성\n",
    "qa_dataset = []\n",
    "random.shuffle(artworks)  # 무작위로 섞기\n",
    "selected_artworks = artworks[:100]  # 100개 선택\n",
    "\n",
    "for artwork in selected_artworks:\n",
    "    if \"artist\" in artwork and \"title\" in artwork and \"description\" in artwork:\n",
    "        question = f\"'{artwork['artist']}'의 '{artwork['title']}'에 대해 설명해주세요.\"\n",
    "        answer = artwork[\"description\"]\n",
    "\n",
    "        qa_dataset.append({\n",
    "            \"text\": f\"<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response in Korean that appropriately completes the request.\\n\\n\"\n",
    "                    f\"### Instruction:\\n{question}\\n\\n\"\n",
    "                    f\"### Input:\\n\\n\\n\"\n",
    "                    f\"### Response:\\n{answer}<|endoftext|>\"\n",
    "        })\n",
    "\n",
    "# JSON 파일 저장\n",
    "json_output_path = \"./qa_dataset_description.json\"\n",
    "with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"QA 데이터셋이 생성되었습니다: {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith 데이터셋 100개 업로드가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from langsmith import Client\n",
    "import pandas as pd\n",
    "\n",
    "# data/qa_dataset.json 파일에서 데이터 불러오기\n",
    "with open(\"./qa_dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "# 데이터 100개 랜덤 추출\n",
    "random.seed(42)  # 재현성을 위한 시드 설정\n",
    "sampled_data = random.sample(data_list, 100)\n",
    "\n",
    "# Langsmith 형식으로 변환 함수\n",
    "def convert_to_langsmith_format(data_list):\n",
    "    questions, answers = [], []\n",
    "    for data in data_list:\n",
    "        text = data[\"text\"]\n",
    "        \n",
    "        # Instruction 추출\n",
    "        instruction_start = text.find(\"### Instruction:\\n\") + len(\"### Instruction:\\n\")\n",
    "        instruction_end = text.find(\"\\n\\n### Input:\")\n",
    "        question = text[instruction_start:instruction_end].strip()\n",
    "        \n",
    "        # Response 추출\n",
    "        response_start = text.find(\"### Response:\\n\") + len(\"### Response:\\n\")\n",
    "        response_end = text.find(\"<|endoftext|>\")\n",
    "        answer = text[response_start:response_end].strip()\n",
    "        \n",
    "        questions.append(question)\n",
    "        answers.append(answer)\n",
    "    return pd.DataFrame({\"question\": questions, \"answer\": answers})\n",
    "\n",
    "# 변환 실행\n",
    "df = convert_to_langsmith_format(sampled_data)\n",
    "\n",
    "# Langsmith Client 연결\n",
    "client = Client()\n",
    "dataset_name = \"RAG_EVAL_DATASET_NEW\"\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def create_dataset(client, dataset_name, description=None):\n",
    "    for dataset in client.list_datasets():\n",
    "        if dataset.name == dataset_name:\n",
    "            return dataset\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=description,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = create_dataset(client, dataset_name)\n",
    "\n",
    "# 생성된 데이터셋에 예제 추가\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in df[\"question\"].tolist()],\n",
    "    outputs=[{\"answer\": a} for a in df[\"answer\"].tolist()],\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n",
    "print(\"Langsmith 데이터셋 100개 업로드가 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'배만실'의 '태고의 흔적'은(는) 어떤 카테고리에 속하나요?</td>\n",
       "      <td>공예</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'황규백'의 '당구'은(는) 어떤 카테고리에 속하나요?</td>\n",
       "      <td>판화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'손일봉'의 '정자'의 작품 번호는 무엇인가요?</td>\n",
       "      <td>2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'임홍순'의 '고비' 크기는 어떻게 되나요?</td>\n",
       "      <td>120×30×6×(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'황규태'의 '픽셀'은(는) 어떤 카테고리에 속하나요?</td>\n",
       "      <td>사진</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             question        answer\n",
       "0  '배만실'의 '태고의 흔적'은(는) 어떤 카테고리에 속하나요?            공예\n",
       "1      '황규백'의 '당구'은(는) 어떤 카테고리에 속하나요?            판화\n",
       "2          '손일봉'의 '정자'의 작품 번호는 무엇인가요?          2434\n",
       "3            '임홍순'의 '고비' 크기는 어떻게 되나요?  120×30×6×(2)\n",
       "4      '황규태'의 '픽셀'은(는) 어떤 카테고리에 속하나요?            사진"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chae/faiss_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:23<00:00,  3.40s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "\n",
    "# 모델과 토크나이저 로드 (CUDA 사용)\n",
    "model_id = \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"cuda\",  # CUDA에서 자동 배치\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "/tmp/ipykernel_839/1315975019.py:15: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 파이프라인 생성\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,  # 생성할 최대 토큰 수 증가\n",
    "    do_sample=True,        # 샘플링 활성화\n",
    "    temperature=0.1,      \n",
    "    top_k=50,             \n",
    "    repetition_penalty=1.05\n",
    ")\n",
    "# LangChain의 HuggingFacePipeline 사용\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = '''\n",
    "<|system|>\n",
    "You are a friendly chatbot specializing in artworks. \n",
    "Answer questions strictly based on the information provided in the document (context). \n",
    "If the requested information is not found in the document, respond with \"The document does not contain this information.\" \n",
    "Provide comprehensive answers, always include the artwork number, and ensure all answers are written in Korean. \n",
    "All answers should be formatted using beautiful Markdown syntax to make the response visually appealing and easy to read. \n",
    "Use headings, bullet points, and bold or italic text where appropriate to enrich the response.\n",
    "\n",
    "<|context|>\n",
    "{context}\n",
    "\n",
    "<|user|>\n",
    "Question: {question}\n",
    "\n",
    "<|assistant|>\n",
    "'''\n",
    "\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 데이터베이스가 성공적으로 로드되었습니다!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"nlpai-lab/KURE-v1\")\n",
    "\n",
    "\n",
    "# 기존 DB 로드 \n",
    "persist_directory = \"./faiss_artworks_0114_docx\"\n",
    "\n",
    "try:\n",
    "    faiss_db = FAISS.load_local(\n",
    "        folder_path=persist_directory,\n",
    "        embeddings=embedding_model,\n",
    "        allow_dangerous_deserialization=True  # 신뢰할 수 있는 소스에서만 사용\n",
    "    )\n",
    "    \n",
    "    # embedding_function 수정\n",
    "    faiss_db.embedding_function = lambda text: (\n",
    "        embedding_model.encode(text) if isinstance(text, str) else embedding_model.encode(str(text))\n",
    "    )\n",
    "    \n",
    "    print(\"FAISS 데이터베이스가 성공적으로 로드되었습니다!\")\n",
    "except Exception as e:\n",
    "    print(f\"FAISS 데이터베이스 로드 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_db.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                # 검색 결과 개수\n",
    "        \"fetch_k\": 20,         # 더 많은 결과 가져오기\n",
    "        \"mmr\": True,           # MMR 활성화\n",
    "        \"mmr_beta\": 0.8      # 다양성과 관련성 간 균형\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class MarkdownOutputParser:\n",
    "    \"\"\"Enhanced Markdown parser with additional formatting options.\"\"\"\n",
    "\n",
    "    def __call__(self, llm_output):\n",
    "        # <assistant> 이후의 텍스트만 추출\n",
    "        match = re.search(r\"<\\|assistant\\|>\\s*(.*)\", llm_output, re.DOTALL)\n",
    "        if match:\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # 마크다운 코드 블록으로 출력 포맷\n",
    "            return f\"### 모델 결과\\n\\n{extracted_text}\\n\\n\"\n",
    "        else:\n",
    "            # <assistant> 태그가 없는 경우 원래 출력 반환\n",
    "            return f\"### 모델 결과\\n\\n{llm_output.strip()}\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough, RunnableMap\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": retriever,               # Retriever에서 반환된 값을 가져옴\n",
    "        \"question\": RunnablePassthrough()   # 질문은 그대로 전달\n",
    "    })\n",
    "    | (lambda x: {\n",
    "        \"context\": \"\\n\".join([doc.page_content for doc in x[\"context\"]]),\n",
    "        \"question\": x[\"question\"]\n",
    "    })  # context를 문자열로 변환\n",
    "    | prompt                               # Prompt Template에 전달\n",
    "    | llm                                  # LLM으로 응답 생성\n",
    "    | MarkdownOutputParser()                    # 응답을 문자열로 변환\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 모델 결과\n",
      "\n",
      "**노란 저고리**는 **김종태** 작가의 작품입니다.  \n",
      "**작품 번호**: 128  \n",
      "**제작 연도**: 1929\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"노란저고리는 누구 작품인가요?\"\n",
    "response = chain.invoke({\"question\": query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '### 모델 결과\\n\\n**노란 저고리**는 **김종태** 작가의 작품입니다. 작품 번호는 **PA-00128**입니다.\\n\\n'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자 질문 예시\n",
    "llm_answer = ask_question(\n",
    "    {\"question\": \"노란저고리는 누구 작품인가요?\"}\n",
    ")\n",
    "llm_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator prompt 출력을 위한 함수\n",
    "def print_evaluator_prompt(evaluator):\n",
    "    return evaluator.evaluator.prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-Answer Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a teacher grading a quiz.\n",
      "You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
      "\n",
      "Example Format:\n",
      "QUESTION: question here\n",
      "STUDENT ANSWER: student's answer here\n",
      "TRUE ANSWER: true answer here\n",
      "GRADE: CORRECT or INCORRECT here\n",
      "\n",
      "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \n",
      "\n",
      "QUESTION: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n",
      "STUDENT ANSWER: \u001b[33;1m\u001b[1;3m{result}\u001b[0m\n",
      "TRUE ANSWER: \u001b[33;1m\u001b[1;3m{answer}\u001b[0m\n",
      "GRADE:\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# qa 평가자 생성\n",
    "qa_evalulator = LangChainStringEvaluator(\"qa\")\n",
    "\n",
    "# 프롬프트 출력\n",
    "print_evaluator_prompt(qa_evalulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: RAG_EVAL_DATASET, ID: b2eb4069-1183-45d7-a21e-5ede0db30bca\n",
      "Dataset Name: RAG_EVAL_DATASET_NEW, ID: 77cefd19-3314-4440-8ba8-f05ea51fb422\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# LangSmith에 존재하는 데이터셋 리스트 출력\n",
    "datasets = list(client.list_datasets())\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Dataset Name: {dataset.name}, ID: {dataset.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'RAG_EVAL-2da95c4c' at:\n",
      "https://smith.langchain.com/o/a89b03f2-9920-4620-a0d1-5b700d444e04/datasets/d5f446c6-5b3c-47fd-a73e-d8d0c7079921/compare?selectedSessions=31a85e88-5669-4f38-b899-4eb854f5d13a\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [06:56,  4.16s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"RAG_EVAL_DATASET_NEW\"\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[qa_evalulator],\n",
    "    experiment_prefix=\"RAG_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"QA Evaluator 를 활용한 평가 (1024)\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: RAG_EVAL_DATASET, ID: b2eb4069-1183-45d7-a21e-5ede0db30bca\n",
      "Dataset Name: RAG_EVAL_DATASET_NEW, ID: 77cefd19-3314-4440-8ba8-f05ea51fb422\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'김기승'의 '진신(전서)'에 대해 설명해주세요.\"} outputs={'answer': '원곡(原谷) 김기승(1909-2000)은 한국 현대 서예사의 대표적인 작가이다. 1946년 소전(素筌) 손재형(孫在馨) 문하에 들어가 본격적인 서예공부를 시작하였고, 《제1-4회 대한민국미술전람회》(1949, 1953-1955)까지 잇달아 서예부 특선을 차지하여 문교부장관상을 수상하였다. 1955년에는 대성서예원(大成書藝院)을 설립하였고, 1978년에는 원곡서예상(原谷書藝賞)을 제정하기도 하였다.김기승은 《제10회 대한민국미술전람회》(1961)의 취지문에서 \"한국적 향기와 한국인의 체취를 풍기는 작품을 제작하기 위하여 온몸을 혹사하면서까지 많은 노력을 기울였으며, 서예의 경지를 어느 단계에 끌어올리려고 정성을 다하였다\"라고 언급한 바 있다. 한국적 정취를 효과적으로 드러내면서도 특정 형식이나 글자 형태에 제한되지 않고 새롭고 율동적인 필세와 개성적인 감각을 추구하는 김기승의 작품들은 작가의 이러한 취지를 잘 드러낸다.또한 김기승은 원곡체(原谷體)를 만들어내고 묵영(墨映)을 창안하는 등, 서예계의 원로임에도 불구하고 새로움을 추구하는 데 게을리 하지 않은 작가이다. 원곡 자신이 전위적이라고 말하는 \\'묵영\\'이란 청묵(靑墨)의 번짐을 사용하거나 먹물의 농담을 이용하여 시각효과를 부각시킨 회화적 서예이다. 일부에서 묵영을 \\'전통을 무시한 예술\\'이라고 몰아붙이자 \"전통을 지키기 위해서는 다각적인 실험작업을 통해 새로운 조형언어를 만들어내야 한다\"고 맞설 정도로 원곡은 새로움을 추구하였다.이 작품에서 김기승은 \\'眞神(진신: 참 정신)’이라는 내용을 전서(篆書)로 표현하였는데, ‘진(眞)’자는 안정감이 있게 하고 ‘신(神)’자는 정신이 날아오르는 듯 표현을 하였다. 차분한 필획과 갈필이 적당하게 들어 있는 활달한 필획이 조화를 잘 이루었고 ‘진(眞)’자 아래에 자리한 협서(脇書)와 좌측에 쓴 협서도 전체 작품과 조화를 잘 이루고 있다.[작품해석]참 정신, 문에 이르기를 참 정신이라.태초 창조시에는, 천지가 높이 매달려 있고, 해와 달 뭇 별들이, 밤낮을 밝게 비추었으며, 만류의 연월과 일시가 분명하게 되었다.'} metadata={'dataset_split': ['base']} id=UUID('a33469a8-b612-4688-b5f0-a16057a397ee') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18379, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18379, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'이유태'의 '설악영봉(雪嶽靈峯)'에 대해 설명해주세요.\"} outputs={'answer': '금강산이나 한국의 자연풍경을 실경적 시각으로 해석하고 있는 현초(玄艸) 이유태(1916-1999)의 <설악영봉>(1965)은 수려한 담채미와 깊이 있는 먹색, 자유로운 필선의 조화를 바탕으로 제작되었다. 특히, 먹색의 농담조절과 갈필(渴筆)준을 이용한 용필법은 이 작품의 전통적 해석과 현대적 표현감각을 뒷받침하는 중요한 요소라고 말할 수 있다. 동양화의 전통 구도법 중 하나인 평원법과 고원법을 응용하여 표현된 이 작품은 가느다란 선묘의 율동이 두드러지면서도 고즈넉한 자연의 이미지가 은자적인 정서미로 승화되고 있으며 예부터 전래되어온 우리 전통 동양화의 조형적 기법과 특성을 잘 보여주는 매우 뛰어난 이유태의 대표작 중 하나라고 볼 수 있다.평소 마치 바탕의 화지에서 우러나는 듯한 맑은 느낌의 수묵 구사 기법은 그의 작품을 특징 지워주는 중요한 표현 요소로 작가는 초기 진채(眞彩)와 먹색 위주의 산수화에서 후기로 갈수록 점차 담채가 주요한 실경(實景)의 사경(寫景) 산수화풍을 제작하기도 하였던 것이다.'} metadata={'dataset_split': ['base']} id=UUID('afc13964-e552-4523-86ec-df5422e9a439') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18370, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18370, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'김영대'의 '와성' 크기는 어떻게 되나요?\"} outputs={'answer': '78×130×68'} metadata={'dataset_split': ['base']} id=UUID('d1f99316-21e1-43ad-ab7d-059088e23a52') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18362, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18362, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'한용진'의 '작품 62' 제작에 사용된 소재는 무엇인가요?\"} outputs={'answer': '종이에 목판'} metadata={'dataset_split': ['base']} id=UUID('4783a17e-eb74-46e8-ad52-9776b7c80d3c') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18354, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18354, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n",
      "dataset_id=UUID('77cefd19-3314-4440-8ba8-f05ea51fb422') inputs={'question': \"'김정숙 a'의 '비상'은(는) 어떤 카테고리에 속하나요?\"} outputs={'answer': '조각ㆍ설치'} metadata={'dataset_split': ['base']} id=UUID('ed2096fc-7ad6-4149-991b-5a53836a9caa') created_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18345, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 2, 3, 7, 59, 25, 18345, tzinfo=datetime.timezone.utc) runs=[] source_run_id=None\n"
     ]
    }
   ],
   "source": [
    "# LangSmith에서 데이터셋 불러오기\n",
    "datasets = client.list_datasets()\n",
    "for dataset in datasets:\n",
    "    print(f\"Dataset Name: {dataset.name}, ID: {dataset.id}\")\n",
    "\n",
    "# 데이터셋에서 데이터 샘플 확인 (제너레이터 → 리스트 변환)\n",
    "examples = list(client.list_examples(dataset_id=dataset.id))  # 리스트로 변환\n",
    "\n",
    "# 처음 5개만 출력\n",
    "for example in examples[:5]:  \n",
    "    print(example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요.', '반갑습니다.', '내', '이름은', '채림입니다.']\n",
      "['안녕하세용', '반갑습니다~^^', '내', '이름은', '채림입니다!!']\n",
      "============================================================\n",
      "['안녕', '하', '세요', '.', '반갑', '습니다', '.', '나', '의', '이름', '은', '채림', '이', 'ᆸ니다', '.']\n",
      "['안녕', '하', '세요', 'ᆼ', '반갑', '습니다', '~', '^^', '나', '의', '이름', '은', '채림', '이', 'ᆸ니다', '!!']\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.kiwi_tokenizer import KiwiTokenizer\n",
    "\n",
    "# 토크나이저 선언\n",
    "kiwi_tokenizer = KiwiTokenizer()\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세용 반갑습니다~^^ 내 이름은 채림입니다!!\"\n",
    "\n",
    "# 토큰화\n",
    "print(sent1.split())\n",
    "print(sent2.split())\n",
    "\n",
    "print(\"===\" * 20)\n",
    "\n",
    "# 토큰화\n",
    "print(kiwi_tokenizer.tokenize(sent1))\n",
    "print(kiwi_tokenizer.tokenize(sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\n",
      "[rouge1] 0.75862\n",
      "[rouge2] 0.59259\n",
      "[rougeL] 0.75862\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 내 이름은 채림입니다. 안녕하세요. 반갑습니다.\n",
      "[rouge1] 1.00000\n",
      "[rouge2] 0.92857\n",
      "[rougeL] 0.53333\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\"\n",
    "sent3 = \"내 이름은 채림입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(\n",
    "    [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=False, tokenizer=KiwiTokenizer()\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"[1] {sent1}\\n[2] {sent2}\\n[rouge1] {scorer.score(sent1, sent2)['rouge1'].fmeasure:.5f}\\n[rouge2] {scorer.score(sent1, sent2)['rouge2'].fmeasure:.5f}\\n[rougeL] {scorer.score(sent1, sent2)['rougeL'].fmeasure:.5f}\"\n",
    ")\n",
    "print(\"===\" * 20)\n",
    "print(\n",
    "    f\"[1] {sent1}\\n[2] {sent3}\\n[rouge1] {scorer.score(sent1, sent3)['rouge1'].fmeasure:.5f}\\n[rouge2] {scorer.score(sent1, sent3)['rouge2'].fmeasure:.5f}\\n[rougeL] {scorer.score(sent1, sent3)['rougeL'].fmeasure:.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕 하 세요 . 반갑 습니다 . 나 의 이름 은 채림 이 ᆸ니다 .\n",
      "안녕 하 세여 반갑 습니다 ~~~ 나 의 이름 은 채림 이 ᆸ니다 !!\n",
      "나 의 이름 은 채림 이 ᆸ니다 . 안녕 하 세요 . 반갑 습니다 .\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\"\n",
    "sent3 = \"내 이름은 채림입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "# 토큰화\n",
    "print(kiwi_tokenizer.tokenize(sent1, type=\"sentence\"))\n",
    "print(kiwi_tokenizer.tokenize(sent2, type=\"sentence\"))\n",
    "print(kiwi_tokenizer.tokenize(sent3, type=\"sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\n",
      "[score] 0.75503\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 내 이름은 채림입니다. 안녕하세요. 반갑습니다.\n",
      "[score] 0.95739\n"
     ]
    }
   ],
   "source": [
    "bleu_score = sentence_bleu(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"sentence\")],\n",
    "    kiwi_tokenizer.tokenize(sent2, type=\"sentence\"),\n",
    ")\n",
    "print(f\"[1] {sent1}\\n[2] {sent2}\\n[score] {bleu_score:.5f}\")\n",
    "print(\"===\" * 20)\n",
    "\n",
    "bleu_score = sentence_bleu(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"sentence\")],\n",
    "    kiwi_tokenizer.tokenize(sent3, type=\"sentence\"),\n",
    ")\n",
    "print(f\"[1] {sent1}\\n[2] {sent3}\\n[score] {bleu_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/chae/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\n",
      "[score] 0.73077\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 내 이름은 채림입니다. 안녕하세요. 반갑습니다.\n",
      "[score] 0.96800\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate import meteor_score\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\"\n",
    "sent3 = \"내 이름은 채림입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "meteor = meteor_score.meteor_score(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"list\")],\n",
    "    kiwi_tokenizer.tokenize(sent2, type=\"list\"),\n",
    ")\n",
    "\n",
    "print(f\"[1] {sent1}\\n[2] {sent2}\\n[score] {meteor:.5f}\")\n",
    "print(\"===\" * 20)\n",
    "\n",
    "meteor = meteor_score.meteor_score(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"list\")],\n",
    "    kiwi_tokenizer.tokenize(sent3, type=\"list\"),\n",
    ")\n",
    "print(f\"[1] {sent1}\\n[2] {sent3}\\n[score] {meteor:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\n",
      "[score] 0.88842\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 채림입니다.\n",
      "[2] 내 이름은 채림입니다. 안녕하세요. 반갑습니다.\n",
      "[score] 0.99265\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 채림입니다.\"\n",
    "sent2 = \"안녕하세여 반갑습니다~~~ 내 이름은 채림입니다!!\"\n",
    "sent3 = \"내 이름은 채림입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "# SentenceTransformer 모델 로드\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# 문장들을 인코딩\n",
    "sent1_encoded = model.encode(sent1, convert_to_tensor=True)\n",
    "sent2_encoded = model.encode(sent2, convert_to_tensor=True)\n",
    "sent3_encoded = model.encode(sent3, convert_to_tensor=True)\n",
    "\n",
    "# sent1과 sent2 사이의 코사인 유사도 계산\n",
    "cosine_similarity = util.pytorch_cos_sim(sent1_encoded, sent2_encoded).item()\n",
    "print(f\"[1] {sent1}\\n[2] {sent2}\\n[score] {cosine_similarity:.5f}\")\n",
    "\n",
    "print(\"===\" * 20)\n",
    "\n",
    "# sent1과 sent3 사이의 코사인 유사도 계산\n",
    "cosine_similarity = util.pytorch_cos_sim(sent1_encoded, sent3_encoded).item()\n",
    "print(f\"[1] {sent1}\\n[2] {sent3}\\n[score] {cosine_similarity:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate import meteor_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "\n",
    "# 토크나이저 병렬화 설정(HuggingFace 모델 사용)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "\n",
    "def rouge_evaluator(metric: str = \"rouge1\") -> dict:\n",
    "    # wrapper function 정의\n",
    "    def _rouge_evaluator(run: Run, example: Example) -> dict:\n",
    "        # 출력값과 정답 가져오기\n",
    "        student_answer = run.outputs.get(\"answer\", \"\")\n",
    "        reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "        # ROUGE 점수 계산\n",
    "        scorer = rouge_scorer.RougeScorer(\n",
    "            [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True, tokenizer=KiwiTokenizer()\n",
    "        )\n",
    "        scores = scorer.score(reference_answer, student_answer)\n",
    "\n",
    "        # ROUGE 점수 반환\n",
    "        rouge = scores[metric].fmeasure\n",
    "\n",
    "        return {\"key\": \"ROUGE\", \"score\": rouge}\n",
    "\n",
    "    return _rouge_evaluator\n",
    "\n",
    "\n",
    "def bleu_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"sentence\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"sentence\")\n",
    "\n",
    "    # BLEU 점수 계산\n",
    "    bleu_score = sentence_bleu([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"BLEU\", \"score\": bleu_score}\n",
    "\n",
    "\n",
    "def meteor_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"list\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"list\")\n",
    "\n",
    "    # METEOR 점수 계산\n",
    "    meteor = meteor_score.meteor_score([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"METEOR\", \"score\": meteor}\n",
    "\n",
    "\n",
    "def semscore_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # SentenceTransformer 모델 로드\n",
    "    model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "    # 문장 임베딩 생성\n",
    "    student_embedding = model.encode(student_answer, convert_to_tensor=True)\n",
    "    reference_embedding = model.encode(reference_answer, convert_to_tensor=True)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    cosine_similarity = util.pytorch_cos_sim(\n",
    "        student_embedding, reference_embedding\n",
    "    ).item()\n",
    "\n",
    "    return {\"key\": \"sem_score\", \"score\": cosine_similarity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Heuristic-EVAL-c226f7a4' at:\n",
      "https://smith.langchain.com/o/a89b03f2-9920-4620-a0d1-5b700d444e04/datasets/5aae75ae-47e4-48e5-823c-eb233a86f9b9/compare?selectedSessions=fe8da49f-37f6-4c33-b673-2f14fff635db\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [06:14, 37.46s/it]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 평가자 정의\n",
    "heuristic_evalulators = [\n",
    "    rouge_evaluator(metric=\"rougeL\"),\n",
    "    bleu_evaluator,\n",
    "    meteor_evaluator,\n",
    "    semscore_evaluator,\n",
    "]\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"ds-0204\"\n",
    "\n",
    "# 실험 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=heuristic_evalulators,\n",
    "    experiment_prefix=\"Heuristic-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Heuristic-EVAL (Rouge, BLEU, METEOR, SemScore) 을 사용하여 평가\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langsmith를 활용하지 않은 로컬 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 1/10 질문 완료: 한국 추상회화의 독특한 접근 방식으로 잘 알려진 박항섭의 작품은 특히 개인적, 역사적 주제에 대한 탐구라는 측면에서 그의 독특한 세계관을 어떻게 반영하고 있나요? -> SemScore: 0.7849, ROUGE-1: 0.6667, ROUGE-2: 0.0000, BLEU: 0.0776, METEOR: 0.3715\n",
      "✅ 2/10 질문 완료: 홍정희 작가의 작품 '광산-희망'에 사용된 콜라주 기법은 어떻게 사용되었나요? -> SemScore: 0.9507, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0731, METEOR: 0.3773\n",
      "✅ 3/10 질문 완료: 최종태 작가의 '생각 속의 여인'의 특징과 화풍은 무엇인가요? -> SemScore: 0.7896, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0580, METEOR: 0.3217\n",
      "✅ 4/10 질문 완료: 박항섭과 김경원의 작품에서 볼 수 있는 한국 추상회화의 특징은 무엇인가요? -> SemScore: 0.9314, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0650, METEOR: 0.3387\n",
      "✅ 5/10 질문 완료: 한국의 풍경과 가족을 강조한 1957년 이수옥의 작품으로 여인과 두 아이가 등장하는 작품은 무엇인가요? -> SemScore: 0.8470, ROUGE-1: 0.4000, ROUGE-2: 0.0000, BLEU: 0.0295, METEOR: 0.3886\n",
      "✅ 6/10 질문 완료: 박성환의 '군무'(1976)는 한국의 풍경과 개인의 변화를 어떻게 묘사하고 있을까요? -> SemScore: 0.8926, ROUGE-1: 0.4000, ROUGE-2: 0.0000, BLEU: 0.0666, METEOR: 0.4056\n",
      "✅ 7/10 질문 완료: 장완 감독의 '침묵'에서 색과 빛은 어떻게 사실적인 단순함과 역동적인 표현의 매력적인 분위기를 불러일으킬 수 있을까요? -> SemScore: 0.6551, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0785, METEOR: 0.3540\n",
      "✅ 8/10 질문 완료: 박성환의 '군무'는 형태와 색채를 이용해 군무의 개성과 변화를 어떻게 표현할까요? -> SemScore: 0.8863, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0663, METEOR: 0.3298\n",
      "✅ 9/10 질문 완료: 오늘날의 문화적 변화는 박항섭의 1977년작 '마술사의 여행'에서 실존적이고 초현실적인 주제를 어떻게 변화시킬 수 있을까요? -> SemScore: 0.6309, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0018, METEOR: 0.0730\n",
      "✅ 10/10 질문 완료: 이수옥 작가의 '가족 초상화'에서 노란색과 갈색은 따뜻함을 자아냅니다. 색채 이론에 따라 다른 환경에서 이 색들이 어떻게 따뜻함을 전달할 수 있을까요? -> SemScore: 0.7364, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0009, METEOR: 0.0773\n",
      "✅ 평가 완료! 결과가 'evaluation_results_0206.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate import meteor_score\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "\n",
    "# 모델 및 토크나이저 초기화\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "kiwi = Kiwi()\n",
    "\n",
    "csv_file_path = 'dataset_csv/gpt_qa_translate.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    question = str(row['question'].strip())\n",
    "    ground_truth = str(row['ground_truth']).strip()\n",
    "\n",
    "    # ✅ RAG 모델을 이용해 답변 생성\n",
    "    model_answer = ask_question({\"question\": question})\n",
    "    model_text = model_answer[\"answer\"]  # ✅ 중요!\n",
    "\n",
    "    # ✅ SemScore 계산\n",
    "    ground_embedding = model.encode(ground_truth, convert_to_tensor=True)\n",
    "    model_embedding = model.encode(model_text, convert_to_tensor=True)\n",
    "    sem_score = util.pytorch_cos_sim(model_embedding, ground_embedding).item()\n",
    "\n",
    "    # ✅ ROUGE 점수 계산 (ROUGE-L 제거)\n",
    "    rouge = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"], use_stemmer=True)\n",
    "    rouge_scores = rouge.score(ground_truth, model_text)\n",
    "    rouge1 = rouge_scores[\"rouge1\"].fmeasure\n",
    "    rouge2 = rouge_scores[\"rouge2\"].fmeasure\n",
    "\n",
    "    # ✅ BLEU 점수 계산 (Smoothing 추가)\n",
    "    reference_tokens = [token.form for token in kiwi.tokenize(ground_truth)]\n",
    "    student_tokens = [token.form for token in kiwi.tokenize(model_text)]\n",
    "    smoothing = SmoothingFunction().method1  # BLEU 스무딩 적용\n",
    "    bleu_score = sentence_bleu([reference_tokens], student_tokens, smoothing_function=smoothing)\n",
    "\n",
    "    # ✅ METEOR 점수 계산\n",
    "    meteor = meteor_score.meteor_score([reference_tokens], student_tokens)\n",
    "\n",
    "    # ✅ 결과 저장\n",
    "    results.append([i + 1, question, model_text, ground_truth, rouge1, rouge2, bleu_score, meteor, sem_score])\n",
    "\n",
    "    print(f\"✅ {i+1}/{len(df)} 질문 완료: {question} -> SemScore: {sem_score:.4f}, ROUGE-1: {rouge1:.4f}, ROUGE-2: {rouge2:.4f}, BLEU: {bleu_score:.4f}, METEOR: {meteor:.4f}\")\n",
    "\n",
    "# ✅ CSV 저장\n",
    "csv_output = \"evaluation_results_0206.csv\"\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    \"Index\", \"Question\", \"RAG Answer\", \"Ground Truth\",\n",
    "    \"ROUGE-1\", \"ROUGE-2\", \"BLEU\", \"METEOR\", \"SemScore\"\n",
    "])\n",
    "df_results.to_csv(csv_output, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ 평가 완료! 결과가 '{csv_output}' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 1/100 질문 완료: '나혜석'의 '화령전작약(華寧殿芍藥)'에 대해 설명해주세요. -> SemScore: 0.7187, ROUGE-1: 0.1538, ROUGE-2: 0.0000, BLEU: 0.1354, METEOR: 0.2207\n",
      "✅ 2/100 질문 완료: '정희승'의 '무제'에 대해 설명해주세요. -> SemScore: 0.6665, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0845, METEOR: 0.2142\n",
      "✅ 3/100 질문 완료: '한운성'의 'Ranunculus Asiaticus'에 대해 설명해주세요. -> SemScore: 0.4556, ROUGE-1: 0.1176, ROUGE-2: 0.0000, BLEU: 0.1451, METEOR: 0.2758\n",
      "✅ 4/100 질문 완료: '홍선웅'의 '민중판화 대표작품'에 대해 설명해주세요. -> SemScore: 0.7460, ROUGE-1: 0.1176, ROUGE-2: 0.0000, BLEU: 0.2435, METEOR: 0.4598\n",
      "✅ 5/100 질문 완료: '유영국'의 '작품005'에 대해 설명해주세요. -> SemScore: 0.5674, ROUGE-1: 0.1739, ROUGE-2: 0.0909, BLEU: 0.1844, METEOR: 0.3270\n",
      "✅ 6/100 질문 완료: '김차섭'의 '자화상'에 대해 설명해주세요. -> SemScore: 0.6968, ROUGE-1: 0.1053, ROUGE-2: 0.0000, BLEU: 0.0711, METEOR: 0.2717\n",
      "✅ 7/100 질문 완료: '아우구스토 바로스'의 '연을 가진 남자'에 대해 설명해주세요. -> SemScore: 0.6347, ROUGE-1: 0.5161, ROUGE-2: 0.3448, BLEU: 0.1340, METEOR: 0.4950\n",
      "✅ 8/100 질문 완료: '하태진'의 '설경'에 대해 설명해주세요. -> SemScore: 0.5843, ROUGE-1: 0.1333, ROUGE-2: 0.0000, BLEU: 0.1801, METEOR: 0.3545\n",
      "✅ 9/100 질문 완료: '재커리 폼왈트'의 '파노라마와 법인의 탄생'에 대해 설명해주세요. -> SemScore: 0.5821, ROUGE-1: 0.2857, ROUGE-2: 0.1053, BLEU: 0.2578, METEOR: 0.4023\n",
      "✅ 10/100 질문 완료: '박서보'의 '닭'에 대해 설명해주세요. -> SemScore: 0.8028, ROUGE-1: 0.4000, ROUGE-2: 0.1111, BLEU: 0.2316, METEOR: 0.3460\n",
      "✅ 11/100 질문 완료: '이다 쇼이치'의 '종이작업'에 대해 설명해주세요. -> SemScore: 0.7073, ROUGE-1: 0.1667, ROUGE-2: 0.0000, BLEU: 0.1043, METEOR: 0.2470\n",
      "✅ 12/100 질문 완료: '이달주'의 '샘터'에 대해 설명해주세요. -> SemScore: 0.7022, ROUGE-1: 0.2857, ROUGE-2: 0.0000, BLEU: 0.2517, METEOR: 0.3558\n",
      "✅ 13/100 질문 완료: '고중광'의 '한간연상 II'에 대해 설명해주세요. -> SemScore: 0.7927, ROUGE-1: 0.2000, ROUGE-2: 0.0000, BLEU: 0.2127, METEOR: 0.5038\n",
      "✅ 14/100 질문 완료: '김수자 b'의 '05일기-부재'에 대해 설명해주세요. -> SemScore: 0.6112, ROUGE-1: 0.2500, ROUGE-2: 0.0000, BLEU: 0.1220, METEOR: 0.3519\n",
      "✅ 15/100 질문 완료: '육명심'의 '예술가의 초상 시리즈 - 피천득'에 대해 설명해주세요. -> SemScore: 0.7626, ROUGE-1: 0.4706, ROUGE-2: 0.3125, BLEU: 0.2001, METEOR: 0.3251\n",
      "✅ 16/100 질문 완료: '정상화'의 '작품 A'에 대해 설명해주세요. -> SemScore: 0.8929, ROUGE-1: 0.3448, ROUGE-2: 0.2222, BLEU: 0.1856, METEOR: 0.6002\n",
      "✅ 17/100 질문 완료: '최명영'의 '평면조건 824-B'에 대해 설명해주세요. -> SemScore: 0.5849, ROUGE-1: 0.2308, ROUGE-2: 0.1667, BLEU: 0.1462, METEOR: 0.3146\n",
      "✅ 18/100 질문 완료: '오치균'의 'Cement Yard'에 대해 설명해주세요. -> SemScore: 0.5261, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.1421, METEOR: 0.3793\n",
      "✅ 19/100 질문 완료: '김성환'의 '6.25 종군스케치 1951년 10월 29일 지뢰찾는 UN군'에 대해 설명해주세요. -> SemScore: 0.7719, ROUGE-1: 0.6349, ROUGE-2: 0.5246, BLEU: 0.2223, METEOR: 0.4756\n",
      "✅ 20/100 질문 완료: '고성종'의 '봉투 04-4'에 대해 설명해주세요. -> SemScore: 0.6691, ROUGE-1: 0.3333, ROUGE-2: 0.1250, BLEU: 0.0624, METEOR: 0.2926\n",
      "✅ 21/100 질문 완료: '육명심'의 '검은 모살뜸 시리즈-제주도 삼양'에 대해 설명해주세요. -> SemScore: 0.6248, ROUGE-1: 0.3571, ROUGE-2: 0.3077, BLEU: 0.1518, METEOR: 0.3886\n",
      "✅ 22/100 질문 완료: '육명심'의 '장승 시리즈-경상남도 진주 문산읍 소문리'에 대해 설명해주세요. -> SemScore: 0.6388, ROUGE-1: 0.2609, ROUGE-2: 0.0952, BLEU: 0.2270, METEOR: 0.2972\n",
      "✅ 23/100 질문 완료: '김녕만'의 '고향시리즈 055'에 대해 설명해주세요. -> SemScore: 0.7976, ROUGE-1: 0.3333, ROUGE-2: 0.0909, BLEU: 0.1267, METEOR: 0.3779\n",
      "✅ 24/100 질문 완료: '임응식'의 '이준 인물'에 대해 설명해주세요. -> SemScore: 0.6627, ROUGE-1: 0.2222, ROUGE-2: 0.0000, BLEU: 0.2665, METEOR: 0.4218\n",
      "✅ 25/100 질문 완료: '김영주'의 '드로잉'에 대해 설명해주세요. -> SemScore: 0.6620, ROUGE-1: 0.1250, ROUGE-2: 0.0435, BLEU: 0.1199, METEOR: 0.2938\n",
      "✅ 26/100 질문 완료: '우제길'의 '리듬 76-10B'에 대해 설명해주세요. -> SemScore: 0.7007, ROUGE-1: 0.3226, ROUGE-2: 0.2069, BLEU: 0.0950, METEOR: 0.4383\n",
      "✅ 27/100 질문 완료: '이종우'의 '누드(남)'에 대해 설명해주세요. -> SemScore: 0.8117, ROUGE-1: 0.3750, ROUGE-2: 0.1429, BLEU: 0.1147, METEOR: 0.3955\n",
      "✅ 28/100 질문 완료: '유강열'의 '작품'에 대해 설명해주세요. -> SemScore: 0.6144, ROUGE-1: 0.1754, ROUGE-2: 0.0000, BLEU: 0.1082, METEOR: 0.2652\n",
      "✅ 29/100 질문 완료: '이동훈'의 '산성풍경'에 대해 설명해주세요. -> SemScore: 0.7525, ROUGE-1: 0.3478, ROUGE-2: 0.0952, BLEU: 0.1393, METEOR: 0.4207\n",
      "✅ 30/100 질문 완료: '서세옥, 안동오'의 '백자 청화 산수 무늬 십이각 병'에 대해 설명해주세요. -> SemScore: 0.7587, ROUGE-1: 0.0833, ROUGE-2: 0.0000, BLEU: 0.1096, METEOR: 0.2198\n",
      "✅ 31/100 질문 완료: '손일봉'의 '모과'에 대해 설명해주세요. -> SemScore: 0.5712, ROUGE-1: 0.1429, ROUGE-2: 0.0000, BLEU: 0.1656, METEOR: 0.5289\n",
      "✅ 32/100 질문 완료: '홍경택'의 '모놀로그'에 대해 설명해주세요. -> SemScore: 0.6173, ROUGE-1: 0.0930, ROUGE-2: 0.0488, BLEU: 0.1185, METEOR: 0.3094\n",
      "✅ 33/100 질문 완료: '장두건'의 '투계'에 대해 설명해주세요. -> SemScore: 0.7468, ROUGE-1: 0.2105, ROUGE-2: 0.0000, BLEU: 0.1282, METEOR: 0.3264\n",
      "✅ 34/100 질문 완료: '김정묵'의 '외설악-봄'에 대해 설명해주세요. -> SemScore: 0.6422, ROUGE-1: 0.1818, ROUGE-2: 0.0000, BLEU: 0.1458, METEOR: 0.3675\n",
      "✅ 35/100 질문 완료: '도흥록'의 '빛을 그리다 2002-Ⅰ, Ⅱ, Ⅲ,  Ⅳ, Ⅴ'에 대해 설명해주세요. -> SemScore: 0.6490, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.1651, METEOR: 0.5183\n",
      "✅ 36/100 질문 완료: '토니 햅번'의 '세인트루이스의 문'에 대해 설명해주세요. -> SemScore: 0.6175, ROUGE-1: 0.4348, ROUGE-2: 0.3810, BLEU: 0.2178, METEOR: 0.4421\n",
      "✅ 37/100 질문 완료: '정진윤'의 '낚시터에서'에 대해 설명해주세요. -> SemScore: 0.6524, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.1842, METEOR: 0.2641\n",
      "✅ 38/100 질문 완료: '존 배'의 '간격'에 대해 설명해주세요. -> SemScore: 0.7319, ROUGE-1: 0.2667, ROUGE-2: 0.1538, BLEU: 0.0579, METEOR: 0.3714\n",
      "✅ 39/100 질문 완료: '변영원'의 '미상15'에 대해 설명해주세요. -> SemScore: 0.0375, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0000, METEOR: 0.0000\n",
      "✅ 40/100 질문 완료: '박영남'의 '하늘에 그려본 풍경'에 대해 설명해주세요. -> SemScore: 0.4770, ROUGE-1: 0.1176, ROUGE-2: 0.0000, BLEU: 0.1161, METEOR: 0.2753\n",
      "✅ 41/100 질문 완료: '최만린'의 '○ 94-1'에 대해 설명해주세요. -> SemScore: 0.5698, ROUGE-1: 0.2286, ROUGE-2: 0.0606, BLEU: 0.1367, METEOR: 0.2550\n",
      "✅ 42/100 질문 완료: '와타나베 도요시게'의 '두개의 사각형사이의 공간'에 대해 설명해주세요. -> SemScore: 0.6777, ROUGE-1: 0.3000, ROUGE-2: 0.0000, BLEU: 0.2650, METEOR: 0.3854\n",
      "✅ 43/100 질문 완료: '이철이'의 '자화상'에 대해 설명해주세요. -> SemScore: 0.6582, ROUGE-1: 0.4000, ROUGE-2: 0.1538, BLEU: 0.1931, METEOR: 0.4390\n",
      "✅ 44/100 질문 완료: '박래현'의 '기원'에 대해 설명해주세요. -> SemScore: 0.7090, ROUGE-1: 0.0889, ROUGE-2: 0.0000, BLEU: 0.1270, METEOR: 0.2349\n",
      "✅ 45/100 질문 완료: '김기승'의 '와당종승(전서) 주송돈명'에 대해 설명해주세요. -> SemScore: 0.6440, ROUGE-1: 0.1000, ROUGE-2: 0.0000, BLEU: 0.1210, METEOR: 0.2811\n",
      "✅ 46/100 질문 완료: '권순철'의 '용마산'에 대해 설명해주세요. -> SemScore: 0.7758, ROUGE-1: 0.1333, ROUGE-2: 0.0000, BLEU: 0.1386, METEOR: 0.3167\n",
      "✅ 47/100 질문 완료: '최종태'의 '달과 여인'에 대해 설명해주세요. -> SemScore: 0.6506, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.1895, METEOR: 0.2899\n",
      "✅ 48/100 질문 완료: '이동훈'의 '소'에 대해 설명해주세요. -> SemScore: 0.8277, ROUGE-1: 0.2000, ROUGE-2: 0.0000, BLEU: 0.2891, METEOR: 0.4361\n",
      "✅ 49/100 질문 완료: '이항성'의 '청도(淸道)'에 대해 설명해주세요. -> SemScore: 0.6111, ROUGE-1: 0.2400, ROUGE-2: 0.0870, BLEU: 0.0115, METEOR: 0.0332\n",
      "✅ 50/100 질문 완료: '장종완'의 '선물'에 대해 설명해주세요. -> SemScore: 0.6197, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.3208, METEOR: 0.3809\n",
      "✅ 51/100 질문 완료: '민병헌'의 '눈 3'에 대해 설명해주세요. -> SemScore: 0.7140, ROUGE-1: 0.2353, ROUGE-2: 0.1333, BLEU: 0.1750, METEOR: 0.5066\n",
      "✅ 52/100 질문 완료: '한운성'의 '욕심많은 거인'에 대해 설명해주세요. -> SemScore: 0.5869, ROUGE-1: 0.0870, ROUGE-2: 0.0000, BLEU: 0.1372, METEOR: 0.2625\n",
      "✅ 53/100 질문 완료: '이화자'의 '회상'에 대해 설명해주세요. -> SemScore: 0.7227, ROUGE-1: 0.2105, ROUGE-2: 0.0000, BLEU: 0.1501, METEOR: 0.3087\n",
      "✅ 54/100 질문 완료: '서진달'의 '교복을 입은 남학생'에 대해 설명해주세요. -> SemScore: 0.8395, ROUGE-1: 0.4000, ROUGE-2: 0.1538, BLEU: 0.2858, METEOR: 0.6673\n",
      "✅ 55/100 질문 완료: '이병규'의 '황국'에 대해 설명해주세요. -> SemScore: 0.7476, ROUGE-1: 0.2500, ROUGE-2: 0.0000, BLEU: 0.1511, METEOR: 0.2790\n",
      "✅ 56/100 질문 완료: '정상화'의 '무제'에 대해 설명해주세요. -> SemScore: 0.7119, ROUGE-1: 0.4211, ROUGE-2: 0.2353, BLEU: 0.2394, METEOR: 0.3702\n",
      "✅ 57/100 질문 완료: '이상일'의 '구망월동'에 대해 설명해주세요. -> SemScore: 0.7300, ROUGE-1: 0.2500, ROUGE-2: 0.0667, BLEU: 0.1567, METEOR: 0.3942\n",
      "✅ 58/100 질문 완료: '이항성'의 '해념(海念)'에 대해 설명해주세요. -> SemScore: 0.6887, ROUGE-1: 0.1379, ROUGE-2: 0.0000, BLEU: 0.1586, METEOR: 0.2396\n",
      "✅ 59/100 질문 완료: '김정숙 a'의 '애인들'에 대해 설명해주세요. -> SemScore: 0.6906, ROUGE-1: 0.2353, ROUGE-2: 0.0000, BLEU: 0.1665, METEOR: 0.4846\n",
      "✅ 60/100 질문 완료: '문신'의 '무제'에 대해 설명해주세요. -> SemScore: 0.5654, ROUGE-1: 0.0526, ROUGE-2: 0.0000, BLEU: 0.0794, METEOR: 0.2673\n",
      "✅ 61/100 질문 완료: '이브 브라이에'의 '루르마랭'에 대해 설명해주세요. -> SemScore: 0.4964, ROUGE-1: 0.1765, ROUGE-2: 0.0625, BLEU: 0.0934, METEOR: 0.2128\n",
      "✅ 62/100 질문 완료: '김태숙'의 '승마'에 대해 설명해주세요. -> SemScore: 0.7253, ROUGE-1: 0.3077, ROUGE-2: 0.0000, BLEU: 0.1443, METEOR: 0.4995\n",
      "✅ 63/100 질문 완료: '일리아 카바코프'의 '사과'에 대해 설명해주세요. -> SemScore: 0.6850, ROUGE-1: 0.2051, ROUGE-2: 0.1081, BLEU: 0.1041, METEOR: 0.2727\n",
      "✅ 64/100 질문 완료: '송수남'의 '붓의 놀림'에 대해 설명해주세요. -> SemScore: 0.0891, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0000, METEOR: 0.0000\n",
      "✅ 65/100 질문 완료: '김근중'의 '귀장연작-원 생명을 위한 의식'에 대해 설명해주세요. -> SemScore: 0.6876, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.1592, METEOR: 0.3818\n",
      "✅ 66/100 질문 완료: '김영수'의 '떠도는 섬(소래)'에 대해 설명해주세요. -> SemScore: 0.8432, ROUGE-1: 0.6667, ROUGE-2: 0.5000, BLEU: 0.2505, METEOR: 0.4589\n",
      "✅ 67/100 질문 완료: '오광섭'의 '작품'에 대해 설명해주세요. -> SemScore: 0.5929, ROUGE-1: 0.1000, ROUGE-2: 0.0000, BLEU: 0.1267, METEOR: 0.3535\n",
      "✅ 68/100 질문 완료: '황영성'의 '가족이야기'에 대해 설명해주세요. -> SemScore: 0.5827, ROUGE-1: 0.2222, ROUGE-2: 0.0000, BLEU: 0.0006, METEOR: 0.0074\n",
      "✅ 69/100 질문 완료: '장상의'의 '백두산 신곡'에 대해 설명해주세요. -> SemScore: 0.6500, ROUGE-1: 0.1538, ROUGE-2: 0.0000, BLEU: 0.1570, METEOR: 0.3507\n",
      "✅ 70/100 질문 완료: '변관식'의 '드로잉'에 대해 설명해주세요. -> SemScore: 0.6280, ROUGE-1: 0.0541, ROUGE-2: 0.0000, BLEU: 0.1914, METEOR: 0.3507\n",
      "✅ 71/100 질문 완료: '신미경'의 '유령 시리즈(자색)'에 대해 설명해주세요. -> SemScore: 0.7165, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0923, METEOR: 0.3740\n",
      "✅ 72/100 질문 완료: '전뢰진'의 '누나와 동생'에 대해 설명해주세요. -> SemScore: 0.7186, ROUGE-1: 0.1250, ROUGE-2: 0.0000, BLEU: 0.1078, METEOR: 0.2926\n",
      "✅ 73/100 질문 완료: '황용엽'의 '옛 이야기'에 대해 설명해주세요. -> SemScore: 0.7619, ROUGE-1: 0.2222, ROUGE-2: 0.0000, BLEU: 0.1110, METEOR: 0.2287\n",
      "✅ 74/100 질문 완료: '노수현'의 '송청(送靑)'에 대해 설명해주세요. -> SemScore: 0.5792, ROUGE-1: 0.0769, ROUGE-2: 0.0000, BLEU: 0.2030, METEOR: 0.3117\n",
      "✅ 75/100 질문 완료: '이대원 a'의 '복숭아 밭'에 대해 설명해주세요. -> SemScore: 0.7418, ROUGE-1: 0.0870, ROUGE-2: 0.0000, BLEU: 0.2557, METEOR: 0.3736\n",
      "✅ 76/100 질문 완료: '유영국'의 '작품002'에 대해 설명해주세요. -> SemScore: 0.5147, ROUGE-1: 0.1277, ROUGE-2: 0.0444, BLEU: 0.1425, METEOR: 0.2510\n",
      "✅ 77/100 질문 완료: '에도 무르티치'의 '어두운 하늘'에 대해 설명해주세요. -> SemScore: 0.4335, ROUGE-1: 0.3333, ROUGE-2: 0.1250, BLEU: 0.1885, METEOR: 0.3881\n",
      "✅ 78/100 질문 완료: '이인화'의 '열려진 공간으로의 여행-9166'에 대해 설명해주세요. -> SemScore: 0.6881, ROUGE-1: 0.2727, ROUGE-2: 0.1000, BLEU: 0.3187, METEOR: 0.5116\n",
      "✅ 79/100 질문 완료: '홍경택'의 '모놀로그'에 대해 설명해주세요. -> SemScore: 0.5051, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.1433, METEOR: 0.2787\n",
      "✅ 80/100 질문 완료: '김영주'의 '드로잉'에 대해 설명해주세요. -> SemScore: 0.6674, ROUGE-1: 0.1702, ROUGE-2: 0.0889, BLEU: 0.1335, METEOR: 0.3425\n",
      "✅ 81/100 질문 완료: '모한드 아마라'의 '무제'에 대해 설명해주세요. -> SemScore: 0.7371, ROUGE-1: 0.4286, ROUGE-2: 0.1667, BLEU: 0.1361, METEOR: 0.3921\n",
      "✅ 82/100 질문 완료: '유영국'의 '작품005'에 대해 설명해주세요. -> SemScore: 0.5527, ROUGE-1: 0.2041, ROUGE-2: 0.0851, BLEU: 0.1670, METEOR: 0.2956\n",
      "✅ 83/100 질문 완료: '하동철'의 '환원Ⅱ'에 대해 설명해주세요. -> SemScore: 0.6475, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.2023, METEOR: 0.4432\n",
      "✅ 84/100 질문 완료: '김성환'의 '6.25스케치 1950년 6월 28일 돈암동 종점의 국군병사의 사체'에 대해 설명해주세요. -> SemScore: 0.7318, ROUGE-1: 0.4231, ROUGE-2: 0.0800, BLEU: 0.0621, METEOR: 0.2074\n",
      "✅ 85/100 질문 완료: '여태명'의 '천,지,인'에 대해 설명해주세요. -> SemScore: 0.7859, ROUGE-1: 0.1538, ROUGE-2: 0.0000, BLEU: 0.1074, METEOR: 0.3567\n",
      "✅ 86/100 질문 완료: '이규선'의 '최치원 영정'에 대해 설명해주세요. -> SemScore: 0.7664, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.1169, METEOR: 0.4045\n",
      "✅ 87/100 질문 완료: '이종우'의 '누드(여)'에 대해 설명해주세요. -> SemScore: 0.7201, ROUGE-1: 0.1250, ROUGE-2: 0.0000, BLEU: 0.1482, METEOR: 0.3582\n",
      "✅ 88/100 질문 완료: '마우로 스타치올리'의 '무제'에 대해 설명해주세요. -> SemScore: 0.7704, ROUGE-1: 0.4444, ROUGE-2: 0.3750, BLEU: 0.0512, METEOR: 0.3029\n",
      "✅ 89/100 질문 완료: '임응식'의 '김환기 인물'에 대해 설명해주세요. -> SemScore: 0.6544, ROUGE-1: 0.3077, ROUGE-2: 0.2500, BLEU: 0.1274, METEOR: 0.2593\n",
      "✅ 90/100 질문 완료: '유영국'의 '새벽'에 대해 설명해주세요. -> SemScore: 0.5969, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0601, METEOR: 0.1767\n",
      "✅ 91/100 질문 완료: '이희중'의 '수 16'에 대해 설명해주세요. -> SemScore: 0.4390, ROUGE-1: 0.2500, ROUGE-2: 0.0000, BLEU: 0.1705, METEOR: 0.5002\n",
      "✅ 92/100 질문 완료: '장두건'의 '정물(장미꽃)'에 대해 설명해주세요. -> SemScore: 0.7126, ROUGE-1: 0.1333, ROUGE-2: 0.0000, BLEU: 0.1975, METEOR: 0.4737\n",
      "✅ 93/100 질문 완료: '최영림'의 '여인'에 대해 설명해주세요. -> SemScore: 0.6196, ROUGE-1: 0.2222, ROUGE-2: 0.1250, BLEU: 0.1754, METEOR: 0.2665\n",
      "✅ 94/100 질문 완료: '서정태'의 '연인'에 대해 설명해주세요. -> SemScore: 0.6330, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.2214, METEOR: 0.3758\n",
      "✅ 95/100 질문 완료: '최미아'의 '구조장비'에 대해 설명해주세요. -> SemScore: 0.7523, ROUGE-1: 0.4000, ROUGE-2: 0.1538, BLEU: 0.1310, METEOR: 0.4485\n",
      "✅ 96/100 질문 완료: '육명심'의 '예술가의 초상 시리즈 - 이외수'에 대해 설명해주세요. -> SemScore: 0.6515, ROUGE-1: 0.2857, ROUGE-2: 0.1538, BLEU: 0.2212, METEOR: 0.2768\n",
      "✅ 97/100 질문 완료: '신학철'의 '하늘소'에 대해 설명해주세요. -> SemScore: 0.6379, ROUGE-1: 0.3200, ROUGE-2: 0.0870, BLEU: 0.2378, METEOR: 0.4051\n",
      "✅ 98/100 질문 완료: '박수근'의 '유동(遊童)'에 대해 설명해주세요. -> SemScore: 0.5386, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.2200, METEOR: 0.2822\n",
      "✅ 99/100 질문 완료: '한기석'의 '초서 항아리'에 대해 설명해주세요. -> SemScore: 0.7786, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0832, METEOR: 0.4005\n",
      "✅ 100/100 질문 완료: '송수남'의 '가나다라'에 대해 설명해주세요. -> SemScore: 0.0711, ROUGE-1: 0.0000, ROUGE-2: 0.0000, BLEU: 0.0000, METEOR: 0.0000\n",
      "✅ 평가 완료! 결과가 'dataset_csv/evaluation_results_description_0206.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate import meteor_score\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "\n",
    "# ✅ 모델 및 토크나이저 초기화\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# ✅ JSON 파일 로드\n",
    "json_file_path = \"qa_dataset_description.json\"  # JSON 파일 경로\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "# ✅ JSON 데이터를 DataFrame으로 변환\n",
    "qa_pairs = []\n",
    "for item in qa_data:\n",
    "    text_parts = item[\"text\"].split(\"### Instruction:\\n\")  # 질문 추출\n",
    "    if len(text_parts) > 1:\n",
    "        question_part = text_parts[1].split(\"\\n\\n### Input:\\n\\n\\n\")[0]  # 질문\n",
    "        answer_part = text_parts[1].split(\"### Response:\\n\")[1].replace(\"<|endoftext|>\", \"\").strip()  # 정답\n",
    "        qa_pairs.append({\"question\": question_part, \"ground_truth\": answer_part})\n",
    "\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# ✅ 평가 진행\n",
    "results = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    question = str(row[\"question\"].strip())\n",
    "    ground_truth = str(row[\"ground_truth\"]).strip()\n",
    "\n",
    "    # ✅ RAG 모델을 이용해 답변 생성\n",
    "    model_answer = ask_question({\"question\": question})\n",
    "    model_text = model_answer[\"answer\"]  # ✅ 중요!\n",
    "\n",
    "    # ✅ SemScore 계산\n",
    "    ground_embedding = model.encode(ground_truth, convert_to_tensor=True)\n",
    "    model_embedding = model.encode(model_text, convert_to_tensor=True)\n",
    "    sem_score = util.pytorch_cos_sim(model_embedding, ground_embedding).item()\n",
    "\n",
    "    # ✅ ROUGE 점수 계산 (ROUGE-L 제거)\n",
    "    rouge = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"], use_stemmer=True)\n",
    "    rouge_scores = rouge.score(ground_truth, model_text)\n",
    "    rouge1 = rouge_scores[\"rouge1\"].fmeasure\n",
    "    rouge2 = rouge_scores[\"rouge2\"].fmeasure\n",
    "\n",
    "    # ✅ BLEU 점수 계산 (Smoothing 추가)\n",
    "    reference_tokens = [token.form for token in kiwi.tokenize(ground_truth)]\n",
    "    student_tokens = [token.form for token in kiwi.tokenize(model_text)]\n",
    "    smoothing = SmoothingFunction().method1  # BLEU 스무딩 적용\n",
    "    bleu_score = sentence_bleu([reference_tokens], student_tokens, smoothing_function=smoothing)\n",
    "\n",
    "    # ✅ METEOR 점수 계산\n",
    "    meteor = meteor_score.meteor_score([reference_tokens], student_tokens)\n",
    "\n",
    "    # ✅ 결과 저장\n",
    "    results.append([i + 1, question, model_text, ground_truth, rouge1, rouge2, bleu_score, meteor, sem_score])\n",
    "\n",
    "    print(f\"✅ {i+1}/{len(df)} 질문 완료: {question} -> SemScore: {sem_score:.4f}, ROUGE-1: {rouge1:.4f}, ROUGE-2: {rouge2:.4f}, BLEU: {bleu_score:.4f}, METEOR: {meteor:.4f}\")\n",
    "\n",
    "# ✅ CSV 저장\n",
    "csv_output = \"dataset_csv/evaluation_results_description_0206.csv\"\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    \"Index\", \"Question\", \"RAG Answer\", \"Ground Truth\",\n",
    "    \"ROUGE-1\", \"ROUGE-2\", \"BLEU\", \"METEOR\", \"SemScore\"\n",
    "])\n",
    "df_results.to_csv(csv_output, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ 평가 완료! 결과가 '{csv_output}' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
