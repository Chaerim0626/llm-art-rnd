{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e06783-f083-424c-9ace-51f3c3bf5e00",
   "metadata": {},
   "source": [
    "### 1. 패키지 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d49d96-9721-43a6-8482-9158d25c93fe",
   "metadata": {},
   "source": [
    "### 2. 문서 split 및 Chroma를 활용한 vector store 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d82f23-0f73-4879-8a69-46d5237a47b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chae/faiss_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로그인 상태입니다. 사용자: chaeeee\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(f\"로그인 상태입니다. 사용자: {user_info['name']}\")\n",
    "except Exception as e:\n",
    "    print(\"로그인되지 않았거나 토큰이 유효하지 않습니다.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c477cb-437e-4c75-b35d-f42641901204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_text 개수:  8042447\n",
      "총 문서 수: 15195\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 텍스트 분할 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=128  # 오버랩 설정\n",
    ")\n",
    "\n",
    "# 단일 DOCX 파일 로드\n",
    "file_path = \"./dataset2.docx\"  # 파일 경로를 이곳에 입력하세요\n",
    "loader = Docx2txtLoader(file_path)\n",
    "raw_text = loader.load()[0].page_content  # DOCX 파일의 전체 텍스트 가져오기\n",
    "print(\"raw_text 개수: \", len(raw_text))\n",
    "      \n",
    "# 작품명을 기준으로 텍스트 분리\n",
    "def split_artwork_documents(doc_text):\n",
    "    artworks = doc_text.split(\"\\n\\n작품명:\")  # 작품을 구분\n",
    "    documents = []\n",
    "\n",
    "    for artwork in artworks:\n",
    "        if artwork.strip():  # 빈 텍스트 제외\n",
    "            # \"작품명:\" 추가로 일관성 유지\n",
    "            doc_content = \"작품명:\" + artwork if not artwork.startswith(\"작품명:\") else artwork\n",
    "\n",
    "            # 메타데이터 초기화\n",
    "            metadata = {}\n",
    "            lines = doc_content.split(\"\\n\")  # 텍스트 줄 단위로 나누기\n",
    "\n",
    "            # 메타데이터 추출\n",
    "            for line in lines:\n",
    "                if line.startswith(\"작품명:\"):\n",
    "                    metadata[\"작품명\"] = line.replace(\"작품명:\", \"\").strip()\n",
    "                elif line.startswith(\"작가:\"):\n",
    "                    metadata[\"작가\"] = line.replace(\"작가:\", \"\").strip()\n",
    "                elif line.startswith(\"제작 연도:\"):\n",
    "                    metadata[\"제작 연도\"] = line.replace(\"제작 연도:\", \"\").strip()\n",
    "                elif line.startswith(\"카테고리:\"):\n",
    "                    metadata[\"카테고리\"] = line.replace(\"카테고리:\", \"\").strip()\n",
    "\n",
    "            # Document 객체 생성\n",
    "            documents.append(Document(\n",
    "                page_content=doc_content.strip(),\n",
    "                metadata=metadata\n",
    "            ))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "\n",
    "# 작품별 Document 생성\n",
    "documents = split_artwork_documents(raw_text)\n",
    "\n",
    "# 생성된 작품별 Document에 대해 추가 청크 분할\n",
    "chunked_documents = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    for chunk in chunks:\n",
    "        # 청크에 원래 Document의 메타데이터 유지\n",
    "        chunked_documents.append(Document(\n",
    "            page_content=chunk,\n",
    "            metadata=doc.metadata  # 원본 메타데이터 복사\n",
    "        ))\n",
    "\n",
    "print(f\"총 문서 수: {len(chunked_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43fe4e47-d1ac-4d3f-8609-7f6a7c0c6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "메타데이터: {'작품명': '작가사진 / 作家寫眞 / Selfportrait', '작가': '한기석 / HAN Kisuk', '제작 연도': '1960', '카테고리': '사진'}\n",
      "작품명: 작가사진 / 作家寫眞 / Selfportrait\n",
      "\n",
      "작가: 한기석 / HAN Kisuk\n",
      "\n",
      "작품 번호: 1\n",
      "\n",
      "제작 연도: 1960\n",
      "\n",
      "크기: 41×51\n",
      "\n",
      "재료: 종이에 젤라틴실버프린트\n",
      "\n",
      "카테고리: 사진\n",
      "\n",
      "작품 설명: ‘농(Nong)’이라는 이름으로 미국에서 널리 알려진 한농(韓農) 한기석(1930-2011)은 국내 활동이 그리 많지 않아서 한국 화단에서는 생소한 이름이다. 그가 최초로 한국 화단에 등장한 것은 1971년 11월 신세계 화랑에서 개최한《Nong 展》이후이다. 그는 농(Nong)을 구름 위의 시선(詩仙) 혹은 주선(酒仙)같은 존재로 비유해서 미국에서 자신의 이름으로 쓰고 있다.그의 작품은 전반적으로 자신의 철학적 이미지를 조형화시킨 추상 회화 계통이다. 일종의 형이상학적인 회화 혹은 초현실적인 환상세계라고도 할 수 있는 그의 작품은 양식적인 면에서 주로 구상적인 형태를 취한다.한기석의 <작가사진>(1960)은 본인의 얼굴을 찍은 것으로, 사진 속에서 작가는 자신의 작품을 배경으로 화면의 우측을 주시하고 있다.\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "메타데이터: {'작품명': '팔괘호 / 八卦壺 / Palgwae Vase', '작가': '한기석 / HAN Kisuk', '제작 연도': '1960', '카테고리': '회화 II'}\n",
      "작품명: 팔괘호 / 八卦壺 / Palgwae Vase\n",
      "\n",
      "작가: 한기석 / HAN Kisuk\n",
      "\n",
      "작품 번호: 2\n",
      "\n",
      "제작 연도: 1960\n",
      "\n",
      "크기: 250×127\n",
      "\n",
      "재료: 캔버스, 종이에 유화 물감\n",
      "\n",
      "카테고리: 회화 II\n",
      "\n",
      "작품 설명: 한농(韓農) 한기석(1930-2011)은 표면 묘사에 많은 관심을 가진 작가이다.그는 모나고 약간 무게가 있는 듯이 보이는 항아리와 화병을 계속 그렸는데, 항아리에 대한 사람들의 일반적 향수 이미지는 그의 작품에서 친근감을 불어넣어 준다. 또한 완벽한 균형을 이루면서 노련하게 표현되어 다양한 색의 조화를 지닌 도자기의 미를 느낄 수 있다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 첫 2개 문서만 출력해 확인\n",
    "for i, doc in enumerate(chunked_documents[:2], 1):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(\"메타데이터:\", doc.metadata)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4ddbe99-f6c8-4580-92b6-503253277965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'작품명': '직각 / N/A / Right Angle', '작가': '김차섭 / KIM Tchahsup', '제작 연도': '1981', '카테고리': '판화'}, page_content='작품명: 직각 / N/A / Right Angle\\n\\n작가: 김차섭 / KIM Tchahsup\\n\\n작품 번호: 11001\\n\\n제작 연도: 1981\\n\\n크기: 57×76.5\\n\\n재료: 종이에 에칭\\n\\n카테고리: 판화\\n\\n작품 설명: 김차섭(金次燮, 1942-2022)은 일본 야마구치현(山口県)에서 태어났으며, 광복 즈음에 한국으로 건너와 1963년 서울대학교 회화과에 입학했다. 1960년대 후반에 《회화 ‘68》전과 《AG》전에 참여했으며, 1967년 제5회 파리비엔날레, 1970년 제7회 도쿄 국제판화비엔날레, 1971년 제11회 상파울루비엔날레 등에 참가하며 국제적으로도 활발히 활동하였다. 김차섭은 록펠러 재단 장학금을 받고 1975년에 미국으로 건너가서 뉴욕 프랫 인스티튜트(Pratt Institute) 대학원에서 에칭을 공부했다. 1990년에 귀국한 후 춘천의 한 폐교에 작업실을 마련하여 뉴욕과 한국을 오가며 작업했다. 작가는 1975년에 포드 재단 프랫 인스티튜트 스튜디오 미술상을 받고, 2002년 제14회 이중섭미술상, 2008년 제9회 이인성미술상 등을 수상했다. 김차섭은 1970년대까지 스크린 판화를 다수 제작했으나, 미국으로 건너간 후에는 에칭 기법을 활용한 판화작업을 했다. 김차섭의 에칭 판화는 기법뿐 아니라 작가가 그 당시 추구했던 기하학적 개념을 처음으로 시도한 것이었다.<직각>은 김차섭이 1976년 미국으로 가기 전부터 부단히 고민했던 ‘삼각형’에 대한 관념이 드러나 있다. 삼각형의 한 꼭짓점이 뚫려 있고 이를 가리키는 듯이 제스쳐를 한 손이 그려져 있으며, 열려 있는 직각 부분을 손 뒤의 예리한 각이 짚고 있다. 긴장감 있으면서 완벽한 도형으로 인식되는 삼각형의 직각 부분을 뚫은 것은 서구 합리주의에 대한 도전이자 뉴욕에서 작업하는 한국 작가로서 자신의 정체성에 대한 해답으로 볼 수 있다. 김차섭은 이에 대해 “삼각형의 직각 꼭짓점을 뚫는 데 2년이 걸렸고 뚫고 나니 속이 후련하더라”고 말하였다.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[11000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c102d292-48e8-4eeb-9280-79dc003ed796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 Document 객체의 텍스트 길이 확인\n",
    "len(documents[11000].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcec14a4-2333-4381-8152-dc30d011ba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800자를 초과하는 Document 개수: 4166\n"
     ]
    }
   ],
   "source": [
    "# 800자를 초과하는 Document 개수 세기\n",
    "over_800_count = sum(1 for doc in documents if len(doc.page_content) > 800)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"800자를 초과하는 Document 개수: {over_800_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1ef186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss  # FAISS 라이브러리 필요\n",
    "\n",
    "# 1. 임베딩 초기화\n",
    "embedding_model = SentenceTransformer(\"nlpai-lab/KURE-v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce036d50",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m chunked_documents]  \u001b[38;5;66;03m# 문서 메타데이터\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 3. 문서 임베딩 생성\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:652\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m--> 652\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[1;32m    656\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2. 문서 데이터와 메타데이터 분리\n",
    "texts = [doc.page_content for doc in chunked_documents]  # 문서 텍스트\n",
    "metadatas = [doc.metadata for doc in chunked_documents]  # 문서 메타데이터\n",
    "\n",
    "# 3. 문서 임베딩 생성\n",
    "embeddings = embedding_model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23144ef3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 4. FAISS 인덱스 생성\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# 벡터 차원 확인\u001b[39;00m\n\u001b[1;32m      3\u001b[0m faiss_index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatL2(embedding_dim)  \u001b[38;5;66;03m# L2 거리 기반 인덱스\u001b[39;00m\n\u001b[1;32m      4\u001b[0m faiss_index\u001b[38;5;241m.\u001b[39madd(embeddings)  \u001b[38;5;66;03m# 벡터 추가\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. FAISS 인덱스 생성\n",
    "embedding_dim = embeddings.shape[1]  # 벡터 차원 확인\n",
    "faiss_index = faiss.IndexFlatL2(embedding_dim)  # L2 거리 기반 인덱스\n",
    "faiss_index.add(embeddings)  # 벡터 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba322337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# 5. Docstore 생성\n",
    "# 각 문서에 고유 ID를 부여해 InMemoryDocstore 생성\n",
    "docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(chunked_documents)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbd078ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 데이터베이스가 성공적으로 저장되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# 6. FAISS 벡터스토어 생성\n",
    "def embed_query(text):\n",
    "    return embedding_model.encode([text])[0]  # 단일 쿼리 텍스트를 임베딩\n",
    "\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(chunked_documents))}\n",
    "\n",
    "faiss_db = FAISS(\n",
    "    embedding_function=embed_query,\n",
    "    index=faiss_index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "# 7. FAISS 데이터베이스 저장\n",
    "faiss_db.save_local(\"./faiss_artworks\")\n",
    "print(\"FAISS 데이터베이스가 성공적으로 저장되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c40e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 텍스트: 작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈아이들〉은 수많은 아이들의 신체가 서로 포개어져 있거나 뒤엉켜 있는 모습을 담은 은지화이다. 신체의 구획을 명확히 헤아리기 어려울 정도로 복잡한 구성을 보인다. 아이들은 은근한 미소를 띠고 있으며, 역동적인 자세를 취하고 있는 이들은 마치 친구들과 장난을 치고 있는 듯 신나 보이기도 한다. 이중섭의 작품에서 아이들은 핵심적인 소재이다. 그러나 많은 경우 아이들은 물고기, 게 등 여러 동물과 혹은 식물과 어울리는 모습으로 자주 등장한다는 점에서, 이 작품과 같이 아이들만 등장하는 경우는 그의 작품 전반에서 상대적으로 많지 않은 편이다.\n",
      "문서 메타데이터: {'작품명': '아이들 / N/A / Children', '작가': '이중섭 / LEE Jungseop', '제작 연도': '1950', '카테고리': '회화 II'}\n",
      "문서 텍스트: 작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈다섯 아이들〉은 다섯 명의 아이들이 서로 함께 어울리고 있는 모습을 담은 작품이다. 그들은 특정한 행동 없이 그저 은근한 미소를 얼굴에 띄우며 서로의 신체를 맞닿아 연결되어 화면 전체를 채우고 있다. 화면 하단 좌측에 더 작은 크기로 희미하게 새겨져 있는 다른 인체 형상을 발견할 수 있기도 하다. 이중섭의 작품에서 아이들은 핵심적인 소재이다. 그의 작품들에서 아이들은 장난을 치기도 하고 물고기, 게 등 여러 동물과 혹은 식물과 어울리는 모습으로 자주 등장한다.\n",
      "문서 메타데이터: {'작품명': '다섯 아이들 / N/A / Five Children', '작가': '이중섭 / LEE Jungseop', '제작 연도': '1950', '카테고리': '회화 II'}\n",
      "문서 텍스트: 작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈다섯 아이들〉은 눈을 감고 있는 다섯 명의 나체를 은지에 선묘로 그린 작품이다. 이 작품에는 다섯 얼굴이 등장하지만, 어떤 아이들은 다리를 두 쌍씩 가지고 있다. 움직임의 표현으로 읽히기도 하고 아이들의 신체를 이리저리 배치하는 조형 실험의 과정으로 이해될 수도 있다. 아이들의 자세는 자연스럽다기보다 익살스럽게 꺾여 있고, 겹쳐진 선들은 한층 리듬감 있게 화면을 구성한다. 이중섭은 입술과 눈매의 각도를 미세하게 조정함으로써 아이들에게 각자 다른 인상을 부여해 다채로운 이야기를 암시하고 있다.\n",
      "문서 메타데이터: {'작품명': '다섯 아이들 / N/A / Five Children', '작가': '이중섭 / LEE Jungseop', '제작 연도': '1950', '카테고리': '회화 II'}\n",
      "문서 텍스트: 작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈네 아이들〉은 천진무구한 소년들의 모습을 담아낸 이중섭의 은지화 작품이다. 단순한 선으로만 표현된 머리카락 없는 둥근 얼굴형과 비슷한 표정의 네 아이가 서로 손과 발을 맞대고, 혹은 겹쳐진 모습으로 뒤엉켜 있다. 작품에 익살스러운 분위기를 더하는 이들의다채로운 자세는 다소 왜곡된 듯 보이기도 하지만, 한편으로는 네 아이를 잇는 자연스러운 선의 흐름을 가능케 한다. 이중섭은 사람과 동물이 서로 원형을 이루거나 이어지고 겹쳐진 모습, 혹은 끈으로 이어진 듯한 모습을 자주 그렸는데, 여기에는 그의 평화로운 시대에 대한 갈망, 인연에 대한 믿음 등이 담겨 있다.\n",
      "문서 메타데이터: {'작품명': '네 아이들 / N/A / Four Children', '작가': '이중섭 / LEE Jungseop', '제작 연도': '1950', '카테고리': '회화 II'}\n",
      "문서 텍스트: 작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 근대기의 대표적 화가로 대중적으로 가장 많이 알려진 화가 중 한 사람이기도 하다. 특히, 그의 ‘은지화’는 독창적인 작품으로 많은 사람들에게 사랑받고 있다. 또한, 이중섭은 그의 무구한 천성과 작가적 정신으로 많은 일화를 남긴 작가이며 소, 닭, 물고기, 동자, 달구지 등의 향토적인 소재와 자신과 처자를 상징하는 가족도 등의 자전적인 주제를 많이 다루었다.<애들과 물고기와 게>는 두 명의 남자 아이가 물고기와 게를 가지고 노는 작품으로,  한국 근대 미술의 가장 대표적인 작가라 일컬어지는 이중섭의 군동화(群童畵) 중 하나이다. '물고기, 게와 노는 아이들'은 이중섭이 가장 즐겨 그린 화제(畵題)로 최근까지 세 작품이 확인되고 있다. 이 작품에서 이중섭은 농밀한 색채와 간결한 데생 그리고 담채(淡彩)의 기법을 통하여 해맑고 천진난만한 동심의 세계를 가감없이 그려내고 있다. 그는 윤곽선을 그리고 색채를 가해 그림을 완성한 후 그 위에 다시 회색 물감을 부분적으로 뒤덮는 방식을 통해, 화면 전체에 희뿌연 느낌을 부가한 것이다. 아이들은 그저 해맑은 표정으로 물고기와 게와 어우러져 있는데, 이들은 끈을 통해서 서로 이어져 있을 뿐 아니라, 서로서로 신체의 일부를 접촉하면서 완전히 연결되어 있다. 아이의 성기를 희롱하는 게의 집게발, 물고기의 꼬리를 만지는 아이의 손가락, 한 아이의 발바닥을 간질이는 다른 아이의 손동작을 주목해 보라. 매우 감각적이고 촉각적인 자극을 유발하면서, 이들은 하나로 어우러진 이상적 ‘연결고리’를 형성하고 있다.\n",
      "문서 메타데이터: {'작품명': '애들과 물고기와 게 / N/A / Children and Fish and Crab', '작가': '이중섭 / LEE Jungseop', '제작 연도': '1950', '카테고리': '회화 II'}\n"
     ]
    }
   ],
   "source": [
    "# 9. 검색 테스트\n",
    "query = \"이중섭 작품의 특징\"\n",
    "results = faiss_db.similarity_search(query, k=5)\n",
    "\n",
    "# 10. 검색 결과 출력\n",
    "for result in results:\n",
    "    print(\"문서 텍스트:\", result.page_content)\n",
    "    print(\"문서 메타데이터:\", result.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6a00995-3f64-49d2-8b0f-033e8b640085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 데이터베이스가 성공적으로 로드되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# 2. FAISS 데이터베이스 로드\n",
    "persist_directory = \"./faiss_artworks\"\n",
    "\n",
    "try:\n",
    "    faiss_db = FAISS.load_local(\n",
    "        folder_path=persist_directory,\n",
    "        embeddings=embedding_model,\n",
    "        allow_dangerous_deserialization=True  # 신뢰할 수 있는 소스에서만 사용\n",
    "    )\n",
    "    \n",
    "    # embedding_function 수정\n",
    "    faiss_db.embedding_function = lambda text: (\n",
    "        embedding_model.encode(text) if isinstance(text, str) else embedding_model.encode(str(text))\n",
    "    )\n",
    "    \n",
    "    print(\"FAISS 데이터베이스가 성공적으로 로드되었습니다!\")\n",
    "except Exception as e:\n",
    "    print(f\"FAISS 데이터베이스 로드 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4607b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40645602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:29<00:00,  4.20s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "\n",
    "# 모델과 토크나이저 로드 (CUDA 사용)\n",
    "model_id = \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"cuda\",  # CUDA에서 자동 배치\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6446fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "/tmp/ipykernel_1188/1315975019.py:15: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 파이프라인 생성\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,  # 생성할 최대 토큰 수 증가\n",
    "    do_sample=True,        # 샘플링 활성화\n",
    "    temperature=0.1,      \n",
    "    top_k=50,             \n",
    "    repetition_penalty=1.05\n",
    ")\n",
    "# LangChain의 HuggingFacePipeline 사용\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "747bc299-6dde-4a89-beeb-0f330ac28baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = '''\n",
    "<|system|>\n",
    "You are a friendly chatbot specializing in artworks. \n",
    "Answer questions strictly based on the information provided in the document (context). \n",
    "If the requested information is not found in the document, respond with \"The document does not contain this information.\" \n",
    "Provide detailed and comprehensive answers, always include the artwork number, and ensure all answers are written in Korean. \n",
    "All answers should be formatted using beautiful Markdown syntax to make the response visually appealing and easy to read. Use headings, bullet points, and bold or italic text where appropriate to enrich the response.\n",
    "\n",
    "<|context|>\n",
    "{context}\n",
    "\n",
    "<|user|>\n",
    "Question: {question}\n",
    "\n",
    "<|assistant|>\n",
    "'''\n",
    "\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "137611cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_db.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                # 검색 결과 개수\n",
    "        \"fetch_k\": 15,         # 더 많은 결과 가져오기\n",
    "        \"mmr\": True,           # MMR 활성화\n",
    "        \"mmr_beta\": 0.5        # 다양성과 관련성 간 균형\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e8023be-86e0-487d-b773-df209eac7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class MarkdownOutputParser:\n",
    "    \"\"\"Enhanced Markdown parser with additional formatting options.\"\"\"\n",
    "\n",
    "    def __call__(self, llm_output):\n",
    "        # <assistant> 이후의 텍스트만 추출\n",
    "        match = re.search(r\"<\\|assistant\\|>\\s*(.*)\", llm_output, re.DOTALL)\n",
    "        if match:\n",
    "            extracted_text = match.group(1).strip()\n",
    "            # 마크다운 코드 블록으로 출력 포맷\n",
    "            return f\"### 모델 결과\\n\\n{extracted_text}\\n\\n\"\n",
    "        else:\n",
    "            # <assistant> 태그가 없는 경우 원래 출력 반환\n",
    "            return f\"### 모델 결과\\n\\n{llm_output.strip()}\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e5af389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough, RunnableMap\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": retriever,               # Retriever에서 반환된 값을 가져옴\n",
    "        \"question\": RunnablePassthrough()   # 질문은 그대로 전달\n",
    "    })\n",
    "    | (lambda x: {\n",
    "        \"context\": \"\\n\".join([doc.page_content for doc in x[\"context\"]]),\n",
    "        \"question\": x[\"question\"]\n",
    "    })  # context를 문자열로 변환\n",
    "    | prompt                               # Prompt Template에 전달\n",
    "    | llm                                  # LLM으로 응답 생성\n",
    "    | MarkdownOutputParser()                    # 응답을 문자열로 변환\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb2b4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"드로잉 작품 5개 추천해줘\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "525b7a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "### 모델 결과\n",
       "\n",
       "## 박미나 작가의 드로잉 작품 5개 추천\n",
       "\n",
       "    <div style=\"background-color: #f0f8ff; padding: 10px; border-radius: 5px;\">\n",
       "        **1. 드로잉 (KA-POW!)**  \n",
       "        * **작품 번호:** 7415   \n",
       "        * **제작 연도:** 2014     \n",
       "        * **재료:** 색칠도안에 연필      \n",
       "        * **설명:** 박미나가 수집한 여러 나라의 색칠 공부 교본 중 '해'를 제외한 부분을 연필로 색칠한 작품입니다. 다양한 연필을 활용하여 각 형상에 담긴 이야기를 표현합니다. <span style=\"color:blue;\">기본적인 재료임에도 불구하고 시대와 장소에 따라 변화하며 인간의 사고 방식을 반영합니다.</span>\n",
       "       \n",
       "       ![드로잉 (KA-POW!)](이미지 링크 삽입 - 실제 이미지 링크 필요) <!-- 이미지 삽입 위치 -->\n",
       "         \n",
       "        ---\n",
       "        **2. 드로잉**  \n",
       "        * **작품 번호:** 7300   \n",
       "        * **제작 연도:** 2013     \n",
       "        * **재료:** 색칠도안에 연필      \n",
       "        * **설명:** 박미나의 '드로잉' 연작 중 하나로, 형태, 주제, 색채 간의 관계를 탐구합니다. 여러 나라의 색칠 공부 교본에서 '해', '달', '별'을 제외한 부분을 연필로 채워넣습니다. <span style=\"color:green;\">기본 미술 도구를 통해 예술적 표현의 깊이를 보여줍니다.</span>\n",
       "          \n",
       "       ![드로잉](이미지 링크 삽입 - 실제 이미지 링크 필요) <!-- 이미지 삽입 위치 -->\n",
       "           \n",
       "        ---\n",
       "        **3. 다섯 어린이**  \n",
       "        * **작품 번호:** 10000   \n",
       "        * **제작 연도:** 1954     \n",
       "        * **재료:** 종이에 유화 물감, 펜      \n",
       "        * **설명:** 이중섭 작가의 작품으로, 어린이들의 순수함과 상상력을 담고 있습니다.  <span style=\"color:orange;\">한국 현대미술 초기의 드로잉 작품으로서 역사적 가치를 지닙니다.</span>\n",
       "            \n",
       "       ![다섯 어린이](이미지 링크 삽입 - 실제 이미지 링크 필요) <!-- 이미지 삽입 위치 -->\n",
       "             \n",
       "        ---\n",
       "        **4. 드로잉 (5)**  \n",
       "        * **작품 번호:** 4122   \n",
       "        * **제작 연도:** 1950     \n",
       "        * **재료:** 종이에 수채 물감, 색연필      \n",
       "        * **설명:** 송영수 작가의 초기 작품으로, 추상조각의 특징을 보여줍니다.  <span style=\"color:purple;\">작가의 실험 정신과 예술적 탐구 과정을 엿볼 수 있습니다.</span>\n",
       "              \n",
       "       ![드로잉 (5)](이미지 링크 삽입 - 실제 이미지 링크 필요) <!-- 이미지 삽입 위치 -->\n",
       "               \n",
       "        ---\n",
       "        **5. 드로잉**  \n",
       "        * **작품 번호:** 7801   \n",
       "        * **제작 연도:** 1976     \n",
       "        * **재료:** 종이에 태운 종이      \n",
       "        * **설명:** 조성묵 작가의 다채로운 드로잉 작품입니다. 다양한 종이 재료를 활용하여 독특한 표현을 시도합니다. <span style=\"color:brown;\">기본적인 재료를 통해 창조적인 표현을 추구합니다.</span>\n",
       "                \n",
       "       ![드로잉](이미지 링크 삽입 - 실제 이미지 링크 필요) <!-- 이미지 삽입 위치 -->\n",
       "                 \n",
       "    </div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, HTML, display\n",
    "\n",
    "response = chain.invoke({\"question\": query})\n",
    "display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c31d4a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieved_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mretrieved_docs\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retrieved_docs' is not defined"
     ]
    }
   ],
   "source": [
    "type(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "501b6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1188/3695306690.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(retrieved_docs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/langchain_core/retrievers.py:409\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_name:\n\u001b[1;32m    408\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_name\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/langchain_core/retrievers.py:266\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    265\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    269\u001b[0m         result,\n\u001b[1;32m    270\u001b[0m     )\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/langchain_core/retrievers.py:259\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/langchain_core/vectorstores/base.py:1083\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs \u001b[38;5;241m|\u001b[39m kwargs\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1083\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1085\u001b[0m     docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[1;32m   1087\u001b[0m             query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[1;32m   1088\u001b[0m         )\n\u001b[1;32m   1089\u001b[0m     )\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:643\u001b[0m, in \u001b[0;36mFAISS.similarity_search\u001b[0;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    625\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    630\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    631\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:515\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score\u001b[0;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    493\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    498\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    499\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \n\u001b[1;32m    501\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score_by_vector(\n\u001b[1;32m    517\u001b[0m         embedding,\n\u001b[1;32m    518\u001b[0m         k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:268\u001b[0m, in \u001b[0;36mFAISS._embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function\u001b[38;5;241m.\u001b[39membed_query(text)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:690\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    689\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/faiss_env/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:389\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     trans_features \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    391\u001b[0m         trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"Content: {doc.page_content}\")  # 문서의 실제 내용\n",
    "    print(f\"Metadata: {doc.metadata}\")    # 메타데이터 (예: 출처, 페이지 등)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b13d46-a624-421e-80bd-f1f041d77b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서 수: 5\n",
      "\n",
      "문서 1:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.6107\n",
      "  전체 내용: 작품 설명: 이중섭(1916-1956)은 1916년 평안남도 평원의 부유한 가문에서 태어나, 정주 오산학교에서 임용련으로부터 미술지도를 받았고, 도쿄 제국미술학교와 문화학원에서 본격적으로 미술을 공부했다. 일제강점기 일본에서 화가 활동을 시작했고, 함경남도 원산으로 돌아온 후 해방을 맞았다. 한국전쟁으로 제주도, 부산 등지에서 피난생활을 했고, 전쟁 직후에는 통영, 서울, 대구 등지를 전전하며 열악한 환경 속에서도 열정적인 작품 활동을 하다가 1956년 만 40세의 나이로 생을 마감했다.이중섭은 1955년부터 극도의 좌절과 정신적인 압박에 시달리기 시작했고, 여러 병원을 전전하다가 1956년 서울의 정릉 골짜기에서 친구인 작가 한묵과 함께 지내고 있었다. 거식증으로 인한 영양실조, 그리고 간염 등으로 인해 매우 황폐한 생활을 하면서도, 일시적으로 상태가 좋아질 때는 여전히 끊임없이 작품을 제작했다.정릉시기 이중섭의 작품은 붉은 색을 포함한 강렬한 색을 거의 쓰지 않는다는 점, 흰 색과 우울한 노란색이 압도적이라는 점, 그리고 연필 위에 ‘크레파스’와 유채물감을 함께 섞어 여전히 기법적 실험을 계속하고 있다는 점을 들 수 있다. <정릉 풍경>(1956)은 1956년 9월 생을 마감하기 전 정릉에 머물렀던 짧은 기간 동안 제작된 작품으로 쓸쓸한 임종을 예견하고 있는 듯, 낮은 위치에서 골짜기의 경사를 올려다보는 불안한 시선을 택하고 있고, 여러 겹의 헝클어진 연필 선 위에 크레파스로 색을 쌓아 올리고, 그 위에 유채로 살짝 덧칠을 가하는 기법을 구사하고 있다. 쓸쓸하고 황량한 작가의 내면세계가 정릉의 흐릿한 풍경 속에 여지없이 녹아든 작품이라고 할 수 있다.\n",
      "\n",
      "문서 2:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.6621\n",
      "  전체 내용: 작품 설명: 이중섭(1916-1956)은 1916년 평안남도 평원의 부유한 가문에서 태어나, 정주 오산학교에서 임용련으로부터 미술지도를 받았고, 도쿄 제국미술학교와 문화학원에서 본격적으로 미술을 공부했다. 일제강점기 일본에서 화가 활동을 시작했고, 함경남도 원산으로 돌아온 후 해방을 맞았다. 한국전쟁으로 제주도, 부산 등지에서 피난생활을 했고, 전쟁 직후에는 통영, 서울, 대구 등지를 전전하며 열악한 환경 속에서도 열정적인 작품 활동을 하다가 1956년 만 40세의 나이로 생을 마감했다.<세 사람>(1943-1945)은 1943년 이중섭이 일본 유학을 마치고 조선으로 귀국하여 원산에 머무를 때 제작된 것이다. 1945년 해방이 되자마자 서울에서 열린 해방기념미술전에 <소년>이라는 작품과 함께 출품하려 했다가 늦게 도착하는 바람에 전시되지는 못했다고 전해진다. 대신 이 작품은 같은 해 인천에서 전시할 기회를 가졌고, 이후 남한에 남게 되어, 현존하는 유일한 이중섭의 원산시기 작품으로 전해진다.엎드리고, 쪼그리고, 드러누운, 각기 다른 자세를 한 세 인물이 화면을 가득 채운다. 이들은 서로 다른 세 명의 인물들인지, 아니면 한 인물의 세 가지 다른 자세를 동시에 한 화면에 담은 것인지 알 수 없다. 다만, 한 가지 분명한 것은 모두 매우 우울한 표정을 띠고 있다는 것이다. 제작 시기(1943-1945년)를 감안할 때, 일제 말기의 암울한 현실을 반영한 작품으로 보인다. 청년들은 꿈을 잃고 아무것도 할 수가 없는 처지에 놓여있다. 두꺼운 종이 바닥에 그리고 또 그린 무수한 연필 자국들은 허무하기 그지없는 현실의 또 다른 반영이다. 그러나 드러누운 소년의 힘찬 왼손과 오른발의 강렬한 선들을 보라. 작가는 저 손을 통해 암담한 현실을 뚫고 나올 강인한 의지를 놓치지 않고 표현하려 했다.\n",
      "\n",
      "문서 3:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.6647\n",
      "  전체 내용: 작품 설명: 이중섭(1916-1956)은 1916년 평안남도 평원의 부유한 가문에서 태어나, 정주 오산학교에서 임용련으로부터 미술지도를 받았고, 도쿄 제국미술학교와 문화학원에서 본격적으로 미술을 공부했다. 일제강점기 일본에서 화가 활동을 시작했고, 함경남도 원산으로 돌아온 후 해방을 맞았다. 한국전쟁으로 제주도, 부산 등지에서 피난생활을 했고, 전쟁 직후에는 통영, 서울, 대구 등지를 전전하며 열악한 환경 속에서도 열정적인 작품 활동을 하다가 1956년 만 40세의 나이로 생을 마감했다.<소년>(1943-1945)은 1943년 이중섭이 일본 유학을 마치고 조선으로 귀국하여 원산에 머무를 때 제작된 것이다. 1945년 해방이 되자마자 서울에서 열린 해방기념미술전에 <세 사람>과 함께 출품하려 했다가 늦게 도착하는 바람에 전시되지는 못했다고 전해진다. 대신 이 작품은 같은 해 인천에서 전시할 기회를 가졌고, 이후 남한에 남게 되어, 현존하는 유일한 이중섭의 원산시기 작품으로 전해진다.통상 <길 위의 소년> 혹은 <소년>으로 이름 붙여진 이 작품에는 한 소년이 웅크린 자세로 길 한편에 쪼그리고 앉아있다. 그 앞에는 잘려나간 그루터기가 외로이 서있고, 화면 왼쪽 뒤에는 이파리 하나 남지 않은 앙상한 나뭇가지가 쓸쓸함을 더한다. 그리고 그 나무 아래로는 정체를 알 수 없는 긴 그림자가 유령처럼 화면을 침범한다. 이 모든 표현은 수없이 반복적으로 그어진 연필 선들로 이루어져 있으며, 매우 가녀린 힘없는 연필선 위로 또 다른 연필선이 끝없이 겹쳐져 완성되었다. 최종적으로는 단호하고 강한, 깊이 새겨진 연필선이 화면을 지배하게 된다. 갈 길을 알 수 없는, 쓸쓸하고 암담한 일제 말기의 현실 상황을 그 어떤 강한 웅변보다 강렬하고 처절하게 표현한 작품이라고 할 수 있다.\n",
      "\n",
      "문서 4:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.6766\n",
      "  전체 내용: 작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈소와 말과 두 남자〉는 이중섭의 엽서화 중 하나로, 여러 번 나누어 그은 단순한 선묘와 일부 옅은 채색의 가미로 형상화된 상상의 풍경이다. 눈 감은 말 위에 거꾸로 올라탄 남자는 소의 얼굴을 두 팔로 감싸 안고 있는데, 소와 남자 모두 감상자의 시선을 의식하는 듯 정면을 응시하고 있다. 화면 왼편에 얼굴과 왼손이 화면에서 생략된 남자는 말의 엉덩이 위에 한 발을 딛고 다른 한발은 하늘로 치켜든 자세를 취하며, 앉아있는 남자의 몸짓과 대구를 이루려는 듯 두 팔을 하늘로 벌리고 있다. 이는 마치 구복적인 춤사위 같은 인상을 자아낸다. 소와 말의 옅은 미소와 연분홍으로 물든 육체는 풍경의 상서로움을 증폭시킨다. 가로 분할된 배경의 윗부분은 옅은 푸른 채색으로 채워진 한편, 형상들이 발 딛고 있는 대지는 채색이 생략된 채 여백을 연출하고 있다. 소박한 필치로 구현된 이상적 풍경을 통해 작가가 지속적으로 염원하던 평화로운 조화의 세계를 짐작해볼 수 있다.\n",
      "\n",
      "문서 5:\n",
      "  파일명: N/A\n",
      "  유사도 점수: 0.6787\n",
      "  전체 내용: 작품 설명: 대향(大鄕) 이중섭(李仲燮, 1916-1956)은 평안북도 정주의 오산고등보통학교에서 서양화가 임용련, 백남순 부부에게 서양화를 배웠다. 이후 1936년 일본으로 건너가 데이코쿠미술학교(帝国美術学校)와 분카학원(文化学院)에서 미술을 전공했다. 추상 미술단체인 ‘자유미술가협회(自由美術家協会)’의 전시회에 지속적으로 출품하였으며, 제7회전(1943)에서는 태양상(太陽賞)을 수상했다. 1943년 귀국 후에는 생활고와 병으로 고생하면서도 꾸준히 작품을 제작했다.이중섭은 소, 아이들 등을 주요 소재로 고분 벽화와 민화 등 전통적이고 토속적인 것에 영감을 받아 표현주의적인 감각으로 작품을 제작했다. 이중섭의 작품에서는 그의 삶을 엿볼 수 있다. 동경의 분카학원에서 야마모토 마사코와 연애하던 시기의 엽서화에는 두 사람의 연인관계를 암시하는 환상적이고 초현실주의적인 이미지를 그렸다. 한국 전쟁기 제주도 피란시절 작품에는 가족과 행복했던 나날들이 소박하게 표현되었으며, 가족을 일본으로 보낸 후에는 삭막한 풍경화와 전쟁의 은유들이 그려졌다. 그는 열악한 경제 상황과 재료 부족에도 끊임없이 새로운 기법과 재료를 실험했는데, 담배를 싼 은지를 활용한 은지화가 대표적인 예이다. 전쟁이 끝난 후에는 가족을 만나려는 생각에 작품 제작에 몰두하여, 당당하고 힘찬 기세가 화면에 나타난다. 그러나 곧 경제적 어려움과 정신질환 등에 시달리며 가족과 재회할 수 있으리라는 희망이 사라졌을 때에는 초점을 잃은 흐릿한 풍경들이 애잔하게 펼쳐졌다.〈줄 타는 사람들〉은 선이 서로 만나거나 중간에 끊기면서 생기는 공간에 다양한 동작의 사람들을 그려 넣은 작품이다. 화면 상단에 줄을 타고 곡예를 하듯 한 발로 균형을 맞추는 사람, 기대어 휴식을 취하는 사람, 아래를 내려 보며 두 팔로 겨우 매달려 있는 사람, 줄을 타고 오르는 사람, 다리를 걸고 놀고 있는 사람 등 다양하게 등장한다. 단순하게 그려졌지만 간략한 명암처리를 통해 모든 동작들이 분명하고 역동적으로 포착되고 있다. 간결한 선 하나가 주어질 때 사람에게 얼마나 많은 상황이 있을 수 있는지 상상하며 연출된 장면으로 읽힌다. 혹은 작가가 선을 그리면서 벼랑 끝에 서 있는 긴장감을 느끼기도 하고 날아갈 듯 산뜻함을 경험하듯, 이중섭이 작가로서 갖는 환희와 고민을 그려낸 듯 보이기도 한다.\n"
     ]
    }
   ],
   "source": [
    "# 검색 수행: 유사도 점수와 함께 반환\n",
    "docs_and_scores = retriever.vectorstore.similarity_search_with_score(query, k=5)\n",
    "\n",
    "# 검색된 문서 수 출력\n",
    "print(f\"검색된 문서 수: {len(docs_and_scores)}\")\n",
    "\n",
    "# 각 문서의 파일명, 전체 내용, 유사도 점수 출력\n",
    "for i, (doc, score) in enumerate(docs_and_scores, 1):\n",
    "    print(f\"\\n문서 {i}:\")\n",
    "    print(f\"  파일명: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(f\"  유사도 점수: {score:.4f}\")\n",
    "    print(f\"  전체 내용: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "925d43fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터베이스에 저장된 파일 목록:\n",
      "./dataset2.docx\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 임베딩 모델 로드\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Chroma 데이터베이스 불러오기 (임베딩 함수 포함)\n",
    "persist_directory = './chroma_1104'\n",
    "collection_name = 'chroma_art'\n",
    "\n",
    "database = Chroma(\n",
    "    embedding_function=embeddings,  # 임베딩 함수 설정\n",
    "    collection_name=collection_name,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# 모든 문서 검색을 위한 retriever 생성\n",
    "retriever = database.as_retriever(search_kwargs={\"k\": 1000})\n",
    "\n",
    "# 문서 검색 수행 (빈 쿼리 사용)\n",
    "all_docs = retriever.get_relevant_documents(\" \")\n",
    "\n",
    "# 파일 소스 목록 출력\n",
    "file_sources = set(doc.metadata['source'] for doc in all_docs)  # 중복 제거\n",
    "\n",
    "print(\"데이터베이스에 저장된 파일 목록:\")\n",
    "for source in file_sources:\n",
    "    print(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227476a-1804-4ac4-89dc-4197c5ed6f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
