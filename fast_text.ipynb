{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고유명사 어쩌지? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자모 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText 자모 단위 모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# 자모 변환된 한국어 문서를 불러오기\n",
    "with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences = [line.strip().split() for line in f.readlines()] \n",
    "\n",
    "# FastText 모델 학습\n",
    "model = FastText(sentences, vector_size=100, window=5, min_count=1, workers=4, sg=1, epochs=10)\n",
    "\n",
    "# 학습한 모델 저장\n",
    "model.save(\"fasttext_jamo.model\")\n",
    "print(\"FastText 자모 단위 모델 학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# 학습된 모델 불러오기\n",
    "model = FastText.load(\"fasttext_jamo.model\")\n",
    "\n",
    "# 테스트 단어 (자모 분리)\n",
    "test_word = decompose_korean(\"자연어\")\n",
    "print(f\"자모 변환된 단어: {test_word}\")\n",
    "\n",
    "# 단어 벡터 출력\n",
    "print(f\"'{test_word}'의 벡터 값:\\n\", model.wv[test_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 문장의 코사인 유사도 계산\n",
    "def calculate_similarity(sentence1, sentence2, model):\n",
    "    vec1 = sentence_to_vector(sentence1, model)\n",
    "    vec2 = sentence_to_vector(sentence2, model)\n",
    "    return cosine_similarity([vec1], [vec2])[0][0]  # 코사인 유사도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '작가사진', 'title_ch': '作家寫眞', 'title_eng': 'Selfportrait', 'artist': '한기석', 'artist_eng': 'HAN Kisuk', 'artwork_number': 1, 'year': '1960', 'size': '41×51', 'materials': '종이에 젤라틴실버프린트', 'category': '사진', 'description': '‘농(Nong)’이라는 이름으로 미국에서 널리 알려진 한농(韓農) 한기석(1930-2011)은 국내 활동이 그리 많지 않아서 한국 화단에서는 생소한 이름이다. 그가 최초로 한국 화단에 등장한 것은 1971년 11월 신세계 화랑에서 개최한《Nong 展》이후이다. 그는 농(Nong)을 구름 위의 시선(詩仙) 혹은 주선(酒仙)같은 존재로 비유해서 미국에서 자신의 이름으로 쓰고 있다.그의 작품은 전반적으로 자신의 철학적 이미지를 조형화시킨 추상 회화 계통이다. 일종의 형이상학적인 회화 혹은 초현실적인 환상세계라고도 할 수 있는 그의 작품은 양식적인 면에서 주로 구상적인 형태를 취한다.한기석의 <작가사진>(1960)은 본인의 얼굴을 찍은 것으로, 사진 속에서 작가는 자신의 작품을 배경으로 화면의 우측을 주시하고 있다.', 'read_count': 10468}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON 데이터 불러오기\n",
    "with open('json_data.json', 'r', encoding='utf-8') as f:\n",
    "    artwork_data = json.load(f)\n",
    "\n",
    "# 데이터 샘플 출력\n",
    "print(artwork_data[0])  # 첫 번째 작품 정보 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText 자모 모델 학습 완료!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# FastText 기반 유사도 계산 함수\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"코사인 유사도 계산\"\"\"\n",
    "    return np.dot(vec1, vec2.T) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def get_embedding(sentence, model):\n",
    "    \"\"\"문장 임베딩 계산 (FastText)\"\"\"\n",
    "    tokens = sentence.split()  # 문장을 공백 기준으로 나눔\n",
    "    vec = np.mean([model.wv[token] for token in tokens if token in model.wv], axis=0)  # 평균 벡터 계산\n",
    "    return vec\n",
    "\n",
    "# RAG 정답과 LLM 응답의 유사도를 계산하는 함수\n",
    "def calculate_similarity(ground_truth, llm_response, model):\n",
    "    # RAG 정답과 LLM 응답에 대한 임베딩 계산\n",
    "    vec1 = get_embedding(ground_truth, model)\n",
    "    vec2 = get_embedding(llm_response, model)\n",
    "    \n",
    "    # 유사도 계산\n",
    "    similarity = cosine_similarity(vec1, vec2)\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 정답과 LLM 응답의 유사도: 0.1882\n"
     ]
    }
   ],
   "source": [
    "# 예시 문장들 (ground_truth와 LLM 응답)\n",
    "rag_answer = \"\"\"\n",
    "집에가고싶어.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "llm_response = \"\"\"\n",
    "짜증이나.\n",
    "\"\"\"\n",
    "\n",
    "# 유사도 계산\n",
    "similarity = calculate_similarity(rag_answer, llm_response, model)\n",
    "\n",
    "print(f\"RAG 정답과 LLM 응답의 유사도: {similarity:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잠시만 질문도 뭔지 파악해야되는거아냐? 정답이랑 llm답변만 비교하는게 아니라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 커스텀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import FastText\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "# ✅ FastText 모델 로드\n",
    "model_path = \"./fasttext_jamo_with_numbers.model\"\n",
    "model = FastText.load(model_path)\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# ✅ 문장을 FastText 벡터로 변환하는 함수\n",
    "def get_sentence_embedding(sentence, model):\n",
    "    tokens = [token.form for token in kiwi.tokenize(sentence)]\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)  # 모델에 없는 단어만 있으면 0 벡터 반환\n",
    "    return np.mean(vectors, axis=0)  # 평균 벡터 반환\n",
    "\n",
    "# ✅ 숫자 비교 및 패널티 적용 함수\n",
    "def compare_numbers_ignore_order(sentence1, sentence2):\n",
    "    \"\"\"숫자의 값이 다르면 패널티 적용, 순서는 무시\"\"\"\n",
    "    numbers1 = set(re.findall(r'\\d+', sentence1))  # 숫자만 추출하여 집합으로 저장\n",
    "    numbers2 = set(re.findall(r'\\d+', sentence2))\n",
    "\n",
    "    if not numbers1 or not numbers2:\n",
    "        return 1.0  # 숫자가 없으면 패널티 없음\n",
    "\n",
    "    if numbers1 != numbers2:  \n",
    "        return 0.1  # 숫자 값이 다르면 패널티 적용\n",
    "\n",
    "    return 1.0  # 숫자 값이 같으면 패널티 없음\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 무시할 단어 목록 (조사, 접속사 등)\n",
    "IGNORED_WORDS = {\"이\", \"그\", \"그리고\", \"하지만\", \"또한\", \"그러나\", \"즉\"}\n",
    "\n",
    "# ✅ 중요한 개념을 담고 있는 키워드 목록\n",
    "KEYWORDS = {\"작품\", \"제작\", \"연도\", \"년도\", \"미술\", \"예술\", \"작가\", \"전시\", \"소재\"}\n",
    "\n",
    "# ✅ 할루시네이션 감지 함수 개선\n",
    "def detect_hallucination(ground_truth, generated_text):\n",
    "    \"\"\"핵심 개념이 유지되면 감점하지 않고, 새로운 정보 추가 또는 정보 삭제 시 감점\"\"\"\n",
    "    \n",
    "    # ✅ 형태소 분석 후 명사, 동사, 형용사만 비교\n",
    "    gt_tokens = {token.form for token in kiwi.tokenize(ground_truth) if token.tag.startswith((\"N\", \"V\", \"X\"))}\n",
    "    gen_tokens = {token.form for token in kiwi.tokenize(generated_text) if token.tag.startswith((\"N\", \"V\", \"X\"))}\n",
    "\n",
    "    # ✅ 불필요한 단어(조사, 접속사 등) 제거\n",
    "    gt_tokens -= IGNORED_WORDS\n",
    "    gen_tokens -= IGNORED_WORDS\n",
    "\n",
    "    # ✅ 원래 있어야 할 단어 중 중요한 개념 단어만 체크\n",
    "    gt_key_tokens = gt_tokens & KEYWORDS\n",
    "    gen_key_tokens = gen_tokens & KEYWORDS\n",
    "\n",
    "    # ✅ 핵심 개념이 유지되었다면 감점하지 않음\n",
    "    if gt_key_tokens and gen_key_tokens and gt_key_tokens == gen_key_tokens:\n",
    "        return 1.0  # 핵심 개념이 유지되었으므로 감점 X\n",
    "\n",
    "    # ✅ 새로운 개념이 2개 이상 추가되면 감점\n",
    "    extra_tokens = gen_tokens - gt_tokens  # 생성된 문장에서 원문에 없는 단어 찾기\n",
    "    missing_tokens = gt_tokens - gen_tokens  # 원래 문장에서 빠진 단어 찾기\n",
    "\n",
    "    if len(extra_tokens) > 2:  # 새로운 정보가 추가되었을 때 감점\n",
    "        return 0.5\n",
    "\n",
    "    # ✅ 중요한 정보가 빠지면 감점\n",
    "    if len(missing_tokens) > 2:\n",
    "        return 0.5\n",
    "\n",
    "    return 1.0  # 큰 차이가 없으면 점수 유지\n",
    "\n",
    "\n",
    "def custom_similarity(text1, text2, model):\n",
    "    \"\"\"FastText 기반 유사도 계산, 동의어 적용, 숫자 패널티 반영, 할루시네이션 감지\"\"\"\n",
    "    # 동의어 확장 적용\n",
    "    # 문장 임베딩 변환 (FastText)\n",
    "    vec1 = get_sentence_embedding(text1, model)\n",
    "    vec2 = get_sentence_embedding(text2, model)\n",
    "\n",
    "    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:\n",
    "        return 0.0  # 한쪽 문장이라도 FastText 벡터가 없으면 유사도 0\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "    # 숫자 비교 후 패널티 적용 (숫자 순서 무시)\n",
    "    number_penalty = compare_numbers_ignore_order(text1, text2)\n",
    "\n",
    "    # 할루시네이션 감지 후 패널티 적용\n",
    "    hallucination_penalty = detect_hallucination(text1, text2)\n",
    "\n",
    "    # 최종 유사도 계산 (숫자 & 할루시네이션 패널티 반영)\n",
    "    final_score = similarity.item() * number_penalty * hallucination_penalty  # numpy 값 -> float 변환\n",
    "\n",
    "    return final_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 유사도 (동일 의미 다른 표현): 0.9999\n",
      "🔹 유사도 (의미 유지, 단어 순서 다름): 0.9495\n",
      "🔹 유사도 (숫자 다름): 0.0864\n",
      "🔹 유사도 (숫자 다름, 추가 숫자 있음): 0.0921\n"
     ]
    }
   ],
   "source": [
    "# ✅ 예제 문장\n",
    "text1 = \"이 작품은 1998년에 제작되었습니다.\"\n",
    "text2 = \"이 작품은 1998년에 만들어졌습니다.\"\n",
    "text3 = \"이 작품의 제작 연도는 1998년입니다.\"\n",
    "text4 = \"이 작품은 1999년에 제작되었습니다.\"\n",
    "text5 = \"이 작품은 1998년이 아닌 2000년에 제작되었습니다.\"\n",
    "\n",
    "# ✅ 숫자 + 문맥 + 동의어까지 고려한 유사도 비교\n",
    "sim1 = custom_similarity(text1, text2, model)\n",
    "sim2 = custom_similarity(text1, text3, model)\n",
    "sim3 = custom_similarity(text1, text4, model)\n",
    "sim4 = custom_similarity(text1, text5, model)\n",
    "\n",
    "print(f\"🔹 유사도 (동일 의미 다른 표현): {sim1:.4f}\")  # 높은 점수 기대\n",
    "print(f\"🔹 유사도 (의미 유지, 단어 순서 다름): {sim2:.4f}\")  # 높은 점수 기대\n",
    "print(f\"🔹 유사도 (숫자 다름): {sim3:.4f}\")  # 낮은 점수 (패널티 적용)\n",
    "print(f\"🔹 유사도 (숫자 다름, 추가 숫자 있음): {sim4:.4f}\")  # 매우 낮은 점수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 정답과 LLM 응답의 유사도: 0.4536\n"
     ]
    }
   ],
   "source": [
    "# RAG 정답과 LLM 응답 예제\n",
    "rag_answer = \"\"\"\n",
    "김세진이 컴퓨터 그래픽 회사에서 익힌 다양한 최신 영상 기법을 활용하여 '되돌려진 시간'에서 실험성과 당대성을 확인할 수 있는 감각적인 비디오 작품을 만들었습니다. \n",
    "\n",
    "이 작품은 각각의 화면에는 울기, 성냥 켜기, 그리기, 말하기, 머리 말리기, 먹기 등 일상적인 행위를 촬영한 후에 리버스(reverse) 기법으로 되돌린 영상이 재생되며, \n",
    "\n",
    "평범한 순간을 담은 영상을 되돌렸을 때에 발생하는 낯선 공감각적 내러티브를 통해 또 다른 차원의 이미지를 제시하고자 한 작가의 시도를 보여줍니다.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "llm_response = \"\"\"\n",
    "김세진은 컴퓨터 그래픽 회사에서 다양한 최신 영상 기법을 익혀 \"되돌려진 시간\"에서 이러한 기술을 활용하여 6채널 영상을 제작했습니다. \n",
    "\n",
    "이를 통해 시간의 물리적 흐름을 리버스하는 복잡한 시각적 표현을 구현하고, 매체 실험성을 강화했습니다\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 유사도 계산\n",
    "similarity = custom_similarity(rag_answer, llm_response, model)\n",
    "\n",
    "print(f\"RAG 정답과 LLM 응답의 유사도: {similarity:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 점수범위 -1 ~ 1 \n",
    "# 1: 완전 같음\n",
    "# 0: 완전 무관\n",
    "# -1: 반대되는 의미이지만 거의 발생 x\n",
    "\n",
    "# 0.9612, 0.7238, 0.9073, 0.9053, 0.9434, 0.4258\n",
    "\n",
    "# 숫자가 있을때는 custom similartiy를 아니라면 calculate_similarity를 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_0217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
