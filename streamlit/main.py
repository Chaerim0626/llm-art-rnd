import streamlit as st

st.set_page_config(page_title="Artwork Chatbot", layout="wide")
from model import load_pipeline
from database import load_database
from chain import load_prompt_template, process_input
import uuid
from langchain.schema import HumanMessage, AIMessage
from model import llm
from config import memory
from summary import extract_summary
from langchain.memory import VectorStoreRetrieverMemory
from langchain_huggingface import HuggingFaceEmbeddings  # ë³€ê²½ëœ ì„í¬íŠ¸
from langchain_chroma import Chroma  # ë³€ê²½ëœ ì„í¬íŠ¸


st.title("ğŸ–¼ï¸ Artwork QA Chatbot")

# ì„¸ì…˜ ID ê´€ë¦¬
session_id = st.session_state.get('session_id', None)
if not session_id:
    session_id = str(uuid.uuid4())
    st.session_state['session_id'] = session_id

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
persist_directory = "../chroma_1218"
collection_name = "chroma_art"
retriever = load_database(persist_directory, collection_name)

embeddings = HuggingFaceEmbeddings(model_name='intfloat/multilingual-e5-large')

# ëŒ€í™”ìš© DB ì´ˆê¸°í™”
chat_persist_directory = "../chroma_chat_db"  # ëŒ€í™” DB ì €ì¥ ê²½ë¡œ
chat_vectorstore = Chroma(persist_directory=chat_persist_directory, embedding_function=embeddings)
chat_retriever = chat_vectorstore.as_retriever()

# VectorStoreRetrieverMemory ì„¤ì •
chat_memory = VectorStoreRetrieverMemory(
    retriever=chat_retriever,
    memory_key="history",
    input_key="question"
)

def save_to_chat_memory(question, answer):
    chat_memory.save_context({"question": question}, {"output": answer})
    
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
prompt = load_prompt_template('prompt.yaml')

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ



# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í¼ (ì¡°ê±´ë¬¸ ë°–ì— ìœ„ì¹˜)
with st.form('Question_form'):  # í¼ì˜ keyë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
    user_input = st.text_area('ì§ˆë¬¸ ë‚´ìš©:', 'ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.')
    submitted = st.form_submit_button('ë³´ë‚´ê¸°')

# í¼ ì œì¶œ ì²˜ë¦¬
if submitted:  # í¼ì´ ì œì¶œë˜ì—ˆì„ ë•Œë§Œ ì‹¤í–‰
    # ëª¨ë¸ ì‘ë‹µ ìƒì„±
    response = process_input(llm, retriever,chat_retriever, prompt, user_input, chat_memory)
    if not response:
        response = "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # VectorStore ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ (ëŒ€í™” ì €ì¥)
    chat_memory.save_context(
        {"question": user_input},  # ì‚¬ìš©ì ì…ë ¥
        {"output": response}       # ëª¨ë¸ ì‘ë‹µ
    )

    # í˜„ì¬ ì§ˆë¬¸ê³¼ ë‹µë³€ ì¶œë ¥
    st.markdown("---")
    st.markdown("### í˜„ì¬ ëŒ€í™”")
    st.write(f"**ì§ˆë¬¸:** {user_input}")
    st.markdown(f"**ë‹µë³€:** {response}")

#ëŒ€í™” ìš”ì•½
if st.button("ëŒ€í™” ìš”ì•½ ë³´ê¸°"):
    try:
        memory_variables = chat_memory.load_memory_variables({"question": ""})  # ë¹ˆ question ëª…ì‹œ
        history = memory_variables.get("history", "")

        # ìš”ì•½ í‘œì‹œ
        st.markdown("### ëŒ€í™” ìš”ì•½:")
        if history:
            st.write(memory_variables)
        else:
            st.write("ìš”ì•½ëœ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")